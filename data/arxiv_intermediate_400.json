[
  {
    "arxiv_id": "2512.13690",
    "title": "DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders",
    "abstract": "Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users to interactively generate previews at any point (timestep or transformer block) during the denoising process. Our model can generate multi-modal preview representations that include RGB and scene intrinsics at more than 4$\\times$ real-time speed (less than 1 second for a 4-second video) that convey consistent appearance and motion to the final video. With the trained decoder, we show that it is possible to interactively guide the generation at intermediate noise steps via stochasticity reinjection and modal steering, unlocking a new control capability. Moreover, we systematically probe the model using the learned decoders, revealing how scene, object, and other details are composed and assembled during the otherwise black-box denoising process.",
    "published": "2025-12-15T18:59:57Z",
    "authors": [
      "Susung Hong",
      "Chongjian Ge",
      "Zhifei Zhang",
      "Jui-Hsien Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13689",
    "title": "LitePT: Lighter Yet Stronger Point Transformer",
    "abstract": "Modern neural architectures for 3D point cloud processing contain both convolutional layers and attention blocks, but the best way to assemble them remains unclear. We analyse the role of different computational blocks in 3D point cloud networks and find an intuitive behaviour: convolution is adequate to extract low-level geometry at high-resolution in early layers, where attention is expensive without bringing any benefits; attention captures high-level semantics and context in low-resolution, deep layers more efficiently. Guided by this design principle, we propose a new, improved 3D point cloud backbone that employs convolutions in early stages and switches to attention for deeper layers. To avoid the loss of spatial layout information when discarding redundant convolution layers, we introduce a novel, training-free 3D positional encoding, PointROPE. The resulting LitePT model has $3.6\\times$ fewer parameters, runs $2\\times$ faster, and uses $2\\times$ less memory than the state-of-the-art Point Transformer V3, but nonetheless matches or even outperforms it on a range of tasks and datasets. Code and models are available at: https://github.com/prs-eth/LitePT.",
    "published": "2025-12-15T18:59:57Z",
    "authors": [
      "Yuanwen Yue",
      "Damien Robert",
      "Jianyuan Wang",
      "Sunghwan Hong",
      "Jan Dirk Wegner",
      "Christian Rupprecht",
      "Konrad Schindler"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13687",
    "title": "Towards Scalable Pre-training of Visual Tokenizers for Generation",
    "abstract": "The quality of the latent space in visual tokenizers (e.g., VAEs) is crucial for modern generative models. However, the standard reconstruction-based training paradigm produces a latent space that is biased towards low-level information, leading to a foundation flaw: better pixel-level accuracy does not lead to higher-quality generation. This implies that pouring extensive compute into visual tokenizer pre-training translates poorly to improved performance in generation. We identify this as the ``pre-training scaling problem`` and suggest a necessary shift: to be effective for generation, a latent space must concisely represent high-level semantics. We present VTP, a unified visual tokenizer pre-training framework, pioneering the joint optimization of image-text contrastive, self-supervised, and reconstruction losses. Our large-scale study reveals two principal findings: (1) understanding is a key driver of generation, and (2) much better scaling properties, where generative performance scales effectively with compute, parameters, and data allocated to the pretraining of the visual tokenizer. After large-scale pre-training, our tokenizer delivers a competitive profile (78.2 zero-shot accuracy and 0.36 rFID on ImageNet) and 4.1 times faster convergence on generation compared to advanced distillation methods. More importantly, it scales effectively: without modifying standard DiT training specs, solely investing more FLOPS in pretraining VTP achieves 65.8\\% FID improvement in downstream generation, while conventional autoencoder stagnates very early at 1/10 FLOPS. Our pre-trained models are available at https://github.com/MiniMax-AI/VTP.",
    "published": "2025-12-15T18:59:54Z",
    "authors": [
      "Jingfeng Yao",
      "Yuda Song",
      "Yucong Zhou",
      "Xinggang Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13685",
    "title": "Beyond surface form: A pipeline for semantic analysis in Alzheimer's Disease detection from spontaneous speech",
    "abstract": "Alzheimer's Disease (AD) is a progressive neurodegenerative condition that adversely affects cognitive abilities. Language-related changes can be automatically identified through the analysis of outputs from linguistic assessment tasks, such as picture description. Language models show promise as a basis for screening tools for AD, but their limited interpretability poses a challenge in distinguishing true linguistic markers of cognitive decline from surface-level textual patterns. To address this issue, we examine how surface form variation affects classification performance, with the goal of assessing the ability of language models to represent underlying semantic indicators. We introduce a novel approach where texts surface forms are transformed by altering syntax and vocabulary while preserving semantic content. The transformations significantly modify the structure and lexical content, as indicated by low BLEU and chrF scores, yet retain the underlying semantics, as reflected in high semantic similarity scores, isolating the effect of semantic information, and finding models perform similarly to if they were using the original text, with only small deviations in macro-F1. We also investigate whether language from picture descriptions retains enough detail to reconstruct the original image using generative models. We found that image-based transformations add substantial noise reducing classification accuracy. Our methodology provides a novel way of looking at what features influence model predictions, and allows the removal of possible spurious correlations. We find that just using semantic information, language model based classifiers can still detect AD. This work shows that difficult to detect semantic impairment can be identified, addressing an overlooked feature of linguistic deterioration, and opening new pathways for early detection systems.",
    "published": "2025-12-15T18:59:49Z",
    "authors": [
      "Dylan Phelps",
      "Rodrigo Wilkens",
      "Edward Gow-Smith",
      "Lilian Hubner",
      "Bárbara Malcorra",
      "César Rennó-Costa",
      "Marco Idiart",
      "Maria-Cruz Villa-Uriol",
      "Aline Villavicencio"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13684",
    "title": "Recurrent Video Masked Autoencoders",
    "abstract": "We present Recurrent Video Masked-Autoencoders (RVM): a novel video representation learning approach that uses a transformer-based recurrent neural network to aggregate dense image features over time, effectively capturing the spatio-temporal structure of natural video data. RVM learns via an asymmetric masked prediction task requiring only a standard pixel reconstruction objective. This design yields a highly efficient ``generalist'' encoder: RVM achieves competitive performance with state-of-the-art video models (e.g. VideoMAE, V-JEPA) on video-level tasks like action recognition and point/object tracking, while also performing favorably against image models (e.g. DINOv2) on tasks that test geometric and dense spatial understanding. Notably, RVM achieves strong performance in the small-model regime without requiring knowledge distillation, exhibiting up to 30x greater parameter efficiency than competing video masked autoencoders. Moreover, we demonstrate that RVM's recurrent nature allows for stable feature propagation over long temporal horizons with linear computational cost, overcoming some of the limitations of standard spatio-temporal attention-based architectures. Finally, we use qualitative visualizations to highlight that RVM learns rich representations of scene semantics, structure, and motion.",
    "published": "2025-12-15T18:59:48Z",
    "authors": [
      "Daniel Zoran",
      "Nikhil Parthasarathy",
      "Yi Yang",
      "Drew A Hudson",
      "Joao Carreira",
      "Andrew Zisserman"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13683",
    "title": "I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners",
    "abstract": "Generalization remains the central challenge for interactive 3D scene generation. Existing learning-based approaches ground spatial understanding in limited scene dataset, restricting generalization to new layouts. We instead reprogram a pre-trained 3D instance generator to act as a scene level learner, replacing dataset-bounded supervision with model-centric spatial supervision. This reprogramming unlocks the generator transferable spatial knowledge, enabling generalization to unseen layouts and novel object compositions. Remarkably, spatial reasoning still emerges even when the training scenes are randomly composed objects. This demonstrates that the generator's transferable scene prior provides a rich learning signal for inferring proximity, support, and symmetry from purely geometric cues. Replacing widely used canonical space, we instantiate this insight with a view-centric formulation of the scene space, yielding a fully feed-forward, generalizable scene generator that learns spatial relations directly from the instance model. Quantitative and qualitative results show that a 3D instance generator is an implicit spatial learner and reasoner, pointing toward foundation models for interactive 3D scene understanding and generation. Project page: https://luling06.github.io/I-Scene-project/",
    "published": "2025-12-15T18:59:13Z",
    "authors": [
      "Lu Ling",
      "Yunhao Ge",
      "Yichen Sheng",
      "Aniket Bera"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13680",
    "title": "LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction",
    "abstract": "Recent feed-forward reconstruction models like VGGT and $π^3$ achieve impressive reconstruction quality but cannot process streaming videos due to quadratic memory complexity, limiting their practical deployment. While existing streaming methods address this through learned memory mechanisms or causal attention, they require extensive retraining and may not fully leverage the strong geometric priors of state-of-the-art offline models. We propose LASER, a training-free framework that converts an offline reconstruction model into a streaming system by aligning predictions across consecutive temporal windows. We observe that simple similarity transformation ($\\mathrm{Sim}(3)$) alignment fails due to layer depth misalignment: monocular scale ambiguity causes relative depth scales of different scene layers to vary inconsistently between windows. To address this, we introduce layer-wise scale alignment, which segments depth predictions into discrete layers, computes per-layer scale factors, and propagates them across both adjacent windows and timestamps. Extensive experiments show that LASER achieves state-of-the-art performance on camera pose estimation and point map reconstruction %quality with offline models while operating at 14 FPS with 6 GB peak memory on a RTX A6000 GPU, enabling practical deployment for kilometer-scale streaming videos. Project website: $\\href{https://neu-vi.github.io/LASER/}{\\texttt{https://neu-vi.github.io/LASER/}}$",
    "published": "2025-12-15T18:59:04Z",
    "authors": [
      "Tianye Ding",
      "Yiming Xie",
      "Yiqing Liang",
      "Moitreya Chatterjee",
      "Pedro Miraldo",
      "Huaizu Jiang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13678",
    "title": "Feedforward 3D Editing via Text-Steerable Image-to-3D",
    "abstract": "Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward pass. We build a scalable data engine for automatic data generation, and develop a two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4x to 28.5x faster. Steer3D demonstrates that it is possible to add a new modality (text) to steer the generation of pretrained image-to-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/",
    "published": "2025-12-15T18:58:55Z",
    "authors": [
      "Ziqi Ma",
      "Hongqiao Chen",
      "Yisong Yue",
      "Georgia Gkioxari"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13677",
    "title": "JoVA: Unified Multimodal Learning for Joint Video-Audio Generation",
    "abstract": "In this paper, we present JoVA, a unified framework for joint video-audio generation. Despite recent encouraging advances, existing methods face two critical limitations. First, most existing approaches can only generate ambient sounds and lack the capability to produce human speech synchronized with lip movements. Second, recent attempts at unified human video-audio generation typically rely on explicit fusion or modality-specific alignment modules, which introduce additional architecture design and weaken the model simplicity of the original transformers. To address these issues, JoVA employs joint self-attention across video and audio tokens within each transformer layer, enabling direct and efficient cross-modal interaction without the need for additional alignment modules. Furthermore, to enable high-quality lip-speech synchronization, we introduce a simple yet effective mouth-area loss based on facial keypoint detection, which enhances supervision on the critical mouth region during training without compromising architectural simplicity. Extensive experiments on benchmarks demonstrate that JoVA outperforms or is competitive with both unified and audio-driven state-of-the-art methods in lip-sync accuracy, speech quality, and overall video-audio generation fidelity. Our results establish JoVA as an elegant framework for high-quality multimodal generation.",
    "published": "2025-12-15T18:58:18Z",
    "authors": [
      "Xiaohu Huang",
      "Hao Zhou",
      "Qiangpeng Yang",
      "Shilei Wen",
      "Kai Han"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13676",
    "title": "Towards Effective Model Editing for LLM Personalization",
    "abstract": "Personalization is becoming indispensable for LLMs to align with individual user preferences and needs. Yet current approaches are often computationally expensive, data-intensive, susceptible to catastrophic forgetting, and prone to performance degradation in multi-turn interactions or when handling implicit queries. To address these challenges, we conceptualize personalization as a model editing task and introduce Personalization Editing, a framework that applies localized edits guided by clustered preference representations. This design enables precise preference-aligned updates while preserving overall model capabilities. In addition, existing personalization benchmarks frequently rely on persona-based dialogs between LLMs rather than user-LLM interactions, or focus primarily on stylistic imitation while neglecting information-seeking tasks that require accurate recall of user-specific preferences. We introduce User Preference Question Answering (UPQA), a short-answer QA dataset constructed from in-situ user queries with varying levels of difficulty. Unlike prior benchmarks, UPQA directly evaluates a model's ability to recall and apply specific user preferences. Across experimental settings, Personalization Editing achieves higher editing accuracy and greater computational efficiency than fine-tuning, while outperforming prompting-based baselines in multi-turn conversations and implicit preference questions settings.",
    "published": "2025-12-15T18:58:15Z",
    "authors": [
      "Baixiang Huang",
      "Limeng Cui",
      "Jiapeng Liu",
      "Haoran Wang",
      "Jiawei Xu",
      "Zhuiyue Tan",
      "Yutong Chen",
      "Chen Luo",
      "Yi Liu",
      "Kai Shu"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13674",
    "title": "Towards Interactive Intelligence for Digital Humans",
    "abstract": "We introduce Interactive Intelligence, a novel paradigm of digital human that is capable of personality-aligned expression, adaptive interaction, and self-evolution. To realize this, we present Mio (Multimodal Interactive Omni-Avatar), an end-to-end framework composed of five specialized modules: Thinker, Talker, Face Animator, Body Animator, and Renderer. This unified architecture integrates cognitive reasoning with real-time multimodal embodiment to enable fluid, consistent interaction. Furthermore, we establish a new benchmark to rigorously evaluate the capabilities of interactive intelligence. Extensive experiments demonstrate that our framework achieves superior performance compared to state-of-the-art methods across all evaluated dimensions. Together, these contributions move digital humans beyond superficial imitation toward intelligent interaction.",
    "published": "2025-12-15T18:57:35Z",
    "authors": [
      "Yiyi Cai",
      "Xuangeng Chu",
      "Xiwei Gao",
      "Sitong Gong",
      "Yifei Huang",
      "Caixin Kang",
      "Kunhang Li",
      "Haiyang Liu",
      "Ruicong Liu",
      "Yun Liu",
      "Dianwen Ng",
      "Zixiong Su",
      "Erwin Wu",
      "Yuhan Wu",
      "Dingkun Yan",
      "Tianyu Yan",
      "Chang Zeng",
      "Bo Zheng",
      "You Zhou"
    ],
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.GR",
      "cs.HC"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13672",
    "title": "Directional Textual Inversion for Personalized Text-to-Image Generation",
    "abstract": "Textual Inversion (TI) is an efficient approach to text-to-image personalization but often fails on complex prompts. We trace these failures to embedding norm inflation: learned tokens drift to out-of-distribution magnitudes, degrading prompt conditioning in pre-norm Transformers. Empirically, we show semantics are primarily encoded by direction in CLIP token space, while inflated norms harm contextualization; theoretically, we analyze how large magnitudes attenuate positional information and hinder residual updates in pre-norm blocks. We propose Directional Textual Inversion (DTI), which fixes the embedding magnitude to an in-distribution scale and optimizes only direction on the unit hypersphere via Riemannian SGD. We cast direction learning as MAP with a von Mises-Fisher prior, yielding a constant-direction prior gradient that is simple and efficient to incorporate. Across personalization tasks, DTI improves text fidelity over TI and TI-variants while maintaining subject similarity. Crucially, DTI's hyperspherical parameterization enables smooth, semantically coherent interpolation between learned concepts (slerp), a capability that is absent in standard TI. Our findings suggest that direction-only optimization is a robust and scalable path for prompt-faithful personalization.",
    "published": "2025-12-15T18:57:07Z",
    "authors": [
      "Kunhee Kim",
      "NaHyeon Park",
      "Kibeom Hong",
      "Hyunjung Shim"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13671",
    "title": "AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection",
    "abstract": "Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We propose AgentIAD, a tool-driven agentic framework that enables multi-stage visual inspection. The agent is equipped with a Perceptive Zoomer (PZ) for localized fine-grained analysis and a Comparative Retriever (CR) for querying normal exemplars when evidence is ambiguous. To teach these inspection behaviors, we construct structured perceptive and comparative trajectories from the MMAD dataset and train the model in two stages: supervised fine-tuning followed by reinforcement learning. A two-part reward design drives this process: a perception reward that supervises classification accuracy, spatial alignment, and type correctness, and a behavior reward that encourages efficient tool use. Together, these components enable the model to refine its judgment through step-wise observation, zooming, and verification. AgentIAD achieves a new state-of-the-art 97.62% classification accuracy on MMAD, surpassing prior MLLM-based approaches while producing transparent and interpretable inspection traces.",
    "published": "2025-12-15T18:57:04Z",
    "authors": [
      "Junwen Miao",
      "Penghui Du",
      "Yi Liu",
      "Yu Wang",
      "Yan Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13668",
    "title": "A Scientific Reasoning Model for Organic Synthesis Procedure Generation",
    "abstract": "Solving computer-aided synthesis planning is essential for enabling fully automated, robot-assisted synthesis workflows and improving the efficiency of drug discovery. A key challenge, however, is bridging the gap between computational route design and practical laboratory execution, particularly the accurate prediction of viable experimental procedures for each synthesis step. In this work, we present QFANG, a scientific reasoning language model capable of generating precise, structured experimental procedures directly from reaction equations, with explicit chain-of-thought reasoning. To develop QFANG, we curated a high-quality dataset comprising 905,990 chemical reactions paired with structured action sequences, extracted and processed from patent literature using large language models. We introduce a Chemistry-Guided Reasoning (CGR) framework that produces chain-of-thought data grounded in chemical knowledge at scale. The model subsequently undergoes supervised fine-tuning to elicit complex chemistry reasoning. Finally, we apply Reinforcement Learning from Verifiable Rewards (RLVR) to further enhance procedural accuracy. Experimental results demonstrate that QFANG outperforms advanced general-purpose reasoning models and nearest-neighbor retrieval baselines, measured by traditional NLP similarity metrics and a chemically aware evaluator using an LLM-as-a-judge. Moreover, QFANG generalizes to certain out-of-domain reaction classes and adapts to variations in laboratory conditions and user-specific constraints. We believe that QFANG's ability to generate high-quality synthesis procedures represents an important step toward bridging the gap between computational synthesis planning and fully automated laboratory synthesis.",
    "published": "2025-12-15T18:55:39Z",
    "authors": [
      "Guoqing Liu",
      "Junren Li",
      "Zihan Zhao",
      "Eray Inanc",
      "Krzysztof Maziarz",
      "Jose Garrido Torres",
      "Victor Garcia Satorras",
      "Shoko Ueda",
      "Christopher M. Bishop",
      "Marwin Segler"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13667",
    "title": "A stylometric analysis of speaker attribution from speech transcripts",
    "abstract": "Forensic scientists often need to identify an unknown speaker or writer in cases such as ransom calls, covert recordings, alleged suicide notes, or anonymous online communications, among many others. Speaker recognition in the speech domain usually examines phonetic or acoustic properties of a voice, and these methods can be accurate and robust under certain conditions. However, if a speaker disguises their voice or employs text-to-speech software, vocal properties may no longer be reliable, leaving only their linguistic content available for analysis. Authorship attribution methods traditionally use syntactic, semantic, and related linguistic information to identify writers of written text (authorship attribution). In this paper, we apply a content-based authorship approach to speech that has been transcribed into text, using what a speaker says to attribute speech to individuals (speaker attribution). We introduce a stylometric method, StyloSpeaker, which incorporates character, word, token, sentence, and style features from the stylometric literature on authorship, to assess whether two transcripts were produced by the same speaker. We evaluate this method on two types of transcript formatting: one approximating prescriptive written text with capitalization and punctuation and another normalized style that removes these conventions. The transcripts' conversation topics are also controlled to varying degrees. We find generally higher attribution performance on normalized transcripts, except under the strongest topic control condition, in which overall performance is highest. Finally, we compare this more explainable stylometric model to black-box neural approaches on the same data and investigate which stylistic features most effectively distinguish speakers.",
    "published": "2025-12-15T18:55:25Z",
    "authors": [
      "Cristina Aggazzotti",
      "Elizabeth Allyn Smith"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13666",
    "title": "SEDULity: A Proof-of-Learning Framework for Distributed and Secure Blockchains with Efficient Useful Work",
    "abstract": "The security and decentralization of Proof-of-Work (PoW) have been well-tested in existing blockchain systems. However, its tremendous energy waste has raised concerns about sustainability. Proof-of-Useful-Work (PoUW) aims to redirect the meaningless computation to meaningful tasks such as solving machine learning (ML) problems, giving rise to the branch of Proof-of-Learning (PoL). While previous studies have proposed various PoLs, they all, to some degree, suffer from security, decentralization, or efficiency issues. In this paper, we propose a PoL framework that trains ML models efficiently while maintaining blockchain security in a fully distributed manner. We name the framework SEDULity, which stands for a Secure, Efficient, Distributed, and Useful Learning-based blockchain system. Specifically, we encode the template block into the training process and design a useful function that is difficult to solve but relatively easy to verify, as a substitute for the PoW puzzle. We show that our framework is distributed, secure, and efficiently trains ML models. We further demonstrate that the proposed PoL framework can be extended to other types of useful work and design an incentive mechanism to incentivize task verification. We show theoretically that a rational miner is incentivized to train fully honestly with well-designed system parameters. Finally, we present simulation results to demonstrate the performance of our framework and validate our analysis.",
    "published": "2025-12-15T18:55:20Z",
    "authors": [
      "Weihang Cao",
      "Mustafa Doger",
      "Sennur Ulukus"
    ],
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.IT",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13665",
    "title": "Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency",
    "abstract": "Recent advances in diffusion-based generation techniques enable AI models to produce highly realistic videos, heightening the need for reliable detection mechanisms. However, existing detection methods provide only limited exploration of the 3D geometric patterns present in generated videos. In this paper, we use vanishing points as an explicit representation of 3D geometry patterns, revealing fundamental discrepancies in geometric consistency between real and AI-generated videos. We introduce Grab-3D, a geometry-aware transformer framework for detecting AI-generated videos based on 3D geometric temporal consistency. To enable reliable evaluation, we construct an AI-generated video dataset of static scenes, allowing stable 3D geometric feature extraction. We propose a geometry-aware transformer equipped with geometric positional encoding, temporal-geometric attention, and an EMA-based geometric classifier head to explicitly inject 3D geometric awareness into temporal modeling. Experiments demonstrate that Grab-3D significantly outperforms state-of-the-art detectors, achieving robust cross-domain generalization to unseen generators.",
    "published": "2025-12-15T18:54:30Z",
    "authors": [
      "Wenhan Chen",
      "Sezer Karaoglu",
      "Theo Gevers"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13660",
    "title": "RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics",
    "abstract": "Spatial tracing, as a fundamental embodied interaction ability for robots, is inherently challenging as it requires multi-step metric-grounded reasoning compounded with complex spatial referring and real-world metric measurement. However, existing methods struggle with this compositional task. To this end, we propose RoboTracer, a 3D-aware VLM that first achieves both 3D spatial referring and measuring via a universal spatial encoder and a regression-supervised decoder to enhance scale awareness during supervised fine-tuning (SFT). Moreover, RoboTracer advances multi-step metric-grounded reasoning via reinforcement fine-tuning (RFT) with metric-sensitive process rewards, supervising key intermediate perceptual cues to accurately generate spatial traces. To support SFT and RFT training, we introduce TraceSpatial, a large-scale dataset of 30M QA pairs, spanning outdoor/indoor/tabletop scenes and supporting complex reasoning processes (up to 9 steps). We further present TraceSpatial-Bench, a challenging benchmark filling the gap to evaluate spatial tracing. Experimental results show that RoboTracer surpasses baselines in spatial understanding, measuring, and referring, with an average success rate of 79.1%, and also achieves SOTA performance on TraceSpatial-Bench by a large margin, exceeding Gemini-2.5-Pro by 36% accuracy. Notably, RoboTracer can be integrated with various control policies to execute long-horizon, dynamic tasks across diverse robots (UR5, G1 humanoid) in cluttered real-world scenes.",
    "published": "2025-12-15T18:52:43Z",
    "authors": [
      "Enshen Zhou",
      "Cheng Chi",
      "Yibo Li",
      "Jingkun An",
      "Jiayuan Zhang",
      "Shanyu Rong",
      "Yi Han",
      "Yuheng Ji",
      "Mengzhen Liu",
      "Pengwei Wang",
      "Zhongyuan Wang",
      "Lu Sheng",
      "Shanghang Zhang"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13658",
    "title": "Embedding-Based Rankings of Educational Resources based on Learning Outcome Alignment: Benchmarking, Expert Validation, and Learner Performance",
    "abstract": "As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review, which is costly and limits scalability. We propose a framework that supports the cost-effective automation of evaluating alignment between educational resources and intended learning outcomes. Using human-generated materials, we benchmarked LLM-based text-embedding models and found that the most accurate model (Voyage) achieved 79% accuracy in detecting alignment. We then applied the optimal model to LLM-generated resources and, via expert evaluation, confirmed that it reliably assessed correspondence to intended outcomes (83% accuracy). Finally, in a three-group experiment with 360 learners, higher alignment scores were positively related to greater learning performance, chi-squared(2, N = 360) = 15.39, p < 0.001. These findings show that embedding-based alignment scores can facilitate scalable personalization by confirming alignment with learning outcomes, which allows teachers to focus on tailoring content to diverse learner needs.",
    "published": "2025-12-15T18:51:00Z",
    "authors": [
      "Mohammadreza Molavi",
      "Mohammad Moein",
      "Mohammadreza Tavakoli",
      "Abdolali Faraji",
      "Stefan T. Mol",
      "Gábor Kismihók"
    ],
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13655",
    "title": "Comparative Analysis of LLM Abliteration Methods: A Cross-Architecture Evaluation",
    "abstract": "Safety alignment mechanisms in large language models prevent responses to harmful queries through learned refusal behavior, yet these same mechanisms impede legitimate research applications including cognitive modeling, adversarial testing, and security analysis. While abliteration techniques enable surgical removal of refusal representations through directional orthogonalization, the relative effectiveness of available implementations remains uncharacterized. This study evaluates four abliteration tools (Heretic, DECCP, ErisForge, FailSpy) across sixteen instruction-tuned models (7B-14B parameters), reporting tool compatibility on all 16 models and quantitative metrics on subsets dictated by tool support. Single-pass methods demonstrated superior capability preservation on the benchmarked subset (avg GSM8K change across three models: ErisForge -0.28 pp; DECCP -0.13 pp), while Bayesian-optimized abliteration produced variable distribution shift (KL divergence: 0.043-1.646) with model-dependent capability impact. These findings provide researchers with evidence-based selection criteria for abliteration tool deployment across diverse model architectures. The principal finding indicates that mathematical reasoning capabilities exhibit the highest sensitivity to abliteration interventions, with GSM8K change ranging from +1.51 pp to -18.81 pp (-26.5% relative) depending on tool selection and model architecture.",
    "published": "2025-12-15T18:48:42Z",
    "authors": [
      "Richard J. Young"
    ],
    "categories": [
      "cs.CL",
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13654",
    "title": "Large-Language Memorization During the Classification of United States Supreme Court Cases",
    "abstract": "Large-language models (LLMs) have been shown to respond in a variety of ways for classification tasks outside of question-answering. LLM responses are sometimes called \"hallucinations\" since the output is not what is ex pected. Memorization strategies in LLMs are being studied in detail, with the goal of understanding how LLMs respond. We perform a deep dive into a classification task based on United States Supreme Court (SCOTUS) decisions. The SCOTUS corpus is an ideal classification task to study for LLM memory accuracy because it presents significant challenges due to extensive sentence length, complex legal terminology, non-standard structure, and domain-specific vocabulary. Experimentation is performed with the latest LLM fine tuning and retrieval-based approaches, such as parameter-efficient fine-tuning, auto-modeling, and others, on two traditional category-based SCOTUS classification tasks: one with 15 labeled topics and another with 279. We show that prompt-based models with memories, such as DeepSeek, can be more robust than previous BERT-based models on both tasks scoring about 2 points better than previous models not based on prompting.",
    "published": "2025-12-15T18:47:48Z",
    "authors": [
      "John E. Ortega",
      "Dhruv D. Joshi",
      "Matt P. Borkowski"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.IR"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13644",
    "title": "World Models Can Leverage Human Videos for Dexterous Manipulation",
    "abstract": "Dexterous manipulation is challenging because it requires understanding how subtle hand motion influences the environment through contact with objects. We introduce DexWM, a Dexterous Manipulation World Model that predicts the next latent state of the environment conditioned on past states and dexterous actions. To overcome the scarcity of dexterous manipulation datasets, DexWM is trained on over 900 hours of human and non-dexterous robot videos. To enable fine-grained dexterity, we find that predicting visual features alone is insufficient; therefore, we introduce an auxiliary hand consistency loss that enforces accurate hand configurations. DexWM outperforms prior world models conditioned on text, navigation, and full-body actions, achieving more accurate predictions of future states. DexWM also demonstrates strong zero-shot generalization to unseen manipulation skills when deployed on a Franka Panda arm equipped with an Allegro gripper, outperforming Diffusion Policy by over 50% on average in grasping, placing, and reaching tasks.",
    "published": "2025-12-15T18:37:12Z",
    "authors": [
      "Raktim Gautam Goswami",
      "Amir Bar",
      "David Fan",
      "Tsung-Yen Yang",
      "Gaoyue Zhou",
      "Prashanth Krishnamurthy",
      "Michael Rabbat",
      "Farshad Khorrami",
      "Yann LeCun"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13641",
    "title": "From Code to Field: Evaluating the Robustness of Convolutional Neural Networks for Disease Diagnosis in Mango Leaves",
    "abstract": "The validation and verification of artificial intelligence (AI) models through robustness assessment are essential to guarantee the reliable performance of intelligent systems facing real-world challenges, such as image corruptions including noise, blurring, and weather variations. Despite the global importance of mango (Mangifera indica L.), there is a lack of studies on the robustness of models for the diagnosis of disease in its leaves. This paper proposes a methodology to evaluate convolutional neural networks (CNNs) under adverse conditions. We adapted the MangoLeafDB dataset, generating MangoLeafDB-C with 19 types of artificial corruptions at five severity levels. We conducted a benchmark comparing five architectures: ResNet-50, ResNet-101, VGG-16, Xception, and LCNN (the latter being a lightweight architecture designed specifically for mango leaf diagnosis). The metrics include the F1 score, the corruption error (CE) and the relative mean corruption error (relative mCE). The results show that LCNN outperformed complex models in corruptions that can be present in real-world scenarios such as Defocus Blur, Motion Blur, while also achieving the lowest mCE. Modern architectures (e.g., ResNet-101) exhibited significant performance degradation in corrupted scenarios, despite their high accuracy under ideal conditions. These findings suggest that lightweight and specialized models may be more suitable for real-world applications in edge devices, where robustness and efficiency are critical. The study highlights the need to incorporate robustness assessments in the development of intelligent systems for agriculture, particularly in regions with technological limitations.",
    "published": "2025-12-15T18:36:48Z",
    "authors": [
      "Gabriel Vitorino de Andrade",
      "Saulo Roberto dos Santos",
      "Itallo Patrick Castro Alves da Silva",
      "Emanuel Adler Medeiros Pereira",
      "Erick de Andrade Barboza"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13639",
    "title": "Charge: A Comprehensive Novel View Synthesis Benchmark and Dataset to Bind Them All",
    "abstract": "This paper presents a new dataset for Novel View Synthesis, generated from a high-quality, animated film with stunning realism and intricate detail. Our dataset captures a variety of dynamic scenes, complete with detailed textures, lighting, and motion, making it ideal for training and evaluating cutting-edge 4D scene reconstruction and novel view generation models. In addition to high-fidelity RGB images, we provide multiple complementary modalities, including depth, surface normals, object segmentation and optical flow, enabling a deeper understanding of scene geometry and motion. The dataset is organised into three distinct benchmarking scenarios: a dense multi-view camera setup, a sparse camera arrangement, and monocular video sequences, enabling a wide range of experimentation and comparison across varying levels of data sparsity. With its combination of visual richness, high-quality annotations, and diverse experimental setups, this dataset offers a unique resource for pushing the boundaries of view synthesis and 3D vision.",
    "published": "2025-12-15T18:33:08Z",
    "authors": [
      "Michal Nazarczuk",
      "Thomas Tanay",
      "Arthur Moreau",
      "Zhensong Zhang",
      "Eduardo Pérez-Pellitero"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13638",
    "title": "Design in Tiles: Automating GEMM Deployment on Tile-Based Many-PE Accelerators",
    "abstract": "Tile-based many-Processing Element (PE) accelerators can achieve competitive performance on General Matrix Multiplication (GEMM), but they are extremely hard to program, as their optimal software mapping is deeply coupled with hardware design which is unwieldy to manual deployment. We propose \"Design in Tiles (DiT)\", an automated framework connecting a deployment toolchain with a configurable executable model for these accelerators. For evaluation, we apply our framework to GEMM targeting a large acceleration configuration (e.g., 32x32 tiles, 1979 TFLOPS@FP8, 4 TB/s Bandwidth) comparable to an NVIDIA GH200. We achieve higher PE utilization than GH200 with its expert-tuned GEMM libraries, achieving 1.2-2.0x speedup across diverse matrix shapes.",
    "published": "2025-12-15T18:33:04Z",
    "authors": [
      "Aofeng Shen",
      "Chi Zhang",
      "Yakup Budanaz",
      "Alexandru Calotoiu",
      "Torsten Hoefler",
      "Luca Benini"
    ],
    "categories": [
      "cs.DC",
      "cs.AR"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13636",
    "title": "MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning",
    "abstract": "Current Vision-Language-Action (VLA) paradigms in autonomous driving primarily rely on Imitation Learning (IL), which introduces inherent challenges such as distribution shift and causal confusion. Online Reinforcement Learning offers a promising pathway to address these issues through trial-and-error learning. However, applying online reinforcement learning to VLA models in autonomous driving is hindered by inefficient exploration in continuous action spaces. To overcome this limitation, we propose MindDrive, a VLA framework comprising a large language model (LLM) with two distinct sets of LoRA parameters. The one LLM serves as a Decision Expert for scenario reasoning and driving decision-making, while the other acts as an Action Expert that dynamically maps linguistic decisions into feasible trajectories. By feeding trajectory-level rewards back into the reasoning space, MindDrive enables trial-and-error learning over a finite set of discrete linguistic driving decisions, instead of operating directly in a continuous action space. This approach effectively balances optimal decision-making in complex scenarios, human-like driving behavior, and efficient exploration in online reinforcement learning. MindDrive achieves strong closed-loop performance on the challenging Bench2Drive benchmark, with a Driving Score (DS) of 78.04 and a Success Rate (SR) of 55.09%. To the best of our knowledge, this is the first work to demonstrate the effectiveness of online reinforcement learning for the VLA model in autonomous driving.",
    "published": "2025-12-15T18:31:32Z",
    "authors": [
      "Haoyu Fu",
      "Diankun Zhang",
      "Zongchuang Zhao",
      "Jianfeng Cui",
      "Hongwei Xie",
      "Bing Wang",
      "Guang Chen",
      "Dingkang Liang",
      "Xiang Bai"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13635",
    "title": "SCR2-ST: Combine Single Cell with Spatial Transcriptomics for Efficient Active Sampling via Reinforcement Learning",
    "abstract": "Spatial transcriptomics (ST) is an emerging technology that enables researchers to investigate the molecular relationships underlying tissue morphology. However, acquiring ST data remains prohibitively expensive, and traditional fixed-grid sampling strategies lead to redundant measurements of morphologically similar or biologically uninformative regions, thus resulting in scarce data that constrain current methods. The well-established single-cell sequencing field, however, could provide rich biological data as an effective auxiliary source to mitigate this limitation. To bridge these gaps, we introduce SCR2-ST, a unified framework that leverages single-cell prior knowledge to guide efficient data acquisition and accurate expression prediction. SCR2-ST integrates a single-cell guided reinforcement learning-based (SCRL) active sampling and a hybrid regression-retrieval prediction network SCR2Net. SCRL combines single-cell foundation model embeddings with spatial density information to construct biologically grounded reward signals, enabling selective acquisition of informative tissue regions under constrained sequencing budgets. SCR2Net then leverages the actively sampled data through a hybrid architecture combining regression-based modeling with retrieval-augmented inference, where a majority cell-type filtering mechanism suppresses noisy matches and retrieved expression profiles serve as soft labels for auxiliary supervision. We evaluated SCR2-ST on three public ST datasets, demonstrating SOTA performance in both sampling efficiency and prediction accuracy, particularly under low-budget scenarios. Code is publicly available at: https://github.com/hrlblab/SCR2ST",
    "published": "2025-12-15T18:30:40Z",
    "authors": [
      "Junchao Zhu",
      "Ruining Deng",
      "Junlin Guo",
      "Tianyuan Yao",
      "Chongyu Qu",
      "Juming Xiong",
      "Siqi Lu",
      "Zhengyi Lu",
      "Yanfan Zhu",
      "Marilyn Lionts",
      "Yuechen Yang",
      "Yalin Zheng",
      "Yu Wang",
      "Shilin Zhao",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13634",
    "title": "Universality of high-dimensional scaling limits of stochastic gradient descent",
    "abstract": "We consider statistical tasks in high dimensions whose loss depends on the data only through its projection into a fixed-dimensional subspace spanned by the parameter vectors and certain ground truth vectors. This includes classifying mixture distributions with cross-entropy loss with one and two-layer networks, and learning single and multi-index models with one and two-layer networks. When the data is drawn from an isotropic Gaussian mixture distribution, it is known that the evolution of a finite family of summary statistics under stochastic gradient descent converges to an autonomous ordinary differential equation (ODE), as the dimension and sample size go to $\\infty$ and the step size goes to $0$ commensurately. Our main result is that these ODE limits are universal in that this convergence occurs even when the data is drawn from mixtures of product measures provided the first two moments match the corresponding Gaussian distribution and the initialization and ground truth vectors are sufficiently coordinate-delocalized. We complement this by proving two corresponding non-universality results. We provide a simple example where the ODE limits are non-universal if the initialization is coordinate aligned. We also show that the stochastic differential equation limits arising as fluctuations of the summary statistics around their ODE's fixed points are not universal.",
    "published": "2025-12-15T18:30:26Z",
    "authors": [
      "Reza Gheissari",
      "Aukosh Jagannath"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.PR",
      "math.ST"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13632",
    "title": "StutterFuse: Mitigating Modality Collapse in Stuttering Detection with Jaccard-Weighted Metric Learning and Gated Fusion",
    "abstract": "Stuttering detection breaks down when disfluencies overlap. Existing parametric models struggle to distinguish complex, simultaneous disfluencies (e.g., a 'block' with a 'prolongation') due to the scarcity of these specific combinations in training data. While Retrieval-Augmented Generation (RAG) has revolutionized NLP by grounding models in external knowledge, this paradigm remains unexplored in pathological speech processing. To bridge this gap, we introduce StutterFuse, the first Retrieval-Augmented Classifier (RAC) for multi-label stuttering detection. By conditioning a Conformer encoder on a non-parametric memory bank of clinical examples, we allow the model to classify by reference rather than memorization. We further identify and solve \"Modality Collapse\", an \"Echo Chamber\" effect where naive retrieval boosts recall but degrades precision. We mitigate this using: (1) SetCon, a Jaccard-Weighted Metric Learning objective that optimizes for multi-label set similarity, and (2) a Gated Mixture-of-Experts fusion strategy that dynamically arbitrates between acoustic evidence and retrieved context. On the SEP-28k dataset, StutterFuse achieves a weighted F1-score of 0.65, outperforming strong baselines and demonstrating remarkable zero-shot cross-lingual generalization.",
    "published": "2025-12-15T18:28:39Z",
    "authors": [
      "Guransh Singh",
      "Md Shah Fahad"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13628",
    "title": "Certified-Everlasting Quantum NIZK Proofs",
    "abstract": "We study non-interactive zero-knowledge proofs (NIZKs) for NP satisfying: 1) statistical soundness, 2) computational zero-knowledge and 3) certified-everlasting zero-knowledge (CE-ZK). The CE-ZK property allows a verifier of a quantum proof to revoke the proof in a way that can be checked (certified) by the prover. Conditioned on successful certification, the verifier's state can be efficiently simulated with only the statement, in a statistically indistinguishable way. Our contributions regarding these certified-everlasting NIZKs (CE-NIZKs) are as follows:   - We identify a barrier to obtaining CE-NIZKs in the CRS model via generalizations of known interactive proofs that satisfy CE-ZK.   - We circumvent this by constructing CE-NIZK from black-box use of NIZK for NP satisfying certain properties, along with OWFs. As a result, we obtain CE-NIZKs for NP in the CRS model, based on polynomial hardness of the learning with errors (LWE) assumption.   - In addition, we observe that the aforementioned barrier does not apply to the shared EPR model. Consequently, we present a CE-NIZK for NP in this model based on any statistical binding hidden-bits generator, which can be based on LWE. The only quantum computation in this protocol involves single-qubit measurements of the shared EPR pairs.",
    "published": "2025-12-15T18:23:48Z",
    "authors": [
      "Nikhil Pappu"
    ],
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13618",
    "title": "Temporal Tokenization Strategies for Event Sequence Modeling with Large Language Models",
    "abstract": "Representing continuous time is a critical and under-explored challenge in modeling temporal event sequences with large language models (LLMs). Various strategies like byte-level representations or calendar tokens have been proposed. However, the optimal approach remains unclear, especially given the diverse statistical distributions of real-world event data, which range from smooth log-normal to discrete, spiky patterns. This paper presents the first empirical study of temporal tokenization for event sequences, comparing distinct encoding strategies: naive numeric strings, high-precision byte-level representations, human-semantic calendar tokens, classic uniform binning, and adaptive residual scalar quantization. We evaluate these strategies by fine-tuning LLMs on real-world datasets that exemplify these diverse distributions. Our analysis reveals that no single strategy is universally superior; instead, prediction performance depends heavily on aligning the tokenizer with the data's statistical properties, with log-based strategies excelling on skewed distributions and human-centric formats proving robust for mixed modalities.",
    "published": "2025-12-15T18:10:51Z",
    "authors": [
      "Zefang Liu",
      "Nam Nguyen",
      "Yinzhu Quan",
      "Austin Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13617",
    "title": "LightTopoGAT: Enhancing Graph Attention Networks with Topological Features for Efficient Graph Classification",
    "abstract": "Graph Neural Networks have demonstrated significant success in graph classification tasks, yet they often require substantial computational resources and struggle to capture global graph properties effectively. We introduce LightTopoGAT, a lightweight graph attention network that enhances node features through topological augmentation by incorporating node degree and local clustering coefficient to improve graph representation learning. The proposed approach maintains parameter efficiency through streamlined attention mechanisms while integrating structural information that is typically overlooked by local message passing schemes. Through comprehensive experiments on three benchmark datasets, MUTAG, ENZYMES, and PROTEINS, we show that LightTopoGAT achieves superior performance compared to established baselines including GCN, GraphSAGE, and standard GAT, with a 6.6 percent improvement in accuracy on MUTAG and a 2.2 percent improvement on PROTEINS. Ablation studies further confirm that these performance gains arise directly from the inclusion of topological features, demonstrating a simple yet effective strategy for enhancing graph neural network performance without increasing architectural complexity.",
    "published": "2025-12-15T18:09:59Z",
    "authors": [
      "Ankit Sharma",
      "Sayan Roy Gupta"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13613",
    "title": "QoeSiGN: Towards Qualified Collaborative eSignatures",
    "abstract": "eSignatures ensure data's authenticity, non-repudiation, and integrity. EU's eIDAS regulation specifies, e.g., advanced and qualified (QES) eSignatures. While eSignatures' concrete legal effects depend on the individual case, QESs constitute the highest level of technical protection and authenticity under eIDAS. QESs are based on a qualified certificate issued by a qualified trust service provider (QTSP). Despite legal requirements, technically, a QTSP represents a single point of failure. Contrary, privacy-preserving collaborative computations (P2C2s) have become increasingly practical in recent years; yet lacking an extensive investigation on potential integrations in the QES landscape.   We perform a threat analysis on the QES-creation process of Austria's national eID, using STRIDE and a DREAD-like model to extract requirement challenges (RCs) primarily related to: (1) Distributed Service Robustness, (2) Agile Crypto Deployment, and (3) Active User Involvement. To address these RCs, we present QoeSiGN, utilizing novel P2C2 technologies. While currently no P2C2 addresses all RCs, legal aspects, and practical efficiency simultaneously, QoeSiGN gives instantiation possibilities for different needs. For instance, \"Multi-Party HSMs\" for distributed hardware-secured computations; or secure multi-party computation (software) for highest crypto agility and user involvement, where the user participates in the QES computation.   Deployment-wise, QTSPs would need to adapt the signing process and setup trusted communication channels. Legal-wise, QoeSiGN's implementation appears permissible, needing further analysis for realization. Technically, QoeSiGN addresses some regulation requirements better than the current solution, such as \"sole control\" or crypto agility. Our identified threats and extracted requirements can be transferred to the general QES ecosystem.",
    "published": "2025-12-15T18:07:17Z",
    "authors": [
      "Karl W. Koch",
      "Stephan Krenn",
      "Alexandra Hofer"
    ],
    "categories": [
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13609",
    "title": "Do-Undo: Generating and Reversing Physical Actions in Vision-Language Models",
    "abstract": "We introduce the Do-Undo task and benchmark to address a critical gap in vision-language models: understanding and generating physically plausible scene transformations driven by real-world actions. Unlike prior work focused on object-level edits, Do-Undo requires models to simulate the outcome of a physical action and then accurately reverse it, reflecting true cause-and-effect in the visual world. We curate a large-scale dataset of reversible actions from real-world videos and design a training strategy enforcing consistency for robust action grounding. Our experiments reveal that current models struggle with physical reversibility, underscoring the importance of this task for embodied AI, robotics, and physics-aware generative modeling. Do-Undo establishes an intuitive testbed for evaluating and advancing physical reasoning in multimodal systems.",
    "published": "2025-12-15T18:03:42Z",
    "authors": [
      "Shweta Mahajan",
      "Shreya Kadambi",
      "Hoang Le",
      "Munawar Hayat",
      "Fatih Porikli"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13608",
    "title": "DBT-DINO: Towards Foundation model based analysis of Digital Breast Tomosynthesis",
    "abstract": "Foundation models have shown promise in medical imaging but remain underexplored for three-dimensional imaging modalities. No foundation model currently exists for Digital Breast Tomosynthesis (DBT), despite its use for breast cancer screening.   To develop and evaluate a foundation model for DBT (DBT-DINO) across multiple clinical tasks and assess the impact of domain-specific pre-training.   Self-supervised pre-training was performed using the DINOv2 methodology on over 25 million 2D slices from 487,975 DBT volumes from 27,990 patients. Three downstream tasks were evaluated: (1) breast density classification using 5,000 screening exams; (2) 5-year risk of developing breast cancer using 106,417 screening exams; and (3) lesion detection using 393 annotated volumes.   For breast density classification, DBT-DINO achieved an accuracy of 0.79 (95\\% CI: 0.76--0.81), outperforming both the MetaAI DINOv2 baseline (0.73, 95\\% CI: 0.70--0.76, p<.001) and DenseNet-121 (0.74, 95\\% CI: 0.71--0.76, p<.001). For 5-year breast cancer risk prediction, DBT-DINO achieved an AUROC of 0.78 (95\\% CI: 0.76--0.80) compared to DINOv2's 0.76 (95\\% CI: 0.74--0.78, p=.57). For lesion detection, DINOv2 achieved a higher average sensitivity of 0.67 (95\\% CI: 0.60--0.74) compared to DBT-DINO with 0.62 (95\\% CI: 0.53--0.71, p=.60). DBT-DINO demonstrated better performance on cancerous lesions specifically with a detection rate of 78.8\\% compared to Dinov2's 77.3\\%.   Using a dataset of unprecedented size, we developed DBT-DINO, the first foundation model for DBT. DBT-DINO demonstrated strong performance on breast density classification and cancer risk prediction. However, domain-specific pre-training showed variable benefits on the detection task, with ImageNet baseline outperforming DBT-DINO on general lesion detection, indicating that localized detection tasks require further methodological development.",
    "published": "2025-12-15T18:03:09Z",
    "authors": [
      "Felix J. Dorfner",
      "Manon A. Dorster",
      "Ryan Connolly",
      "Oscar Gentilhomme",
      "Edward Gibbs",
      "Steven Graham",
      "Seth Wander",
      "Thomas Schultz",
      "Manisha Bahl",
      "Dania Daye",
      "Albert E. Kim",
      "Christopher P. Bridge"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13607",
    "title": "Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models",
    "abstract": "Building general-purpose reasoning models with reinforcement learning (RL) entails substantial cross-domain heterogeneity, including large variation in inference-time response lengths and verification latency. Such variability complicates the RL infrastructure, slows training, and makes training curriculum (e.g., response length extension) and hyperparameter selection challenging. In this work, we propose cascaded domain-wise reinforcement learning (Cascade RL) to develop general-purpose reasoning models, Nemotron-Cascade, capable of operating in both instruct and deep thinking modes. Departing from conventional approaches that blend heterogeneous prompts from different domains, Cascade RL orchestrates sequential, domain-wise RL, reducing engineering complexity and delivering state-of-the-art performance across a wide range of benchmarks. Notably, RLHF for alignment, when used as a pre-step, boosts the model's reasoning ability far beyond mere preference optimization, and subsequent domain-wise RLVR stages rarely degrade the benchmark performance attained in earlier domains and may even improve it (see an illustration in Figure 1). Our 14B model, after RL, outperforms its SFT teacher, DeepSeek-R1-0528, on LiveCodeBench v5/v6/Pro and achieves silver-medal performance in the 2025 International Olympiad in Informatics (IOI). We transparently share our training and data recipes.",
    "published": "2025-12-15T18:02:35Z",
    "authors": [
      "Boxin Wang",
      "Chankyu Lee",
      "Nayeon Lee",
      "Sheng-Chieh Lin",
      "Wenliang Dai",
      "Yang Chen",
      "Yangyi Chen",
      "Zhuolin Yang",
      "Zihan Liu",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Wei Ping"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13604",
    "title": "LongVie 2: Multimodal Controllable Ultra-Long Video World Model",
    "abstract": "Building video world models upon pretrained video generation systems represents an important yet challenging step toward general spatiotemporal intelligence. A world model should possess three essential properties: controllability, long-term visual quality, and temporal consistency. To this end, we take a progressive approach-first enhancing controllability and then extending toward long-term, high-quality generation. We present LongVie 2, an end-to-end autoregressive framework trained in three stages: (1) Multi-modal guidance, which integrates dense and sparse control signals to provide implicit world-level supervision and improve controllability; (2) Degradation-aware training on the input frame, bridging the gap between training and long-term inference to maintain high visual quality; and (3) History-context guidance, which aligns contextual information across adjacent clips to ensure temporal consistency. We further introduce LongVGenBench, a comprehensive benchmark comprising 100 high-resolution one-minute videos covering diverse real-world and synthetic environments. Extensive experiments demonstrate that LongVie 2 achieves state-of-the-art performance in long-range controllability, temporal coherence, and visual fidelity, and supports continuous video generation lasting up to five minutes, marking a significant step toward unified video world modeling.",
    "published": "2025-12-15T17:59:58Z",
    "authors": [
      "Jianxiong Gao",
      "Zhaoxi Chen",
      "Xian Liu",
      "Junhao Zhuang",
      "Chengming Xu",
      "Jianfeng Feng",
      "Yu Qiao",
      "Yanwei Fu",
      "Chenyang Si",
      "Ziwei Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13600",
    "title": "DA-SSL: self-supervised domain adaptor to leverage foundational models in turbt histopathology slides",
    "abstract": "Recent deep learning frameworks in histopathology, particularly multiple instance learning (MIL) combined with pathology foundational models (PFMs), have shown strong performance. However, PFMs exhibit limitations on certain cancer or specimen types due to domain shifts - these cancer types were rarely used for pretraining or specimens contain tissue-based artifacts rarely seen within the pretraining population. Such is the case for transurethral resection of bladder tumor (TURBT), which are essential for diagnosing muscle-invasive bladder cancer (MIBC), but contain fragmented tissue chips and electrocautery artifacts and were not widely used in publicly available PFMs. To address this, we propose a simple yet effective domain-adaptive self-supervised adaptor (DA-SSL) that realigns pretrained PFM features to the TURBT domain without fine-tuning the foundational model itself. We pilot this framework for predicting treatment response in TURBT, where histomorphological features are currently underutilized and identifying patients who will benefit from neoadjuvant chemotherapy (NAC) is challenging. In our multi-center study, DA-SSL achieved an AUC of 0.77+/-0.04 in five-fold cross-validation and an external test accuracy of 0.84, sensitivity of 0.71, and specificity of 0.91 using majority voting. Our results demonstrate that lightweight domain adaptation with self-supervision can effectively enhance PFM-based MIL pipelines for clinically challenging histopathology tasks. Code is Available at https://github.com/zhanghaoyue/DA_SSL_TURBT.",
    "published": "2025-12-15T17:53:18Z",
    "authors": [
      "Haoyue Zhang",
      "Meera Chappidi",
      "Erolcan Sayar",
      "Helen Richards",
      "Zhijun Chen",
      "Lucas Liu",
      "Roxanne Wadia",
      "Peter A Humphrey",
      "Fady Ghali",
      "Alberto Contreras-Sanz",
      "Peter Black",
      "Jonathan Wright",
      "Stephanie Harmon",
      "Michael Haffner"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13598",
    "title": "Textual Gradients are a Flawed Metaphor for Automatic Prompt Optimization",
    "abstract": "A well-engineered prompt can increase the performance of large language models; automatic prompt optimization techniques aim to increase performance without requiring human effort to tune the prompts. One leading class of prompt optimization techniques introduces the analogy of textual gradients. We investigate the behavior of these textual gradient methods through a series of experiments and case studies. While such methods often result in a performance improvement, our experiments suggest that the gradient analogy does not accurately explain their behavior. Our insights may inform the selection of prompt optimization strategies, and development of new approaches.",
    "published": "2025-12-15T17:52:16Z",
    "authors": [
      "Daniel Melcer",
      "Qi Chen",
      "Wen-Hao Chiang",
      "Shweta Garg",
      "Pranav Garg",
      "Christian Bock"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13597",
    "title": "Lighting in Motion: Spatiotemporal HDR Lighting Estimation",
    "abstract": "We present Lighting in Motion (LiMo), a diffusion-based approach to spatiotemporal lighting estimation. LiMo targets both realistic high-frequency detail prediction and accurate illuminance estimation. To account for both, we propose generating a set of mirrored and diffuse spheres at different exposures, based on their 3D positions in the input. Making use of diffusion priors, we fine-tune powerful existing diffusion models on a large-scale customized dataset of indoor and outdoor scenes, paired with spatiotemporal light probes. For accurate spatial conditioning, we demonstrate that depth alone is insufficient and we introduce a new geometric condition to provide the relative position of the scene to the target 3D position. Finally, we combine diffuse and mirror predictions at different exposures into a single HDRI map leveraging differentiable rendering. We thoroughly evaluate our method and design choices to establish LiMo as state-of-the-art for both spatial control and prediction accuracy.",
    "published": "2025-12-15T17:49:22Z",
    "authors": [
      "Christophe Bolduc",
      "Julien Philip",
      "Li Ma",
      "Mingming He",
      "Paul Debevec",
      "Jean-François Lalonde"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13593",
    "title": "Scalable Formal Verification via Autoencoder Latent Space Abstraction",
    "abstract": "Finite Abstraction methods provide a powerful formal framework for proving that systems satisfy their specifications. However, these techniques face scalability challenges for high-dimensional systems, as they rely on state-space discretization which grows exponentially with dimension. Learning-based approaches to dimensionality reduction, utilizing neural networks and autoencoders, have shown great potential to alleviate this problem. However, ensuring the correctness of the resulting verification results remains an open question. In this work, we provide a formal approach to reduce the dimensionality of systems via convex autoencoders and learn the dynamics in the latent space through a kernel-based method. We then construct a finite abstraction from the learned model in the latent space and guarantee that the abstraction contains the true behaviors of the original system. We show that the verification results in the latent space can be mapped back to the original system. Finally, we demonstrate the effectiveness of our approach on multiple systems, including a 26D system controlled by a neural network, showing significant scalability improvements without loss of rigor.",
    "published": "2025-12-15T17:48:07Z",
    "authors": [
      "Robert Reed",
      "Morteza Lahijanian",
      "Luca Laurenti"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13592",
    "title": "Image Diffusion Preview with Consistency Solver",
    "abstract": "The slow inference process of image diffusion models significantly degrades interactive user experiences. To address this, we introduce Diffusion Preview, a novel paradigm employing rapid, low-step sampling to generate preliminary outputs for user evaluation, deferring full-step refinement until the preview is deemed satisfactory. Existing acceleration methods, including training-free solvers and post-training distillation, struggle to deliver high-quality previews or ensure consistency between previews and final outputs. We propose ConsistencySolver derived from general linear multistep methods, a lightweight, trainable high-order solver optimized via Reinforcement Learning, that enhances preview quality and consistency. Experimental results demonstrate that ConsistencySolver significantly improves generation quality and consistency in low-step scenarios, making it ideal for efficient preview-and-refine workflows. Notably, it achieves FID scores on-par with Multistep DPM-Solver using 47% fewer steps, while outperforming distillation baselines. Furthermore, user studies indicate our approach reduces overall user interaction time by nearly 50% while maintaining generation quality. Code is available at https://github.com/G-U-N/consolver.",
    "published": "2025-12-15T17:47:49Z",
    "authors": [
      "Fu-Yun Wang",
      "Hao Zhou",
      "Liangzhe Yuan",
      "Sanghyun Woo",
      "Boqing Gong",
      "Bohyung Han",
      "Ming-Hsuan Yang",
      "Han Zhang",
      "Yukun Zhu",
      "Ting Liu",
      "Long Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13591",
    "title": "astroCAMP: A Community Benchmark and Co-Design Framework for Sustainable SKA-Scale Radio Imaging",
    "abstract": "The Square Kilometre Array (SKA) project will operate one of the world's largest continuous scientific data systems, sustaining petascale imaging under strict power caps. Yet, current radio-interferometric pipelines utilize only a small fraction of hardware peak performance, typically 4-14%, due to memory and I/O bottlenecks, resulting in poor energy efficiency and high operational and carbon costs. Progress is further limited by the absence of standardised metrics and fidelity tolerances, preventing principled hardware-software co-design and rigorous exploration of quality-efficiency trade-offs. We introduce astroCAMP, a framework for guiding the co-design of next-generation imaging pipelines and sustainable HPC architectures that maximise scientific return within SKA's operational and environmental limits. astroCAMP provides: (1) a unified, extensible metric suite covering scientific fidelity, computational performance, sustainability, and lifecycle economics; (2) standardised SKA-representative datasets and reference outputs enabling reproducible benchmarking across CPUs, GPUs, and emerging accelerators; and (3) a multi-objective co-design formulation linking scientific-quality constraints to time-, energy-, carbon-to-solution, and total cost of ownership. We release datasets, benchmarking results, and a reproducibility kit, and evaluate co-design metrics for WSClean and IDG on an AMD EPYC 9334 processor and an NVIDIA H100 GPU. Further, we illustrate the use of astroCAMP for heterogeneous CPU-FPGA design-space exploration, and its potential to facilitate the identification of Pareto-optimal operating points for SKA-scale imaging deployments. Last, we make a call to the SKA community to define quantifiable fidelity metrics and thresholds to accelerate principled optimisation for SKA-scale imaging.",
    "published": "2025-12-15T17:47:28Z",
    "authors": [
      "Denisa-Andreea Constantinescu",
      "Rubén Rodríguez Álvarez",
      "Jacques Morin",
      "Etienne Orliac",
      "Mickaël Dardaillon",
      "Sunrise Wang",
      "Hugo Miomandre",
      "Miguel Peón-Quirós",
      "Jean-François Nezan",
      "David Atienza"
    ],
    "categories": [
      "cs.DC",
      "astro-ph.IM",
      "cs.PF"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13586",
    "title": "ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding",
    "abstract": "Autoregressive models (ARMs) are hindered by slow sequential inference. While masked diffusion models (MDMs) offer a parallel alternative, they suffer from critical drawbacks: high computational overhead from precluding Key-Value (KV) caching, and incoherent generation arising from learning dependencies over an intractable space of token combinations. To address these limitations, we introduce ReFusion, a novel masked diffusion model that achieves superior performance and efficiency by elevating parallel decoding from the token level to a higher slot level, where each slot is a fixed-length, contiguous sub-sequence. This is achieved through an iterative ``plan-and-infill'' decoding process: a diffusion-based planning step first identifies a set of weakly dependent slots, and an autoregressive infilling step then decodes these selected slots in parallel. The slot-based design simultaneously unlocks full KV cache reuse with a unified causal framework and reduces the learning complexity from the token combination space to a manageable slot-level permutation space. Extensive experiments on seven diverse benchmarks show that ReFusion not only overwhelmingly surpasses prior MDMs with 34% performance gains and an over 18$\\times$ speedup on average, but also bridges the performance gap to strong ARMs while maintaining a 2.33$\\times$ average speedup.",
    "published": "2025-12-15T17:41:19Z",
    "authors": [
      "Jia-Nan Li",
      "Jian Guan",
      "Wei Wu",
      "Chongxuan Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13583",
    "title": "DP-CSGP: Differentially Private Stochastic Gradient Push with Compressed Communication",
    "abstract": "In this paper, we propose a Differentially Private Stochastic Gradient Push with Compressed communication (termed DP-CSGP) for decentralized learning over directed graphs. Different from existing works, the proposed algorithm is designed to maintain high model utility while ensuring both rigorous differential privacy (DP) guarantees and efficient communication. For general non-convex and smooth objective functions, we show that the proposed algorithm achieves a tight utility bound of $\\mathcal{O}\\left( \\sqrt{d\\log \\left( \\frac{1}δ \\right)}/(\\sqrt{n}Jε) \\right)$ ($J$ and $d$ are the number of local samples and the dimension of decision variables, respectively) with $\\left(ε, δ\\right)$-DP guarantee for each node, matching that of decentralized counterparts with exact communication. Extensive experiments on benchmark tasks show that, under the same privacy budget, DP-CSGP achieves comparable model accuracy with significantly lower communication cost than existing decentralized counterparts with exact communication.",
    "published": "2025-12-15T17:37:02Z",
    "authors": [
      "Zehan Zhu",
      "Heng Zhao",
      "Yan Huang",
      "Joey Tianyi Zhou",
      "Shouling Ji",
      "Jinming Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13576",
    "title": "Reproducing and Dissecting Denoising Language Models for Speech Recognition",
    "abstract": "Denoising language models (DLMs) have been proposed as a powerful alternative to traditional language models (LMs) for automatic speech recognition (ASR), motivated by their ability to use bidirectional context and adapt to a specific ASR model's error patterns. However, the complexity of the DLM training pipeline has hindered wider investigation. This paper presents the first independent, large-scale empirical study of DLMs. We build and release a complete, reproducible pipeline to systematically investigate the impact of key design choices. We evaluate dozens of configurations across multiple axes, including various data augmentation techniques (e.g., SpecAugment, dropout, mixup), different text-to-speech systems, and multiple decoding strategies. Our comparative analysis in a common subword vocabulary setting demonstrates that DLMs outperform traditional LMs, but only after a distinct compute tipping point. While LMs are more efficient at lower budgets, DLMs scale better with longer training, mirroring behaviors observed in diffusion language models. However, we observe smaller improvements than those reported in prior character-based work, which indicates that the DLM's performance is conditional on factors such as the vocabulary. Our analysis reveals that a key factor for improving performance is to condition the DLM on richer information from the ASR's hypothesis space, rather than just a single best guess. To this end, we introduce DLM-sum, a novel method for decoding from multiple ASR hypotheses, which consistently outperforms the previously proposed DSR decoding method. We believe our findings and public pipeline provide a crucial foundation for the community to better understand, improve, and build upon this promising class of models. The code is publicly available at https://github.com/rwth-i6/2025-denoising-lm/.",
    "published": "2025-12-15T17:33:22Z",
    "authors": [
      "Dorian Koch",
      "Albert Zeyer",
      "Nick Rossenbach",
      "Ralf Schlüter",
      "Hermann Ney"
    ],
    "categories": [
      "cs.NE"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13573",
    "title": "MMhops-R1: Multimodal Multi-hop Reasoning",
    "abstract": "The ability to perform multi-modal multi-hop reasoning by iteratively integrating information across various modalities and external knowledge is critical for addressing complex real-world challenges. However, existing Multi-modal Large Language Models (MLLMs) are predominantly limited to single-step reasoning, as existing benchmarks lack the complexity needed to evaluate and drive multi-hop abilities. To bridge this gap, we introduce MMhops, a novel, large-scale benchmark designed to systematically evaluate and foster multi-modal multi-hop reasoning. MMhops dataset comprises two challenging task formats, Bridging and Comparison, which necessitate that models dynamically construct complex reasoning chains by integrating external knowledge. To tackle the challenges posed by MMhops, we propose MMhops-R1, a novel multi-modal Retrieval-Augmented Generation (mRAG) framework for dynamic reasoning. Our framework utilizes reinforcement learning to optimize the model for autonomously planning reasoning paths, formulating targeted queries, and synthesizing multi-level information. Comprehensive experiments demonstrate that MMhops-R1 significantly outperforms strong baselines on MMhops, highlighting that dynamic planning and multi-modal knowledge integration are crucial for complex reasoning. Moreover, MMhops-R1 demonstrates strong generalization to tasks requiring fixed-hop reasoning, underscoring the robustness of our dynamic planning approach. In conclusion, our work contributes a challenging new benchmark and a powerful baseline model, and we will release the associated code, data, and weights to catalyze future research in this critical area.",
    "published": "2025-12-15T17:29:02Z",
    "authors": [
      "Tao Zhang",
      "Ziqi Zhang",
      "Zongyang Ma",
      "Yuxin Chen",
      "Bing Li",
      "Chunfeng Yuan",
      "Guangting Wang",
      "Fengyun Rao",
      "Ying Shan",
      "Weiming Hu"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13568",
    "title": "Superposition as Lossy Compression: Measure with Sparse Autoencoders and Connect to Adversarial Vulnerability",
    "abstract": "Neural networks achieve remarkable performance through superposition: encoding multiple features as overlapping directions in activation space rather than dedicating individual neurons to each feature. This challenges interpretability, yet we lack principled methods to measure superposition. We present an information-theoretic framework measuring a neural representation's effective degrees of freedom. We apply Shannon entropy to sparse autoencoder activations to compute the number of effective features as the minimum neurons needed for interference-free encoding. Equivalently, this measures how many \"virtual neurons\" the network simulates through superposition. When networks encode more effective features than actual neurons, they must accept interference as the price of compression. Our metric strongly correlates with ground truth in toy models, detects minimal superposition in algorithmic tasks, and reveals systematic reduction under dropout. Layer-wise patterns mirror intrinsic dimensionality studies on Pythia-70M. The metric also captures developmental dynamics, detecting sharp feature consolidation during grokking. Surprisingly, adversarial training can increase effective features while improving robustness, contradicting the hypothesis that superposition causes vulnerability. Instead, the effect depends on task complexity and network capacity: simple tasks with ample capacity allow feature expansion (abundance regime), while complex tasks or limited capacity force reduction (scarcity regime). By defining superposition as lossy compression, this work enables principled measurement of how neural networks organize information under computational constraints, connecting superposition to adversarial robustness.",
    "published": "2025-12-15T17:25:39Z",
    "authors": [
      "Leonard Bereska",
      "Zoe Tzifa-Kratira",
      "Reza Samavi",
      "Efstratios Gavves"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13565",
    "title": "A Nonparametric Statistics Approach to Feature Selection in Deep Neural Networks with Theoretical Guarantees",
    "abstract": "This paper tackles the problem of feature selection in a highly challenging setting: $\\mathbb{E}(y | \\boldsymbol{x}) = G(\\boldsymbol{x}_{\\mathcal{S}_0})$, where $\\mathcal{S}_0$ is the set of relevant features and $G$ is an unknown, potentially nonlinear function subject to mild smoothness conditions. Our approach begins with feature selection in deep neural networks, then generalizes the results to H{ö}lder smooth functions by exploiting the strong approximation capabilities of neural networks. Unlike conventional optimization-based deep learning methods, we reformulate neural networks as index models and estimate $\\mathcal{S}_0$ using the second-order Stein's formula. This gradient-descent-free strategy guarantees feature selection consistency with a sample size requirement of $n = Ω(p^2)$, where $p$ is the feature dimension. To handle high-dimensional scenarios, we further introduce a screening-and-selection mechanism that achieves nonlinear selection consistency when $n = Ω(s \\log p)$, with $s$ representing the sparsity level. Additionally, we refit a neural network on the selected features for prediction and establish performance guarantees under a relaxed sparsity assumption. Extensive simulations and real-data analyses demonstrate the strong performance of our method even in the presence of complex feature interactions.",
    "published": "2025-12-15T17:22:49Z",
    "authors": [
      "Junye Du",
      "Zhenghao Li",
      "Zhutong Gu",
      "Long Feng"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13564",
    "title": "Memory in the Age of AI Agents",
    "abstract": "Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary agent memory systems. This work aims to provide an up-to-date landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-agent memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence.",
    "published": "2025-12-15T17:22:34Z",
    "authors": [
      "Yuyang Hu",
      "Shichun Liu",
      "Yanwei Yue",
      "Guibin Zhang",
      "Boyang Liu",
      "Fangyi Zhu",
      "Jiahang Lin",
      "Honglin Guo",
      "Shihan Dou",
      "Zhiheng Xi",
      "Senjie Jin",
      "Jiejun Tan",
      "Yanbin Yin",
      "Jiongnan Liu",
      "Zeyu Zhang",
      "Zhongxiang Sun",
      "Yutao Zhu",
      "Hao Sun",
      "Boci Peng",
      "Zhenrong Cheng",
      "Xuanbo Fan",
      "Jiaxin Guo",
      "Xinlei Yu",
      "Zhenhong Zhou",
      "Zewen Hu",
      "Jiahao Huo",
      "Junhao Wang",
      "Yuwei Niu",
      "Yu Wang",
      "Zhenfei Yin",
      "Xiaobin Hu",
      "Yue Liao",
      "Qiankun Li",
      "Kun Wang",
      "Wangchunshu Zhou",
      "Yixin Liu",
      "Dawei Cheng",
      "Qi Zhang",
      "Tao Gui",
      "Shirui Pan",
      "Yan Zhang",
      "Philip Torr",
      "Zhicheng Dou",
      "Ji-Rong Wen",
      "Xuanjing Huang",
      "Yu-Gang Jiang",
      "Shuicheng Yan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13560",
    "title": "3D Human-Human Interaction Anomaly Detection",
    "abstract": "Human-centric anomaly detection (AD) has been primarily studied to specify anomalous behaviors in a single person. However, as humans by nature tend to act in a collaborative manner, behavioral anomalies can also arise from human-human interactions. Detecting such anomalies using existing single-person AD models is prone to low accuracy, as these approaches are typically not designed to capture the complex and asymmetric dynamics of interactions. In this paper, we introduce a novel task, Human-Human Interaction Anomaly Detection (H2IAD), which aims to identify anomalous interactive behaviors within collaborative 3D human actions. To address H2IAD, we then propose Interaction Anomaly Detection Network (IADNet), which is formalized with a Temporal Attention Sharing Module (TASM). Specifically, in designing TASM, we share the encoded motion embeddings across both people such that collaborative motion correlations can be effectively synchronized. Moreover, we notice that in addition to temporal dynamics, human interactions are also characterized by spatial configurations between two people. We thus introduce a Distance-Based Relational Encoding Module (DREM) to better reflect social cues in H2IAD. The normalizing flow is eventually employed for anomaly scoring. Extensive experiments on human-human motion benchmarks demonstrate that IADNet outperforms existing Human-centric AD baselines in H2IAD.",
    "published": "2025-12-15T17:17:55Z",
    "authors": [
      "Shun Maeda",
      "Chunzhi Gu",
      "Koichiro Kamide",
      "Katsuya Hotta",
      "Shangce Gao",
      "Chao Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13559",
    "title": "Verifying Rumors via Stance-Aware Structural Modeling",
    "abstract": "Verifying rumors on social media is critical for mitigating the spread of false information. The stances of conversation replies often provide important cues to determine a rumor's veracity. However, existing models struggle to jointly capture semantic content, stance information, and conversation strructure, especially under the sequence length constraints of transformer-based encoders. In this work, we propose a stance-aware structural modeling that encodes each post in a discourse with its stance signal and aggregates reply embedddings by stance category enabling a scalable and semantically enriched representation of the entire thread. To enhance structural awareness, we introduce stance distribution and hierarchical depth as covariates, capturing stance imbalance and the influence of reply depth. Extensive experiments on benchmark datasets demonstrate that our approach significantly outperforms prior methods in the ability to predict truthfulness of a rumor. We also demonstrate that our model is versatile for early detection and cross-platfrom generalization.",
    "published": "2025-12-15T17:16:56Z",
    "authors": [
      "Gibson Nkhata",
      "Uttamasha Anjally Oyshi",
      "Quan Mai",
      "Susan Gauch"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13552",
    "title": "PrahokBART: A Pre-trained Sequence-to-Sequence Model for Khmer Natural Language Generation",
    "abstract": "This work introduces {\\it PrahokBART}, a compact pre-trained sequence-to-sequence model trained from scratch for Khmer using carefully curated Khmer and English corpora. We focus on improving the pre-training corpus quality and addressing the linguistic issues of Khmer, which are ignored in existing multilingual models, by incorporating linguistic components such as word segmentation and normalization. We evaluate PrahokBART on three generative tasks: machine translation, text summarization, and headline generation, where our results demonstrate that it outperforms mBART50, a strong multilingual pre-trained model. Additionally, our analysis provides insights into the impact of each linguistic module and evaluates how effectively our model handles space during text generation, which is crucial for the naturalness of texts in Khmer.",
    "published": "2025-12-15T17:11:31Z",
    "authors": [
      "Hour Kaing",
      "Raj Dabre",
      "Haiyue Song",
      "Van-Hien Tran",
      "Hideki Tanaka",
      "Masao Utiyama"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13534",
    "title": "Pancakes: Consistent Multi-Protocol Image Segmentation Across Biomedical Domains",
    "abstract": "A single biomedical image can be meaningfully segmented in multiple ways, depending on the desired application. For instance, a brain MRI can be segmented according to tissue types, vascular territories, broad anatomical regions, fine-grained anatomy, or pathology, etc. Existing automatic segmentation models typically either (1) support only a single protocol, the one they were trained on, or (2) require labor-intensive manual prompting to specify the desired segmentation. We introduce Pancakes, a framework that, given a new image from a previously unseen domain, automatically generates multi-label segmentation maps for multiple plausible protocols, while maintaining semantic consistency across related images. Pancakes introduces a new problem formulation that is not currently attainable by existing foundation models. In a series of experiments on seven held-out datasets, we demonstrate that our model can significantly outperform existing foundation models in producing several plausible whole-image segmentations, that are semantically coherent across images.",
    "published": "2025-12-15T17:00:21Z",
    "authors": [
      "Marianne Rakic",
      "Siyu Gai",
      "Etienne Chollet",
      "John V. Guttag",
      "Adrian V. Dalca"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13532",
    "title": "Adaptive Sampling for Hydrodynamic Stability",
    "abstract": "An adaptive sampling approach for efficient detection of bifurcation boundaries in parametrized fluid flow problems is presented herein. The study extends the machine-learning approach of Silvester (Machine Learning for Hydrodynamic Stability, arXiv:2407.09572), where a classifier network was trained on preselected simulation data to identify bifurcated and nonbifurcated flow regimes. In contrast, the proposed methodology introduces adaptivity through a flow-based deep generative model that automatically refines the sampling of the parameter space. The strategy has two components: a classifier network maps the flow parameters to a bifurcation probability, and a probability density estimation technique (KRnet) for the generation of new samples at each adaptive step. The classifier output provides a probabilistic measure of flow stability, and the Shannon entropy of these predictions is employed as an uncertainty indicator. KRnet is trained to approximate a probability density function that concentrates sampling in regions of high entropy, thereby directing computational effort towards the evolving bifurcation boundary. This coupling between classification and generative modeling establishes a feedback-driven adaptive learning process analogous to error-indicator based refinement in contemporary partial differential equation solution strategies. Starting from a uniform parameter distribution, the new approach achieves accurate bifurcation boundary identification with significantly fewer Navier--Stokes simulations, providing a scalable foundation for high-dimensional stability analysis.",
    "published": "2025-12-15T17:00:09Z",
    "authors": [
      "Anshima Singh",
      "David J. Silvester"
    ],
    "categories": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13530",
    "title": "Actively Learning Joint Contours of Multiple Computer Experiments",
    "abstract": "Contour location$\\unicode{x2014}$the process of sequentially training a surrogate model to identify the design inputs that result in a pre-specified response value from a single computer experiment$\\unicode{x2014}$is a well-studied active learning problem. Here, we tackle a related but distinct problem: identifying the input configuration that returns pre-specified values of multiple independent computer experiments simultaneously. Motivated by computer experiments of the rotational torques acting upon a vehicle in flight, we aim to identify stable flight conditions which result in zero torque forces. We propose a \"joint contour location\" (jCL) scheme that strikes a strategic balance between exploring the multiple response surfaces while exploiting learning of the intersecting contours. We employ both shallow and deep Gaussian process surrogates, but our jCL procedure is applicable to any surrogate that can provide posterior predictive distributions. Our jCL designs significantly outperform existing (single response) CL strategies, enabling us to efficiently locate the joint contour of our motivating computer experiments.",
    "published": "2025-12-15T17:00:04Z",
    "authors": [
      "Shih-Ni Prim",
      "Kevin R. Quinlan",
      "Paul Hawkins",
      "Jagadeesh Movva",
      "Annie S. Booth"
    ],
    "categories": [
      "stat.ME",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13529",
    "title": "Enhancing lithological interpretation from petrophysical well log of IODP expedition 390/393 using machine learning",
    "abstract": "Enhanced lithological interpretation from well logs plays a key role in geological resource exploration and mapping, as well as in geo-environmental modeling studies. Core and cutting information is useful for making sound interpretations of well logs; however, these are rarely collected at each depth due to high costs. Moreover, well log interpretation using traditional methods is constrained by poor borehole conditions. Traditional statistical methods are mostly linear, often failing to discriminate between lithology and rock facies, particularly when dealing with overlapping well log signals characterized by the structural and compositional variation of rock types. In this study, we develop multiple supervised and unsupervised machine learning algorithms to jointly analyze multivariate well log data from Integrated Ocean Drilling Program (IODP) expeditions 390 and 393 for enhanced lithological interpretations. Among the algorithms, Logistic Regression, Decision Trees, Gradient Boosting, Support Vector Machines (SVM), k-Nearest Neighbors (KNN), and Multi-Layer Perceptron (MLP) neural network models, the Decision Tree and Gradient Boosting models outperformed the others, achieving an accuracy of 0.9950 and an F1-score of 0.9951. While unsupervised machine learning (ML) provides the foundation for cluster information that inherently supports the classification algorithm, supervised ML is applied to devise a data-driven lithology clustering mechanism for IODP datasets. The joint ML-based method developed here has the potential to be further explored for analyzing other well log datasets from the world's oceans.",
    "published": "2025-12-15T16:59:13Z",
    "authors": [
      "Raj Sahu",
      "Saumen Maiti"
    ],
    "categories": [
      "physics.geo-ph",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13526",
    "title": "Async Control: Stress-testing Asynchronous Control Measures for LLM Agents",
    "abstract": "LLM-based software engineering agents are increasingly used in real-world development tasks, often with access to sensitive data or security-critical codebases. Such agents could intentionally sabotage these codebases if they were misaligned. We investigate asynchronous monitoring, in which a monitoring system reviews agent actions after the fact. Unlike synchronous monitoring, this approach does not impose runtime latency, while still attempting to disrupt attacks before irreversible harm occurs. We treat monitor development as an adversarial game between a blue team (who design monitors) and a red team (who create sabotaging agents). We attempt to set the game rules such that they upper bound the sabotage potential of an agent based on Claude 4.1 Opus. To ground this game in a realistic, high-stakes deployment scenario, we develop a suite of 5 diverse software engineering environments that simulate tasks that an agent might perform within an AI developer's internal infrastructure. Over the course of the game, we develop an ensemble monitor that achieves a 6% false negative rate at 1% false positive rate on a held out test environment. Then, we estimate risk of sabotage at deployment time by extrapolating from our monitor's false negative rate. We describe one simple model for this extrapolation, present a sensitivity analysis, and describe situations in which the model would be invalid. Code is available at: https://github.com/UKGovernmentBEIS/async-control.",
    "published": "2025-12-15T16:56:28Z",
    "authors": [
      "Asa Cooper Stickland",
      "Jan Michelfeit",
      "Arathi Mani",
      "Charlie Griffin",
      "Ollie Matthews",
      "Tomek Korbak",
      "Rogan Inglis",
      "Oliver Makins",
      "Alan Cooney"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13525",
    "title": "Janus: Disaggregating Attention and Experts for Scalable MoE Inference",
    "abstract": "Large Mixture-of-Experts (MoE) model inference is challenging due to high resource demands and dynamic workloads. Existing solutions often deploy the entire model as a single monolithic unit, which applies a unified resource configuration to both attention and expert modules despite their different requirements, leading to limited scalability and resource inefficiency. In this paper, we propose Janus, a scalable MoE inference system that disaggregates attention and experts on separate GPU sub-clusters, enabling each module to be managed and scaled independently. Janus incorporates three key designs for efficient, disaggregated MoE inference. First, it proposes an adaptive two-phase communication scheme that exploits intra- and inter-node bandwidth hierarchies for low-latency data exchange. Second, motivated by the memory-bound nature of MoE modules, Janus introduces a lightweight scheduler and implements it as a GPU kernel to balance the number of activated experts across GPUs at minimal overhead, thereby reducing inference latency. Third, Janus performs fine-grained resource management to dynamically adjust expert placement and independently scale attention and MoE resources to improve overall efficiency. Evaluation shows Janus achieves up to 3.9 higher perGPU throughput than state-of-the-art systems while meeting per-token latency requirements.",
    "published": "2025-12-15T16:53:49Z",
    "authors": [
      "Zhexiang Zhang",
      "Ye Wang",
      "Xiangyu Wang",
      "Yumiao Zhao",
      "Jingzhe Jiang",
      "Qizhen Weng",
      "Shaohuai Shi",
      "Yin Chen",
      "Minchen Yu"
    ],
    "categories": [
      "cs.DC"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13524",
    "title": "How Low Can You Go? The Data-Light SE Challenge",
    "abstract": "Much of software engineering (SE) research assumes that progress depends on massive datasets and CPU-intensive optimizers. Yet has this assumption been rigorously tested?   The counter-evidence presented in this paper suggests otherwise: across dozens of optimization problems from recent SE literature, including software configuration and performance tuning, cloud and systems optimization, project and process-level decision modeling, behavioral analytics, financial risk modeling, project health prediction, reinforcement learning tasks, sales forecasting, and software testing, even with just a few dozen labels, very simple methods (e.g. diversity sampling, a minimal Bayesian learner, or random probes) achieve near 90% of the best reported results. Further, these simple methods perform just as well as more state-of-the-the-art optimizers like SMAC, TPE, DEHB etc. While some tasks would require better outcomes and more sampling, these results seen after a few dozen samples would suffice for many engineering needs (particularly when the goal is rapid and cost-efficient guidance rather than slow and exhaustive optimization).   Our results highlight that some SE tasks may be better served by lightweight approaches that demand fewer labels and far less computation. We hence propose the data-light challenge: when will a handful of labels suffice for SE tasks? To enable a large-scale investigation of this issue, we contribute (1) a mathematical formalization of labeling, (2) lightweight baseline algorithms, and (3) results on public-domain data showing the conditions under which lightweight methods excel or fail.   For the purposes of open science, our scripts and data are online at https://github.com/KKGanguly/NEO .",
    "published": "2025-12-15T16:49:50Z",
    "authors": [
      "Kishan Kumar Ganguly",
      "Tim Menzies"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13517",
    "title": "A Deep Learning Model of Mental Rotation Informed by Interactive VR Experiments",
    "abstract": "Mental rotation -- the ability to compare objects seen from different viewpoints -- is a fundamental example of mental simulation and spatial world modelling in humans. Here we propose a mechanistic model of human mental rotation, leveraging advances in deep, equivariant, and neuro-symbolic learning. Our model consists of three stacked components: (1) an equivariant neural encoder, taking images as input and producing 3D spatial representations of objects, (2) a neuro-symbolic object encoder, deriving symbolic descriptions of objects from these spatial representations, and (3) a neural decision agent, comparing these symbolic descriptions to prescribe rotation simulations in 3D latent space via a recurrent pathway. Our model design is guided by the abundant experimental literature on mental rotation, which we complemented with experiments in VR where participants could at times manipulate the objects to compare, providing us with additional insights into the cognitive process of mental rotation. Our model captures well the performance, response times and behavior of participants in our and others' experiments. The necessity of each model component is shown through systematic ablations. Our work adds to a recent collection of deep neural models of human spatial reasoning, further demonstrating the potency of integrating deep, equivariant, and symbolic representations to model the human mind.",
    "published": "2025-12-15T16:43:50Z",
    "authors": [
      "Raymond Khazoum",
      "Daniela Fernandes",
      "Aleksandr Krylov",
      "Qin Li",
      "Stephane Deny"
    ],
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13515",
    "title": "Fine-tuned LLM-based Code Migration Framework",
    "abstract": "The study presents the outcomes of research and experimental validation in the domain of automated codebase migration, with a focus on addressing challenges in transitioning SQL-based systems. The proposed method for migration essentially appears as a framework that leverages the best aspects of traditional software engineering techniques and provides an iterative, scalable, precise and efficient solution for modern database transformations. The central piece of the approach is the integration of a fine-tuned Large Language Model to address critical issues in SQL code conversion, such as syntax mapping, resolving discrepancies between Oracle PL/SQL and PostgreSQL, and optimising database elements such as stored procedures, triggers, views, and overall database logic. Thus, the method involves a trade-off between fine-tuning and prompt engineering. Special attention is given to a fine-tuning approach, which enhances the adaptability and compatibility with migration requirements across the entire database. According to the achieved results, fine-tuning plays a very important role. The study employs targeted evaluation methodologies along with computational metrics to measure the success of iterative conversion cycles. Core innovations include automated SQL feature detection, semi-supervised error analysis and integration of Subject Matter Experts feedback within a systematic migration workflow. The methodology achieves significant reductions in Syntax Error Rates, enhances feature alignment throughout migration iterations, and leverages dataset sampling to ensure continual improvement. By embedding GAI into the migration process, the framework facilitates precise feature mapping, semi-automated error resolution, and data-driven optimisation loops, improving workflow efficiency.",
    "published": "2025-12-15T16:42:51Z",
    "authors": [
      "Oleg Grynets",
      "Vasyl Lyashkevych",
      "Dmytro Baran",
      "Maksym Orliansky",
      "Taras Zelenyy",
      "Markiian Leshchyshyn"
    ],
    "categories": [
      "cs.SE",
      "cs.CL",
      "cs.LO"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13511",
    "title": "TARA: Simple and Efficient Time Aware Retrieval Adaptation of MLLMs for Video Understanding",
    "abstract": "Our objective is to build a general time-aware video-text embedding model for retrieval. To that end, we propose a simple and efficient recipe, dubbed TARA (Time Aware Retrieval Adaptation), to adapt Multimodal LLMs (MLLMs) to a time-aware video-text embedding model without using any video data at all. For evaluating time-awareness in retrieval, we propose a new benchmark with temporally opposite (chiral) actions as hard negatives and curated splits for chiral and non-chiral actions. We show that TARA outperforms all existing video-text models on this chiral benchmark while also achieving strong results on standard benchmarks. Furthermore, we discover additional benefits of TARA beyond time-awareness: (i) TARA embeddings are negation-aware as shown in NegBench benchmark that evaluates negation in video retrieval, (ii) TARA achieves state of the art performance on verb and adverb understanding in videos. Overall, TARA yields a strong, versatile, time-aware video-text embedding model with state of the art zero-shot performance.",
    "published": "2025-12-15T16:38:59Z",
    "authors": [
      "Piyush Bagad",
      "Andrew Zisserman"
    ],
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13510",
    "title": "MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph",
    "abstract": "Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.",
    "published": "2025-12-15T16:38:46Z",
    "authors": [
      "Linjie Mu",
      "Yannian Gu",
      "Zhongzhen Huang",
      "Yakun Zhu",
      "Shaoting Zhang",
      "Xiaofan Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13507",
    "title": "Seedance 1.5 pro: A Native Audio-Visual Joint Generation Foundation Model",
    "abstract": "Recent strides in video generation have paved the way for unified audio-visual generation. In this work, we present Seedance 1.5 pro, a foundational model engineered specifically for native, joint audio-video generation. Leveraging a dual-branch Diffusion Transformer architecture, the model integrates a cross-modal joint module with a specialized multi-stage data pipeline, achieving exceptional audio-visual synchronization and superior generation quality. To ensure practical utility, we implement meticulous post-training optimizations, including Supervised Fine-Tuning (SFT) on high-quality datasets and Reinforcement Learning from Human Feedback (RLHF) with multi-dimensional reward models. Furthermore, we introduce an acceleration framework that boosts inference speed by over 10X. Seedance 1.5 pro distinguishes itself through precise multilingual and dialect lip-syncing, dynamic cinematic camera control, and enhanced narrative coherence, positioning it as a robust engine for professional-grade content creation. Seedance 1.5 pro is now accessible on Volcano Engine at https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision?type=GenVideo.",
    "published": "2025-12-15T16:36:52Z",
    "authors": [
      "Siyan Chen",
      "Yanfei Chen",
      "Ying Chen",
      "Zhuo Chen",
      "Feng Cheng",
      "Xuyan Chi",
      "Jian Cong",
      "Qinpeng Cui",
      "Qide Dong",
      "Junliang Fan",
      "Jing Fang",
      "Zetao Fang",
      "Chengjian Feng",
      "Han Feng",
      "Mingyuan Gao",
      "Yu Gao",
      "Qiushan Guo",
      "Boyang Hao",
      "Qingkai Hao",
      "Bibo He",
      "Qian He",
      "Tuyen Hoang",
      "Ruoqing Hu",
      "Xi Hu",
      "Weilin Huang",
      "Zhaoyang Huang",
      "Zhongyi Huang",
      "Siqi Jiang",
      "Wei Jiang",
      "Yunpu Jiang",
      "Zhuo Jiang",
      "Ashley Kim",
      "Jianan Kong",
      "Zhichao Lai",
      "Shanshan Lao",
      "Ai Li",
      "Feiya Li",
      "Gen Li",
      "Huixia Li",
      "JiaShi Li",
      "Liang Li",
      "Ming Li",
      "Tao Li",
      "Xian Li",
      "Xiaojie Li",
      "Xiaoyang Li",
      "Xingxing Li",
      "Yameng Li",
      "Yifu Li",
      "Yiying Li",
      "Chao Liang",
      "Ying Liang",
      "Zhiqiang Liang",
      "Wang Liao",
      "Yalin Liao",
      "Heng Lin",
      "Kengyu Lin",
      "Shanchuan Lin",
      "Xi Lin",
      "Zhijie Lin",
      "Feng Ling",
      "Fangfang Liu",
      "Gaohong Liu",
      "Jiawei Liu",
      "Jie Liu",
      "Shouda Liu",
      "Shu Liu",
      "Sichao Liu",
      "Songwei Liu",
      "Xin Liu",
      "Xue Liu",
      "Yibo Liu",
      "Zikun Liu",
      "Zuxi Liu",
      "Junlin Lyu",
      "Lecheng Lyu",
      "Qian Lyu",
      "Han Mu",
      "Xiaonan Nie",
      "Jingzhe Ning",
      "Xitong Pan",
      "Yanghua Peng",
      "Lianke Qin",
      "Xueqiong Qu",
      "Yuxi Ren",
      "Yuchen Shen",
      "Guang Shi",
      "Lei Shi",
      "Yan Song",
      "Yinglong Song",
      "Fan Sun",
      "Li Sun",
      "Renfei Sun",
      "Zeyu Sun",
      "Wenjing Tang",
      "Zirui Tao",
      "Feng Wang",
      "Furui Wang",
      "Jinran Wang",
      "Junkai Wang",
      "Ke Wang",
      "Kexin Wang",
      "Qingyi Wang",
      "Rui Wang",
      "Sen Wang",
      "Shuai Wang",
      "Tingru Wang",
      "Weichen Wang",
      "Xin Wang",
      "Yanhui Wang",
      "Yue Wang",
      "Yuping Wang",
      "Yuxuan Wang",
      "Ziyu Wang",
      "Guoqiang Wei",
      "Wanru Wei",
      "Di Wu",
      "Guohong Wu",
      "Hanjie Wu",
      "Jian Wu",
      "Jie Wu",
      "Ruolan Wu",
      "Xinglong Wu",
      "Yonghui Wu",
      "Ruiqi Xia",
      "Liang Xiang",
      "Fei Xiao",
      "XueFeng Xiao",
      "Pan Xie",
      "Shuangyi Xie",
      "Shuang Xu",
      "Jinlan Xue",
      "Bangbang Yang",
      "Ceyuan Yang",
      "Jiaqi Yang",
      "Runkai Yang",
      "Tao Yang",
      "Yang Yang",
      "Yihang Yang",
      "ZhiXian Yang",
      "Ziyan Yang",
      "Yifan Yao",
      "Zilyu Ye",
      "Bowen Yu",
      "Chujie Yuan",
      "Linxiao Yuan",
      "Sichun Zeng",
      "Weihong Zeng",
      "Xuejiao Zeng",
      "Yan Zeng",
      "Chuntao Zhang",
      "Heng Zhang",
      "Jingjie Zhang",
      "Kuo Zhang",
      "Liang Zhang",
      "Liying Zhang",
      "Manlin Zhang",
      "Ting Zhang",
      "Weida Zhang",
      "Xiaohe Zhang",
      "Xinyan Zhang",
      "Yan Zhang",
      "Yuan Zhang",
      "Zixiang Zhang",
      "Fengxuan Zhao",
      "Huating Zhao",
      "Yang Zhao",
      "Hao Zheng",
      "Jianbin Zheng",
      "Xiaozheng Zheng",
      "Yangyang Zheng",
      "Yijie Zheng",
      "Jiexin Zhou",
      "Kuan Zhu",
      "Shenhan Zhu",
      "Wenjia Zhu",
      "Benhui Zou",
      "Feilong Zuo"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13506",
    "title": "Learning under Distributional Drift: Reproducibility as an Intrinsic Statistical Resource",
    "abstract": "Statistical learning under distributional drift remains insufficiently characterized: when each observation alters the data-generating law, classical generalization bounds can collapse. We introduce a new statistical primitive, the reproducibility budget $C_T$, which quantifies a system's finite capacity for statistical reproducibility - the extent to which its sampling process can remain governed by a consistent underlying distribution in the presence of both exogenous change and endogenous feedback. Formally, $C_T$ is defined as the cumulative Fisher-Rao path length of the coupled learner-environment evolution, measuring the total distributional motion accumulated during learning. From this construct we derive a drift-feedback generalization bound of order $O(T^{-1/2} + C_T/T)$, and we prove a matching minimax lower bound showing that this rate is minimax-optimal. Consequently, the results establish a reproducibility speed limit: no algorithm can achieve smaller worst-case generalization error than that imposed by the average Fisher-Rao drift rate $C_T/T$ of the data-generating process. The framework situates exogenous drift, adaptive data analysis, and performative prediction within a common geometric structure, with $C_T$ emerging as the intrinsic quantity measuring distributional motion across these settings.",
    "published": "2025-12-15T16:34:47Z",
    "authors": [
      "Sofiya Zaichyk"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13505",
    "title": "Defending the Hierarchical Result Models of Precedential Constraint",
    "abstract": "In recent years, hierarchical case-based-reasoning models of precedential constraint have been proposed. In various papers, Trevor Bench-Capon criticised these models on the grounds that they would give incorrect outcomes in some cases. In particular, the models would not account for the possibility that intermediate factors are established with different strengths by different base-level factors. In this paper we respond to these criticisms for van Woerkom's result-based hierarchical models. We argue that in some examples Bench-Capon seems to interpret intermediate factors as dimensions, and that applying van Woerkom's dimension-based version of the hierarchical result model to these examples avoids Bench-Capon's criticisms.",
    "published": "2025-12-15T16:33:33Z",
    "authors": [
      "Henry Prakken",
      "Wijnand van Woerkom"
    ],
    "categories": [
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13501",
    "title": "Behavior-Aware and Generalizable Defense Against Black-Box Adversarial Attacks for ML-Based IDS",
    "abstract": "Machine learning based intrusion detection systems are increasingly targeted by black box adversarial attacks, where attackers craft evasive inputs using indirect feedback such as binary outputs or behavioral signals like response time and resource usage. While several defenses have been proposed, including input transformation, adversarial training, and surrogate detection, they often fall short in practice. Most are tailored to specific attack types, require internal model access, or rely on static mechanisms that fail to generalize across evolving attack strategies. Furthermore, defenses such as input transformation can degrade intrusion detection system performance, making them unsuitable for real time deployment.   To address these limitations, we propose Adaptive Feature Poisoning, a lightweight and proactive defense mechanism designed specifically for realistic black box scenarios. Adaptive Feature Poisoning assumes that probing can occur silently and continuously, and introduces dynamic and context aware perturbations to selected traffic features, corrupting the attacker feedback loop without impacting detection capabilities. The method leverages traffic profiling, change point detection, and adaptive scaling to selectively perturb features that an attacker is likely exploiting, based on observed deviations.   We evaluate Adaptive Feature Poisoning against multiple realistic adversarial attack strategies, including silent probing, transferability based attacks, and decision boundary based attacks. The results demonstrate its ability to confuse attackers, degrade attack effectiveness, and preserve detection performance. By offering a generalizable, attack agnostic, and undetectable defense, Adaptive Feature Poisoning represents a significant step toward practical and robust adversarial resilience in machine learning based intrusion detection systems.",
    "published": "2025-12-15T16:29:23Z",
    "authors": [
      "Sabrine Ennaji",
      "Elhadj Benkhelifa",
      "Luigi Vincenzo Mancini"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13497",
    "title": "On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing",
    "abstract": "In modern manufacturing, Visual Anomaly Detection (VAD) is essential for automated inspection and consistent product quality. Yet, increasingly dynamic and flexible production environments introduce key challenges: First, frequent product changes in small-batch and on-demand manufacturing require rapid model updates. Second, legacy edge hardware lacks the resources to train and run large AI models. Finally, both anomalous and normal training data are often scarce, particularly for newly introduced product variations. We investigate on-device continual learning for unsupervised VAD with localization, extending the PatchCore to incorporate online learning for real-world industrial scenarios. The proposed method leverages a lightweight feature extractor and an incremental coreset update mechanism based on k-center selection, enabling rapid, memory-efficient adaptation from limited data while eliminating costly cloud retraining. Evaluations on an industrial use case are conducted using a testbed designed to emulate flexible production with frequent variant changes in a controlled environment. Our method achieves a 12% AUROC improvement over the baseline, an 80% reduction in memory usage, and faster training compared to batch retraining. These results confirm that our method delivers accurate, resource-efficient, and adaptive VAD suitable for dynamic and smart manufacturing.",
    "published": "2025-12-15T16:27:23Z",
    "authors": [
      "Haoyu Ren",
      "Kay Koehle",
      "Kirill Dorofeev",
      "Darko Anicic"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13495",
    "title": "Soul: Breathe Life into Digital Human for High-fidelity Long-term Multimodal Animation",
    "abstract": "We propose a multimodal-driven framework for high-fidelity long-term digital human animation termed $\\textbf{Soul}$, which generates semantically coherent videos from a single-frame portrait image, text prompts, and audio, achieving precise lip synchronization, vivid facial expressions, and robust identity preservation. We construct Soul-1M, containing 1 million finely annotated samples with a precise automated annotation pipeline (covering portrait, upper-body, full-body, and multi-person scenes) to mitigate data scarcity, and we carefully curate Soul-Bench for comprehensive and fair evaluation of audio-/text-guided animation methods. The model is built on the Wan2.2-5B backbone, integrating audio-injection layers and multiple training strategies together with threshold-aware codebook replacement to ensure long-term generation consistency. Meanwhile, step/CFG distillation and a lightweight VAE are used to optimize inference efficiency, achieving an 11.4$\\times$ speedup with negligible quality loss. Extensive experiments show that Soul significantly outperforms current leading open-source and commercial models on video quality, video-text alignment, identity preservation, and lip-synchronization accuracy, demonstrating broad applicability in real-world scenarios such as virtual anchors and film production. Project page at https://zhangzjn.github.io/projects/Soul/",
    "published": "2025-12-15T16:25:56Z",
    "authors": [
      "Jiangning Zhang",
      "Junwei Zhu",
      "Zhenye Gan",
      "Donghao Luo",
      "Chuming Lin",
      "Feifan Xu",
      "Xu Peng",
      "Jianlong Hu",
      "Yuansen Liu",
      "Yijia Hong",
      "Weijian Cao",
      "Han Feng",
      "Xu Chen",
      "Chencan Fu",
      "Keke He",
      "Xiaobin Hu",
      "Chengjie Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13494",
    "title": "SkipCat: Rank-Maximized Low-Rank Compression of Large Language Models via Shared Projection and Block Skipping",
    "abstract": "Large language models (LLM) have achieved remarkable performance across a wide range of tasks. However, their substantial parameter sizes pose significant challenges for deployment on edge devices with limited computational and memory resources. Low-rank compression is a promising approach to address this issue, as it reduces both computational and memory costs, making LLM more suitable for resource-constrained environments. Nonetheless, naïve low-rank compression methods require a significant reduction in the retained rank to achieve meaningful memory and computation savings. For a low-rank model, the ranks need to be reduced by more than half to yield efficiency gains. Such aggressive truncation, however, typically results in substantial performance degradation. To address this trade-off, we propose SkipCat, a novel low-rank compression framework that enables the use of higher ranks while achieving the same compression rates. First, we introduce an intra-layer shared low-rank projection method, where multiple matrices that share the same input use a common projection. This reduces redundancy and improves compression efficiency. Second, we propose a block skipping technique that omits computations and memory transfers for selected sub-blocks within the low-rank decomposition. These two techniques jointly enable our compressed model to retain more effective ranks under the same compression budget. Experimental results show that, without any additional fine-tuning, our method outperforms previous low-rank compression approaches by 7% accuracy improvement on zero-shot tasks under the same compression rate. These results highlight the effectiveness of our rank-maximized compression strategy in preserving model performance under tight resource constraints.",
    "published": "2025-12-15T16:25:55Z",
    "authors": [
      "Yu-Chen Lu",
      "Sheng-Feng Yu",
      "Hui-Hsien Weng",
      "Pei-Shuo Wang",
      "Yu-Fang Hu",
      "Liang Hung-Chun",
      "Hung-Yueh Chiang",
      "Kai-Chiang Wu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13492",
    "title": "Transform Trained Transformer: Accelerating Naive 4K Video Generation Over 10$\\times$",
    "abstract": "Native 4K (2160$\\times$3840) video generation remains a critical challenge due to the quadratic computational explosion of full-attention as spatiotemporal resolution increases, making it difficult for models to strike a balance between efficiency and quality. This paper proposes a novel Transformer retrofit strategy termed $\\textbf{T3}$ ($\\textbf{T}$ransform $\\textbf{T}$rained $\\textbf{T}$ransformer) that, without altering the core architecture of full-attention pretrained models, significantly reduces compute requirements by optimizing their forward logic. Specifically, $\\textbf{T3-Video}$ introduces a multi-scale weight-sharing window attention mechanism and, via hierarchical blocking together with an axis-preserving full-attention design, can effect an \"attention pattern\" transformation of a pretrained model using only modest compute and data. Results on 4K-VBench show that $\\textbf{T3-Video}$ substantially outperforms existing approaches: while delivering performance improvements (+4.29$\\uparrow$ VQA and +0.08$\\uparrow$ VTC), it accelerates native 4K video generation by more than 10$\\times$. Project page at https://zhangzjn.github.io/projects/T3-Video",
    "published": "2025-12-15T16:25:39Z",
    "authors": [
      "Jiangning Zhang",
      "Junwei Zhu",
      "Teng Hu",
      "Yabiao Wang",
      "Donghao Luo",
      "Weijian Cao",
      "Zhenye Gan",
      "Xiaobin Hu",
      "Zhucun Xue",
      "Chengjie Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13491",
    "title": "From Zipf's Law to Neural Scaling through Heaps' Law and Hilberg's Hypothesis",
    "abstract": "We inspect the deductive connection between the neural scaling law and Zipf's law -- two statements discussed in machine learning and quantitative linguistics. The neural scaling law describes how the cross entropy rate of a foundation model -- such as a large language model -- changes with respect to the amount of training tokens, parameters, and compute. By contrast, Zipf's law posits that the distribution of tokens exhibits a power law tail. Whereas similar claims have been made in more specific settings, we show that the neural scaling law is a consequence of Zipf's law under certain broad assumptions that we reveal systematically. The derivation steps are as follows: We derive Heaps' law on the vocabulary growth from Zipf's law, Hilberg's hypothesis on the entropy scaling from Heaps' law, and the neural scaling from Hilberg's hypothesis. We illustrate these inference steps by a toy example of the Santa Fe process that satisfies all the four statistical laws.",
    "published": "2025-12-15T16:25:06Z",
    "authors": [
      "Łukasz Dębowski"
    ],
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.ST"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13488",
    "title": "SIGMA: An AI-Empowered Training Stack on Early-Life Hardware",
    "abstract": "An increasing variety of AI accelerators is being considered for large-scale training. However, enabling large-scale training on early-life AI accelerators faces three core challenges: frequent system disruptions and undefined failure modes that undermine reliability; numerical errors and training instabilities that threaten correctness and convergence; and the complexity of parallelism optimization combined with unpredictable local noise that degrades efficiency. To address these challenges, SIGMA is an open-source training stack designed to improve the reliability, stability, and efficiency of large-scale distributed training on early-life AI hardware. The core of this initiative is the LUCIA TRAINING PLATFORM (LTP), the system optimized for clusters with early-life AI accelerators. Since its launch in March 2025, LTP has significantly enhanced training reliability and operational productivity. Over the past five months, it has achieved an impressive 94.45% effective cluster accelerator utilization, while also substantially reducing node recycling and job-recovery times. Building on the foundation of LTP, the LUCIA TRAINING FRAMEWORK (LTF) successfully trained SIGMA-MOE, a 200B MoE model, using 2,048 AI accelerators. This effort delivered remarkable stability and efficiency outcomes, achieving 21.08% MFU, state-of-the-art downstream accuracy, and encountering only one stability incident over a 75-day period. Together, these advances establish SIGMA, which not only tackles the critical challenges of large-scale training but also establishes a new benchmark for AI infrastructure and platform innovation, offering a robust, cost-effective alternative to prevailing established accelerator stacks and significantly advancing AI capabilities and scalability. The source code of SIGMA is available at https://github.com/microsoft/LuciaTrainingPlatform.",
    "published": "2025-12-15T16:24:32Z",
    "authors": [
      "Lei Qu",
      "Lianhai Ren",
      "Peng Cheng",
      "Rui Gao",
      "Ruizhe Wang",
      "Tianyu Chen",
      "Xiao Liu",
      "Xingjian Zhang",
      "Yeyun Gong",
      "Yifan Xiong",
      "Yucheng Ding",
      "Yuting Jiang",
      "Zhenghao Lin",
      "Zhongxin Guo",
      "Ziyue Yang"
    ],
    "categories": [
      "cs.DC",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13487",
    "title": "Advancing Bangla Machine Translation Through Informal Datasets",
    "abstract": "Bangla is the sixth most widely spoken language globally, with approximately 234 million native speakers. However, progress in open-source Bangla machine translation remains limited. Most online resources are in English and often remain untranslated into Bangla, excluding millions from accessing essential information. Existing research in Bangla translation primarily focuses on formal language, neglecting the more commonly used informal language. This is largely due to the lack of pairwise Bangla-English data and advanced translation models. If datasets and models can be enhanced to better handle natural, informal Bangla, millions of people will benefit from improved online information access. In this research, we explore current state-of-the-art models and propose improvements to Bangla translation by developing a dataset from informal sources like social media and conversational texts. This work aims to advance Bangla machine translation by focusing on informal language translation and improving accessibility for Bangla speakers in the digital world.",
    "published": "2025-12-15T16:22:45Z",
    "authors": [
      "Ayon Roy",
      "Risat Rahaman",
      "Sadat Shibly",
      "Udoy Saha Joy",
      "Abdulla Al Kafi",
      "Farig Yousuf Sadeque"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13482",
    "title": "Real-Time AI-Driven Milling Digital Twin Towards Extreme Low-Latency",
    "abstract": "Digital twin (DT) enables smart manufacturing by leveraging real-time data, AI models, and intelligent control systems. This paper presents a state-of-the-art analysis on the emerging field of DTs in the context of milling. The critical aspects of DT are explored through the lens of virtual models of physical milling, data flow from physical milling to virtual model, and feedback from virtual model to physical milling. Live data streaming protocols and virtual modeling methods are highlighted. A case study showcases the transformative capability of a real-time machine learning-driven live DT of tool-work contact in a milling process. Future research directions are outlined to achieve the goals of Industry 4.0 and beyond.",
    "published": "2025-12-15T16:18:36Z",
    "authors": [
      "Wenyi Liu",
      "R. Sharma",
      "W. \"Grace\" Guo",
      "J. Yi",
      "Y. B. Guo"
    ],
    "categories": [
      "eess.SY",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13481",
    "title": "neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings",
    "abstract": "Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.",
    "published": "2025-12-15T16:17:12Z",
    "authors": [
      "Ojas Pungalia",
      "Rashi Upadhyay",
      "Abhishek Mishra",
      "Abhiram H",
      "Tejasvi Alladi",
      "Sujan Yenuganti",
      "Dhruv Kumar"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13480",
    "title": "Element-wise Modulation of Random Matrices for Efficient Neural Layers",
    "abstract": "Fully connected layers are a primary source of memory and computational overhead in deep neural networks due to their dense, often redundant parameterization. While various compression techniques exist, they frequently introduce complex engineering trade-offs or degrade model performance. We propose the Parametrized Random Projection (PRP) layer, a novel approach that decouples feature mixing from adaptation by utilizing a fixed random matrix modulated by lightweight, learnable element-wise parameters. This architecture drastically reduces the trainable parameter count to a linear scale while retaining reliable accuracy across various benchmarks. The design serves as a stable, computationally efficient solution for architectural scaling and deployment in resource-limited settings.",
    "published": "2025-12-15T16:16:53Z",
    "authors": [
      "Maksymilian Szorc"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13478",
    "title": "Non-Resolution Reasoning: A Framework for Preserving Semantic Ambiguity in Language Models",
    "abstract": "Premature semantic collapse -- the forced early commitment to a single meaning -- remains a core architectural limitation of current language models. Softmax-driven competition and greedy decoding cause models to discard valid interpretations before sufficient context is available, resulting in brittle reasoning and context failures. We introduce Non-Resolution Reasoning (NRR), a general computational framework that preserves semantic ambiguity during inference and performs resolution only when explicitly required. NRR integrates three components: (1) Multi-Vector Embeddings that maintain multiple viable interpretations per token, (2) Non-Collapsing Attention that prevents winner-take-all dynamics across layers, and (3) Contextual Identity Tracking (CIT), which assigns context-specific identities to recurring entities (e.g., distinguishing \"Dr. Smith the cardiologist\" from \"Dr. Smith the researcher\"). These mechanisms are unified by an external Resolution Operator $ρ$ that makes semantic commitment explicit, controllable, and task-dependent. Unlike standard architectures, NRR separates representation from resolution, allowing a single model to shift between creative, factual, and ambiguity-preserving reasoning without retraining. A synthetic evaluation demonstrates NRR's ability to preserve ambiguity and track context: CIT-enhanced models achieve 90.9% accuracy on out-of-distribution identity-shift tasks, compared to 9.1% for transformer baselines. NRR provides a principled alternative to premature collapse, reframing ambiguity as an explicit representational state rather than a failure mode. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.",
    "published": "2025-12-15T16:14:32Z",
    "authors": [
      "Kei Saito"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13474",
    "title": "Mapping of the system of software-related emissions and shared responsibilities",
    "abstract": "The global climate is experiencing a rapid and unprecedented warming trend. The ICT sector is a notable contributor to global greenhouse gas emissions, with its environmental impact continuing to expand. Addressing this issue is vital for achieving the objectives of the Paris Agreement, particularly the goal of limiting global temperature rise to 1.5°C. At the European Union level, regulatory measures such as the CSRD and the CSDD impose obligations on companies, including those within the ICT sector, to recognize and mitigate their environmental footprint. This study provides a comprehensive system mapping aimed at enhancing the awareness and understanding of software-related emissions and the corresponding responsibilities borne by the ICT sector. The mapping identifies the primary sources of carbon emissions and energy consumption within the ICT domain while also outlining the key responsibilities of the stakeholders accountable throughout the software lifecycle.",
    "published": "2025-12-15T16:12:19Z",
    "authors": [
      "Laura Partanen",
      "Antti Sipila",
      "Md Sanaul Haque",
      "Jari Porras"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13472",
    "title": "Scaling Laws for Code: Every Programming Language Matters",
    "abstract": "Code large language models (Code LLMs) are powerful but costly to train, with scaling laws predicting performance from model size, data, and compute. However, different programming languages (PLs) have varying impacts during pre-training that significantly affect base model performance, leading to inaccurate performance prediction. Besides, existing works focus on language-agnostic settings, neglecting the inherently multilingual nature of modern software development. Therefore, it is first necessary to investigate the scaling laws of different PLs, and then consider their mutual influences to arrive at the final multilingual scaling law. In this paper, we present the first systematic exploration of scaling laws for multilingual code pre-training, conducting over 1000+ experiments (Equivalent to 336,000+ H800 hours) across multiple PLs, model sizes (0.2B to 14B parameters), and dataset sizes (1T tokens). We establish comprehensive scaling laws for code LLMs across multiple PLs, revealing that interpreted languages (e.g., Python) benefit more from increased model size and data than compiled languages (e.g., Rust). The study demonstrates that multilingual pre-training provides synergistic benefits, particularly between syntactically similar PLs. Further, the pre-training strategy of the parallel pairing (concatenating code snippets with their translations) significantly enhances cross-lingual abilities with favorable scaling properties. Finally, a proportion-dependent multilingual scaling law is proposed to optimally allocate training tokens by prioritizing high-utility PLs (e.g., Python), balancing high-synergy pairs (e.g., JavaScript-TypeScript), and reducing allocation to fast-saturating languages (Rust), achieving superior average performance across all PLs compared to uniform distribution under the same compute budget.",
    "published": "2025-12-15T16:07:34Z",
    "authors": [
      "Jian Yang",
      "Shawn Guo",
      "Lin Jing",
      "Wei Zhang",
      "Aishan Liu",
      "Chuan Hao",
      "Zhoujun Li",
      "Wayne Xin Zhao",
      "Xianglong Liu",
      "Weifeng Lv",
      "Bryan Dai"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13465",
    "title": "PoseAnything: Universal Pose-guided Video Generation with Part-aware Temporal Coherence",
    "abstract": "Pose-guided video generation refers to controlling the motion of subjects in generated video through a sequence of poses. It enables precise control over subject motion and has important applications in animation. However, current pose-guided video generation methods are limited to accepting only human poses as input, thus generalizing poorly to pose of other subjects. To address this issue, we propose PoseAnything, the first universal pose-guided video generation framework capable of handling both human and non-human characters, supporting arbitrary skeletal inputs. To enhance consistency preservation during motion, we introduce Part-aware Temporal Coherence Module, which divides the subject into different parts, establishes part correspondences, and computes cross-attention between corresponding parts across frames to achieve fine-grained part-level consistency. Additionally, we propose Subject and Camera Motion Decoupled CFG, a novel guidance strategy that, for the first time, enables independent camera movement control in pose-guided video generation, by separately injecting subject and camera motion control information into the positive and negative anchors of CFG. Furthermore, we present XPose, a high-quality public dataset containing 50,000 non-human pose-video pairs, along with an automated pipeline for annotation and filtering. Extensive experiments demonstrate that Pose-Anything significantly outperforms state-of-the-art methods in both effectiveness and generalization.",
    "published": "2025-12-15T16:03:26Z",
    "authors": [
      "Ruiyan Wang",
      "Teng Hu",
      "Kaihui Huang",
      "Zihan Su",
      "Ran Yi",
      "Lizhuang Ma"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13460",
    "title": "DP-EMAR: A Differentially Private Framework for Autonomous Model Weight Repair in Federated IoT Systems",
    "abstract": "Federated Learning (FL) enables decentralized model training without sharing raw data, but model weight distortion remains a major challenge in resource constrained IoT networks. In multi tier Federated IoT (Fed-IoT) systems, unstable connectivity and adversarial interference can silently alter transmitted parameters, degrading convergence. We propose DP-EMAR, a differentially private, error model based autonomous repair framework that detects and reconstructs transmission induced distortions during FL aggregation. DP-EMAR estimates corruption patterns and applies adaptive correction before privacy noise is added, enabling reliable in network repair without violating confidentiality. By integrating Differential Privacy (DP) with Secure Aggregation (SA), the framework distinguishes DP noise from genuine transmission errors. Experiments on heterogeneous IoT sensor and graph datasets show that DP-EMAR preserves convergence stability and maintains near baseline performance under communication corruption while ensuring strict (epsilon, delta)-DP guarantees. The framework enhances robustness, communication efficiency, and trust in privacy preserving Federated IoT learning.",
    "published": "2025-12-15T15:56:58Z",
    "authors": [
      "Chethana Prasad Kabgere",
      "Shylaja S S"
    ],
    "categories": [
      "cs.LG",
      "math.NA"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13458",
    "title": "SSAS: Cross-subject EEG-based Emotion Recognition through Source Selection with Adversarial Strategy",
    "abstract": "Electroencephalographic (EEG) signals have long been applied in the field of affective brain-computer interfaces (aBCIs). Cross-subject EEG-based emotion recognition has demonstrated significant potential in practical applications due to its suitability across diverse people. However, most studies on cross-subject EEG-based emotion recognition neglect the presence of inter-individual variability and negative transfer phenomena during model training. To address this issue, a cross-subject EEG-based emotion recognition through source selection with adversarial strategy is introduced in this paper. The proposed method comprises two modules: the source selection network (SS) and the adversarial strategies network (AS). The SS uses domain labels to reverse-engineer the training process of domain adaptation. Its key idea is to disrupt class separability and magnify inter-domain differences, thereby raising the classification difficulty and forcing the model to learn domain-invariant yet emotion-relevant representations. The AS gets the source domain selection results and the pretrained domain discriminators from SS. The pretrained domain discriminators compute a novel loss aimed at enhancing the performance of domain classification during adversarial training, ensuring the balance of adversarial strategies. This paper provides theoretical insights into the proposed method and achieves outstanding performance on two EEG-based emotion datasets, SEED and SEED-IV. The code can be found at https://github.com/liuyici/SSAS.",
    "published": "2025-12-15T15:56:04Z",
    "authors": [
      "Yici Liu",
      "Qi Wei Oung",
      "Hoi Leong Lee"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13454",
    "title": "Test-Time Modification: Inverse Domain Transformation for Robust Perception",
    "abstract": "Generative foundation models contain broad visual knowledge and can produce diverse image variations, making them particularly promising for advancing domain generalization tasks. While they can be used for training data augmentation, synthesizing comprehensive target-domain variations remains slow, expensive, and incomplete. We propose an alternative: using diffusion models at test time to map target images back to the source distribution where the downstream model was trained. This approach requires only a source domain description, preserves the task model, and eliminates large-scale synthetic data generation. We demonstrate consistent improvements across segmentation, detection, and classification tasks under challenging environmental shifts in real-to-real domain generalization scenarios with unknown target distributions. Our analysis spans multiple generative and downstream models, including an ensemble variant for enhanced robustness. The method achieves substantial relative gains: 137% on BDD100K-Night, 68% on ImageNet-R, and 62% on DarkZurich.",
    "published": "2025-12-15T15:51:30Z",
    "authors": [
      "Arpit Jadon",
      "Joshua Niemeijer",
      "Yuki M. Asano"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13444",
    "title": "A Data Annotation Requirements Representation and Specification (DARS)",
    "abstract": "With the rise of AI-enabled cyber-physical systems, data annotation has become a critical yet often overlooked process in the development of these intelligent information systems. Existing work in requirements engineering (RE) has explored how requirements for AI systems and their data can be represented. However, related interviews with industry professionals show that data annotations and their related requirements introduce distinct challenges, indicating a need for annotation-specific requirement representations. We propose the Data Annotation Requirements Representation and Specification (DARS), including an Annotation Negotiation Card to align stakeholders on objectives and constraints, and a Scenario-Based Annotation Specification to express atomic and verifiable data annotation requirements. We evaluate DARS with an automotive perception case related to an ongoing project, and a mapping against 18 real-world data annotation error types. The results suggest that DARS mitigates root causes of completeness, accuracy, and consistency annotation errors. By integrating DARS into RE, this work improves the reliability of safety-critical systems using data annotations and demonstrates how engineering frameworks must evolve for data-dependent components of today's intelligent information systems.",
    "published": "2025-12-15T15:41:30Z",
    "authors": [
      "Yi Peng",
      "Hina Saeeda",
      "Hans-Martin Heyn",
      "Jennifer Horkoff",
      "Eric Knauss",
      "Fredrick Warg"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13442",
    "title": "XNNTab -- Interpretable Neural Networks for Tabular Data using Sparse Autoencoders",
    "abstract": "In data-driven applications relying on tabular data, where interpretability is key, machine learning models such as decision trees and linear regression are applied. Although neural networks can provide higher predictive performance, they are not used because of their blackbox nature. In this work, we present XNNTab, a neural architecture that combines the expressiveness of neural networks and interpretability. XNNTab first learns highly non-linear feature representations, which are decomposed into monosemantic features using a sparse autoencoder (SAE). These features are then assigned human-interpretable concepts, making the overall model prediction intrinsically interpretable. XNNTab outperforms interpretable predictive models, and achieves comparable performance to its non-interpretable counterparts.",
    "published": "2025-12-15T15:39:59Z",
    "authors": [
      "Khawla Elhadri",
      "Jörg Schlötterer",
      "Christin Seifert"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13441",
    "title": "Large language models are not about language",
    "abstract": "Large Language Models are useless for linguistics, as they are probabilistic models that require a vast amount of data to analyse externalized strings of words. In contrast, human language is underpinned by a mind-internal computational system that recursively generates hierarchical thought structures. The language system grows with minimal external input and can readily distinguish between real language and impossible languages.",
    "published": "2025-12-15T15:36:42Z",
    "authors": [
      "Johan J. Bolhuis",
      "Andrea Moro",
      "Stephen Crain",
      "Sandiway Fong"
    ],
    "categories": [
      "cs.CL",
      "q-bio.NC"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13440",
    "title": "IMILIA: interpretable multiple instance learning for inflammation prediction in IBD from H&E whole slide images",
    "abstract": "As the therapeutic target for Inflammatory Bowel Disease (IBD) shifts toward histologic remission, the accurate assessment of microscopic inflammation has become increasingly central for evaluating disease activity and response to treatment. In this work, we introduce IMILIA (Interpretable Multiple Instance Learning for Inflammation Analysis), an end-to-end framework designed for the prediction of inflammation presence in IBD digitized slides stained with hematoxylin and eosin (H&E), followed by the automated computation of markers characterizing tissue regions driving the predictions. IMILIA is composed of an inflammation prediction module, consisting of a Multiple Instance Learning (MIL) model, and an interpretability module, divided in two blocks: HistoPLUS, for cell instance detection, segmentation and classification; and EpiSeg, for epithelium segmentation. IMILIA achieves a cross-validation ROC-AUC of 0.83 on the discovery cohort, and a ROC-AUC of 0.99 and 0.84 on two external validation cohorts. The interpretability module yields biologically consistent insights: tiles with higher predicted scores show increased densities of immune cells (lymphocytes, plasmocytes, neutrophils and eosinophils), whereas lower-scored tiles predominantly contain normal epithelial cells. Notably, these patterns were consistent across all datasets. Code and models to partially replicate the results on the public IBDColEpi dataset can be found at https://github.com/owkin/imilia.",
    "published": "2025-12-15T15:36:09Z",
    "authors": [
      "Thalyssa Baiocco-Rodrigues",
      "Antoine Olivier",
      "Reda Belbahri",
      "Thomas Duboudin",
      "Pierre-Antoine Bannier",
      "Benjamin Adjadj",
      "Katharina Von Loga",
      "Nathan Noiry",
      "Maxime Touzot",
      "Hector Roux de Bezieux"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13438",
    "title": "From User Interface to Agent Interface: Efficiency Optimization of UI Representations for LLM Agents",
    "abstract": "While Large Language Model (LLM) agents show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of automatically generating programs that transform UI representations, faces two unique challenges. First, the lack of Boolean oracles, which traditional program synthesis uses to decisively validate semantic correctness, poses a fundamental challenge to co-optimization of token efficiency and completeness. Second, the need to process large, complex UI trees as input while generating long, compositional transformation programs, making the search space vast and error-prone. Toward addressing the preceding limitations, we present UIFormer, the first automated optimization framework that synthesizes UI transformation programs by conducting constraint-based optimization with structured decomposition of the complex synthesis task. First, UIFormer restricts the program space using a domain-specific language (DSL) that captures UI-specific operations. Second, UIFormer conducts LLM-based iterative refinement with correctness and efficiency rewards, providing guidance for achieving the efficiency-completeness co-optimization. UIFormer operates as a lightweight plugin that applies transformation programs for seamless integration with existing LLM agents, requiring minimal modifications to their core logic. Evaluations across three UI navigation benchmarks spanning Android and Web platforms with five LLMs demonstrate that UIFormer achieves 48.7% to 55.8% token reduction with minimal runtime overhead while maintaining or improving agent performance. Real-world industry deployment at WeChat further validates the practical impact of UIFormer.",
    "published": "2025-12-15T15:34:06Z",
    "authors": [
      "Dezhi Ran",
      "Zhi Gong",
      "Yuzhe Guo",
      "Mengzhou Wu",
      "Yuan Cao",
      "Haochuan Lu",
      "Hengyu Zhang",
      "Xia Zeng",
      "Gang Cao",
      "Liangchao Yao",
      "Yuetang Deng",
      "Wei Yang",
      "Tao Xie"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13434",
    "title": "Self-Supervised Ultrasound Representation Learning for Renal Anomaly Prediction in Prenatal Imaging",
    "abstract": "Prenatal ultrasound is the cornerstone for detecting congenital anomalies of the kidneys and urinary tract, but diagnosis is limited by operator dependence and suboptimal imaging conditions. We sought to assess the performance of a self-supervised ultrasound foundation model for automated fetal renal anomaly classification using a curated dataset of 969 two-dimensional ultrasound images. A pretrained Ultrasound Self-Supervised Foundation Model with Masked Autoencoding (USF-MAE) was fine-tuned for binary and multi-class classification of normal kidneys, urinary tract dilation, and multicystic dysplastic kidney. Models were compared with a DenseNet-169 convolutional baseline using cross-validation and an independent test set. USF-MAE consistently improved upon the baseline across all evaluation metrics in both binary and multi-class settings. USF-MAE achieved an improvement of about 1.87% (AUC) and 7.8% (F1-score) on the validation set, 2.32% (AUC) and 4.33% (F1-score) on the independent holdout test set. The largest gains were observed in the multi-class setting, where the improvement in AUC was 16.28% and 46.15% in F1-score. To facilitate model interpretability, Score-CAM visualizations were adapted for a transformer architecture and show that model predictions were informed by known, clinically relevant renal structures, including the renal pelvis in urinary tract dilation and cystic regions in multicystic dysplastic kidney. These results show that ultrasound-specific self-supervised learning can generate a useful representation as a foundation for downstream diagnostic tasks. The proposed framework offers a robust, interpretable approach to support the prenatal detection of renal anomalies and demonstrates the promise of foundation models in obstetric imaging.",
    "published": "2025-12-15T15:28:02Z",
    "authors": [
      "Youssef Megahed",
      "Inok Lee",
      "Robin Ducharme",
      "Kevin Dick",
      "Adrian D. C. Chan",
      "Steven Hawken",
      "Mark C. Walker"
    ],
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13430",
    "title": "Weak Enforcement and Low Compliance in PCI~DSS: A Comparative Security Study",
    "abstract": "Although credit and debit card data continue to be a prime target for attackers, organizational adherence to the Payment Card Industry Data Security Standard (PCI DSS) remains surprisingly low. Despite prior work showing that PCI DSS can reduce card fraud, only 32.4% of organizations were fully compliant in 2022, suggesting possible deficiencies in enforcement mechanisms. This study compares PCI DSS with three data security frameworks, HIPAA, NIS2, and GDPR, to examine how enforcement mechanisms relate to implementation success. The analysis reveals that PCI DSS significantly lags far behind these security frameworks and that its sanctions are orders of magnitude smaller than those under GDPR and NIS2. The findings indicate a positive association between stronger, multi-modal enforcement (including public disclosure, license actions, and imprisonment) and higher implementation rates, and highlights the structural weakness of PCI DSS's bank-dependent monitoring model. Enhanced non-monetary sanctions and the creation of an independent supervisory authority are recommended to increase transparency, reduce conflicts of interest, and improve PCI DSS compliance without discouraging card acceptance.",
    "published": "2025-12-15T15:19:33Z",
    "authors": [
      "Soonwon Park",
      "John D. Hastings"
    ],
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13428",
    "title": "A Domain-Adapted Lightweight Ensemble for Resource-Efficient Few-Shot Plant Disease Classification",
    "abstract": "Accurate and timely identification of plant leaf diseases is essential for resilient and sustainable agriculture, yet most deep learning approaches rely on large annotated datasets and computationally intensive models that are unsuitable for data-scarce and resource-constrained environments. To address these challenges we present a few-shot learning approach within a lightweight yet efficient framework that combines domain-adapted MobileNetV2 and MobileNetV3 models as feature extractors, along with a feature fusion technique to generate robust feature representation. For the classification task, the fused features are passed through a Bi-LSTM classifier enhanced with attention mechanisms to capture sequential dependencies and focus on the most relevant features, thereby achieving optimal classification performance even in complex, real-world environments with noisy or cluttered backgrounds. The proposed framework was evaluated across multiple experimental setups, including both laboratory-controlled and field-captured datasets. On tomato leaf diseases from the PlantVillage dataset, it consistently improved performance across 1 to 15 shot scenarios, reaching 98.23+-0.33% at 15 shot, closely approaching the 99.98% SOTA benchmark achieved by a Transductive LSTM with attention, while remaining lightweight and mobile-friendly. Under real-world conditions using field images from the Dhan Shomadhan dataset, it maintained robust performance, reaching 69.28+-1.49% at 15-shot and demonstrating strong resilience to complex backgrounds. Notably, it also outperformed the previous SOTA accuracy of 96.0% on six diseases from PlantVillage, achieving 99.72% with only 15-shot learning. With a compact model size of approximately 40 MB and inference complexity of approximately 1.12 GFLOPs, this work establishes a scalable, mobile-ready foundation for precise plant disease diagnostics in data-scarce regions.",
    "published": "2025-12-15T15:17:29Z",
    "authors": [
      "Anika Islam",
      "Tasfia Tahsin",
      "Zaarin Anjum",
      "Md. Bakhtiar Hasan",
      "Md. Hasanul Kabir"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13427",
    "title": "MineTheGap: Automatic Mining of Biases in Text-to-Image Models",
    "abstract": "Text-to-Image (TTI) models generate images based on text prompts, which often leave certain aspects of the desired image ambiguous. When faced with these ambiguities, TTI models have been shown to exhibit biases in their interpretations. These biases can have societal impacts, e.g., when showing only a certain race for a stated occupation. They can also affect user experience when creating redundancy within a set of generated images instead of spanning diverse possibilities. Here, we introduce MineTheGap - a method for automatically mining prompts that cause a TTI model to generate biased outputs. Our method goes beyond merely detecting bias for a given prompt. Rather, it leverages a genetic algorithm to iteratively refine a pool of prompts, seeking for those that expose biases. This optimization process is driven by a novel bias score, which ranks biases according to their severity, as we validate on a dataset with known biases. For a given prompt, this score is obtained by comparing the distribution of generated images to the distribution of LLM-generated texts that constitute variations on the prompt. Code and examples are available on the project's webpage.",
    "published": "2025-12-15T15:17:02Z",
    "authors": [
      "Noa Cohen",
      "Nurit Spingarn-Eliezer",
      "Inbar Huberman-Spiegelglas",
      "Tomer Michaeli"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13422",
    "title": "QMon: Monitoring the Execution of Quantum Circuits with Mid-Circuit Measurement and Reset",
    "abstract": "Unlike classical software, where logging and runtime tracing can effectively reveal internal execution status, quantum circuits possess unique properties, such as the no-cloning theorem and measurement-induced collapse, that prevent direct observation or duplication of their states. These characteristics make it especially challenging to monitor the execution of quantum circuits, complicating essential tasks such as debugging and runtime monitoring. This paper presents QMON, a practical methodology that leverages mid-circuit measurements and reset operations to monitor the internal states of quantum circuits while preserving their original runtime behavior. QMON enables the instrumentation of monitoring operators at developer-specified locations within the circuit, allowing comparisons between expected and observed quantum-state probabilities at those locations. We evaluated QMON by analyzing its impact on circuit behavior, monitoring coverage, and effectiveness in bug localization. Experimental results involving 154 quantum circuits show that all circuits preserve their intended functionality after instrumentation and that QMON successfully detects and localizes various programming errors. Although monitoring coverage is limited by the need to preserve delicate quantum properties, such as entanglement, QMON effectively detects errors while introducing no or negligible disturbance to the original quantum states. QMON facilitates the development of more robust and reliable quantum software as the field continues to mature.",
    "published": "2025-12-15T15:14:53Z",
    "authors": [
      "Ning Ma",
      "Jianjun Zhao",
      "Foutse Khomh",
      "Shaukat Ali",
      "Heng Li"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13421",
    "title": "RecTok: Reconstruction Distillation along Rectified Flow",
    "abstract": "Visual tokenizers play a crucial role in diffusion models. The dimensionality of latent space governs both reconstruction fidelity and the semantic expressiveness of the latent feature. However, a fundamental trade-off is inherent between dimensionality and generation quality, constraining existing methods to low-dimensional latent spaces. Although recent works have leveraged vision foundation models to enrich the semantics of visual tokenizers and accelerate convergence, high-dimensional tokenizers still underperform their low-dimensional counterparts. In this work, we propose RecTok, which overcomes the limitations of high-dimensional visual tokenizers through two key innovations: flow semantic distillation and reconstruction--alignment distillation. Our key insight is to make the forward flow in flow matching semantically rich, which serves as the training space of diffusion transformers, rather than focusing on the latent space as in previous works. Specifically, our method distills the semantic information in VFMs into the forward flow trajectories in flow matching. And we further enhance the semantics by introducing a masked feature reconstruction loss. Our RecTok achieves superior image reconstruction, generation quality, and discriminative performance. It achieves state-of-the-art results on the gFID-50K under both with and without classifier-free guidance settings, while maintaining a semantically rich latent space structure. Furthermore, as the latent dimensionality increases, we observe consistent improvements. Code and model are available at https://shi-qingyu.github.io/rectok.github.io.",
    "published": "2025-12-15T15:14:20Z",
    "authors": [
      "Qingyu Shi",
      "Size Wu",
      "Jinbin Bai",
      "Kaidong Yu",
      "Yujing Wang",
      "Yunhai Tong",
      "Xiangtai Li",
      "Xuelong Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13416",
    "title": "Learning to Generate Cross-Task Unexploitable Examples",
    "abstract": "Unexploitable example generation aims to transform personal images into their unexploitable (unlearnable) versions before they are uploaded online, thereby preventing unauthorized exploitation of online personal images. Recently, this task has garnered significant research attention due to its critical relevance to personal data privacy. Yet, despite recent progress, existing methods for this task can still suffer from limited practical applicability, as they can fail to generate examples that are broadly unexploitable across different real-world computer vision tasks. To deal with this problem, in this work, we propose a novel Meta Cross-Task Unexploitable Example Generation (MCT-UEG) framework. At the core of our framework, to optimize the unexploitable example generator for effectively producing broadly unexploitable examples, we design a flat-minima-oriented meta training and testing scheme. Extensive experiments show the efficacy of our framework.",
    "published": "2025-12-15T15:05:38Z",
    "authors": [
      "Haoxuan Qu",
      "Qiuchi Xiang",
      "Yujun Cai",
      "Yirui Wu",
      "Majid Mirmehdi",
      "Hossein Rahmani",
      "Jun Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13415",
    "title": "USTM: Unified Spatial and Temporal Modeling for Continuous Sign Language Recognition",
    "abstract": "Continuous sign language recognition (CSLR) requires precise spatio-temporal modeling to accurately recognize sequences of gestures in videos. Existing frameworks often rely on CNN-based spatial backbones combined with temporal convolution or recurrent modules. These techniques fail in capturing fine-grained hand and facial cues and modeling long-range temporal dependencies. To address these limitations, we propose the Unified Spatio-Temporal Modeling (USTM) framework, a spatio-temporal encoder that effectively models complex patterns using a combination of a Swin Transformer backbone enhanced with lightweight temporal adapter with positional embeddings (TAPE). Our framework captures fine-grained spatial features alongside short and long-term temporal context, enabling robust sign language recognition from RGB videos without relying on multi-stream inputs or auxiliary modalities. Extensive experiments on benchmarked datasets including PHOENIX14, PHOENIX14T, and CSL-Daily demonstrate that USTM achieves state-of-the-art performance against RGB-based as well as multi-modal CSLR approaches, while maintaining competitive performance against multi-stream approaches. These results highlight the strength and efficacy of the USTM framework for CSLR. The code is available at https://github.com/gufranSabri/USTM",
    "published": "2025-12-15T15:05:16Z",
    "authors": [
      "Ahmed Abul Hasanaath",
      "Hamzah Luqman"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13414",
    "title": "PSALM: applying Proportional SAmpLing strategy in Metamorphic testing",
    "abstract": "Metamorphic testing (MT) alleviates the oracle problem by checking metamorphic relations (MRs) across multiple test executions. The fault detection effectiveness of MT is influenced not only by the choice and quality of MRs, but also by how source test cases and metamorphic groups (MGs) are selected. While substantial research has focused on designing, generating, and validating MRs, systematic methods for source test case selection and MG selection remain largely unexplored. Although the Proportional Sampling Strategy (PSS) provides strong theoretical guarantees in traditional testing, its assumptions cannot be directly applied in MT due to differences in selection domains, test units, and failure distributions. This paper proposes PSALM, an adaptation of PSS to MT for both source test case selection and MG selection. We formally prove that PSALM is never inferior to random selection regardless of how the source test case and MG domains are partitioned. We further identify the conditions under which applying PSALM to source test case selection and MG selection yields identical effectiveness. A comprehensive empirical study on eight subject programs and 184 mutants shows that the results are consistent with our theoretical analysis and that PSALM generally performs more effectively than existing selection strategies such as ART and MT-ART. These results demonstrate that PSALM provides a theoretically grounded and practically effective selection strategy for MT.",
    "published": "2025-12-15T15:04:15Z",
    "authors": [
      "Zenghui Zhou",
      "Pak-Lok Poon",
      "Zheng Zheng",
      "Xiao-Yi Zhang"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13411",
    "title": "Computer vision training dataset generation for robotic environments using Gaussian splatting",
    "abstract": "This paper introduces a novel pipeline for generating large-scale, highly realistic, and automatically labeled datasets for computer vision tasks in robotic environments. Our approach addresses the critical challenges of the domain gap between synthetic and real-world imagery and the time-consuming bottleneck of manual annotation. We leverage 3D Gaussian Splatting (3DGS) to create photorealistic representations of the operational environment and objects. These assets are then used in a game engine where physics simulations create natural arrangements. A novel, two-pass rendering technique combines the realism of splats with a shadow map generated from proxy meshes. This map is then algorithmically composited with the image to add both physically plausible shadows and subtle highlights, significantly enhancing realism. Pixel-perfect segmentation masks are generated automatically and formatted for direct use with object detection models like YOLO. Our experiments show that a hybrid training strategy, combining a small set of real images with a large volume of our synthetic data, yields the best detection and segmentation performance, confirming this as an optimal strategy for efficiently achieving robust and accurate models.",
    "published": "2025-12-15T15:00:17Z",
    "authors": [
      "Patryk Niżeniec",
      "Marcin Iwanowski"
    ],
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "source": "arXiv",
    "batch": 1
  },
  {
    "arxiv_id": "2512.13410",
    "title": "Multiclass Graph-Based Large Margin Classifiers: Unified Approach for Support Vectors and Neural Networks",
    "abstract": "While large margin classifiers are originally an outcome of an optimization framework, support vectors (SVs) can be obtained from geometric approaches. This article presents advances in the use of Gabriel graphs (GGs) in binary and multiclass classification problems. For Chipclass, a hyperparameter-less and optimization-less GG-based binary classifier, we discuss how activation functions and support edge (SE)-centered neurons affect the classification, proposing smoother functions and structural SV (SSV)-centered neurons to achieve margins with low probabilities and smoother classification contours. We extend the neural network architecture, which can be trained with backpropagation with a softmax function and a cross-entropy loss, or by solving a system of linear equations. A new subgraph-/distance-based membership function for graph regularization is also proposed, along with a new GG recomputation algorithm that is less computationally expensive than the standard approach. Experimental results with the Friedman test show that our method was better than previous GG-based classifiers and statistically equivalent to tree-based models.",
    "published": "2025-12-15T15:00:13Z",
    "authors": [
      "Vítor M. Hanriot",
      "Luiz C. B. Torres",
      "Antônio P. Braga"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13402",
    "title": "End2Reg: Learning Task-Specific Segmentation for Markerless Registration in Spine Surgery",
    "abstract": "Purpose: Intraoperative navigation in spine surgery demands millimeter-level accuracy. Current systems based on intraoperative radiographic imaging and bone-anchored markers are invasive, radiation-intensive and workflow disruptive. Recent markerless RGB-D registration methods offer a promising alternative, but existing approaches rely on weak segmentation labels to isolate relevant anatomical structures, which can propagate errors throughout registration. Methods: We present End2Reg an end-to-end deep learning framework that jointly optimizes segmentation and registration, eliminating the need for weak segmentation labels and manual steps. The network learns segmentation masks specifically optimized for registration, guided solely by the registration objective without direct segmentation supervision. Results: The proposed framework achieves state-of-the-art performance on ex- and in-vivo benchmarks, reducing median Target Registration Error by 32% to 1.83mm and mean Root Mean Square Error by 45% to 3.95mm, respectively. An ablation study confirms that end-to-end optimization significantly improves registration accuracy. Conclusion: The presented end-to-end RGB-D registration pipeline removes dependency on weak labels and manual steps, advancing towards fully automatic, markerless intraoperative navigation. Code and interactive visualizations are available at: https://lorenzopettinari.github.io/end-2-reg/.",
    "published": "2025-12-15T14:53:20Z",
    "authors": [
      "Lorenzo Pettinari",
      "Sidaty El Hadramy",
      "Michael Wehrli",
      "Philippe C. Cattin",
      "Daniel Studer",
      "Carol C. Hasler",
      "Maria Licci"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13399",
    "title": "Differentiable Evolutionary Reinforcement Learning",
    "abstract": "The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous agents for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the \"meta-gradient\" of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic agent (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving agent alignment without human intervention.",
    "published": "2025-12-15T14:50:08Z",
    "authors": [
      "Sitao Cheng",
      "Tianle Li",
      "Xuhan Huang",
      "Xunjian Yin",
      "Difan Zou"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13397",
    "title": "rNCA: Self-Repairing Segmentation Masks",
    "abstract": "Accurately predicting topologically correct masks remains a difficult task for general segmentation models, which often produce fragmented or disconnected outputs. Fixing these artifacts typically requires hand-crafted refinement rules or architectures specialized to a particular task. Here, we show that Neural Cellular Automata (NCA) can be directly re-purposed as an effective refinement mechanism, using local, iterative updates guided by image context to repair segmentation masks. By training on imperfect masks and ground truths, the automaton learns the structural properties of the target shape while relying solely on local information. When applied to coarse, globally predicted masks, the learned dynamics progressively reconnect broken regions, prune loose fragments and converge towards stable, topologically consistent results. We show how refinement NCA (rNCA) can be easily applied to repair common topological errors produced by different base segmentation models and tasks: for fragmented retinal vessels, it yields 2-3% gains in Dice/clDice and improves Betti errors, reducing $β_0$ errors by 60% and $β_1$ by 20%; for myocardium, it repairs 61.5% of broken cases in a zero-shot setting while lowering ASSD and HD by 19% and 16%, respectively. This showcases NCA as effective and broadly applicable refiners.",
    "published": "2025-12-15T14:49:55Z",
    "authors": [
      "Malte Silbernagel",
      "Albert Alonso",
      "Jens Petersen",
      "Bulat Ibragimov",
      "Marleen de Bruijne",
      "Madeleine K. Wyburd"
    ],
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13392",
    "title": "Beyond the Visible: Disocclusion-Aware Editing via Proxy Dynamic Graphs",
    "abstract": "We address image-to-video generation with explicit user control over the final frame's disoccluded regions. Current image-to-video pipelines produce plausible motion but struggle to generate predictable, articulated motions while enforcing user-specified content in newly revealed areas. Our key idea is to separate motion specification from appearance synthesis: we introduce a lightweight, user-editable Proxy Dynamic Graph (PDG) that deterministically yet approximately drives part motion, while a frozen diffusion prior is used to synthesize plausible appearance that follows that motion. In our training-free pipeline, the user loosely annotates and reposes a PDG, from which we compute a dense motion flow to leverage diffusion as a motion-guided shader. We then let the user edit appearance in the disoccluded areas of the image, and exploit the visibility information encoded by the PDG to perform a latent-space composite that reconciles motion with user intent in these areas. This design yields controllable articulation and user control over disocclusions without fine-tuning. We demonstrate clear advantages against state-of-the-art alternatives towards images turned into short videos of articulated objects, furniture, vehicles, and deformables. Our method mixes generative control, in the form of loose pose and structure, with predictable controls, in the form of appearance specification in the final frame in the disoccluded regions, unlocking a new image-to-video workflow. Code will be released on acceptance. Project page: https://anranqi.github.io/beyondvisible.github.io/",
    "published": "2025-12-15T14:45:05Z",
    "authors": [
      "Anran Qi",
      "Changjian Li",
      "Adrien Bousseau",
      "Niloy J. Mitra"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13381",
    "title": "Dual-Phase Federated Deep Unlearning via Weight-Aware Rollback and Reconstruction",
    "abstract": "Federated Unlearning (FUL) focuses on client data and computing power to offer a privacy-preserving solution. However, high computational demands, complex incentive mechanisms, and disparities in client-side computing power often lead to long times and higher costs. To address these challenges, many existing methods rely on server-side knowledge distillation that solely removes the updates of the target client, overlooking the privacy embedded in the contributions of other clients, which can lead to privacy leakage. In this work, we introduce DPUL, a novel server-side unlearning method that deeply unlearns all influential weights to prevent privacy pitfalls. Our approach comprises three components: (i) identifying high-weight parameters by filtering client update magnitudes, and rolling them back to ensure deep removal. (ii) leveraging the variational autoencoder (VAE) to reconstruct and eliminate low-weight parameters. (iii) utilizing a projection-based technique to recover the model. Experimental results on four datasets demonstrate that DPUL surpasses state-of-the-art baselines, providing a 1%-5% improvement in accuracy and up to 12x reduction in time cost.",
    "published": "2025-12-15T14:32:47Z",
    "authors": [
      "Changjun Zhou",
      "Jintao Zheng",
      "Leyou Yang",
      "Pengfei Wang"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13376",
    "title": "Unlocking Generalization in Polyp Segmentation with DINO Self-Attention \"keys\"",
    "abstract": "Automatic polyp segmentation is crucial for improving the clinical identification of colorectal cancer (CRC). While Deep Learning (DL) techniques have been extensively researched for this problem, current methods frequently struggle with generalization, particularly in data-constrained or challenging settings. Moreover, many existing polyp segmentation methods rely on complex, task-specific architectures. To address these limitations, we present a framework that leverages the intrinsic robustness of DINO self-attention \"key\" features for robust segmentation. Unlike traditional methods that extract tokens from the deepest layers of the Vision Transformer (ViT), our approach leverages the key features of the self-attention module with a simple convolutional decoder to predict polyp masks, resulting in enhanced performance and better generalizability. We validate our approach using a multi-center dataset under two rigorous protocols: Domain Generalization (DG) and Extreme Single Domain Generalization (ESDG). Our results, supported by a comprehensive statistical analysis, demonstrate that this pipeline achieves state-of-the-art (SOTA) performance, significantly enhancing generalization, particularly in data-scarce and challenging scenarios. While avoiding a polyp-specific architecture, we surpass well-established models like nnU-Net and UM-Net. Additionally, we provide a systematic benchmark of the DINO framework's evolution, quantifying the specific impact of architectural advancements on downstream polyp segmentation performance.",
    "published": "2025-12-15T14:29:47Z",
    "authors": [
      "Carla Monteiro",
      "Valentina Corbetta",
      "Regina Beets-Tan",
      "Luís F. Teixeira",
      "Wilson Silva"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13374",
    "title": "Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection",
    "abstract": "Recent advances in Large Language Models (LLMs) have opened new perspectives for automation in optimization. While several studies have explored how LLMs can generate or solve optimization models, far less is understood about what these models actually learn regarding problem structure or algorithmic behavior. This study investigates how LLMs internally represent combinatorial optimization problems and whether such representations can support downstream decision tasks. We adopt a twofold methodology combining direct querying, which assesses LLM capacity to explicitly extract instance features, with probing analyses that examine whether such information is implicitly encoded within their hidden layers. The probing framework is further extended to a per-instance algorithm selection task, evaluating whether LLM-derived representations can predict the best-performing solver. Experiments span four benchmark problems and three instance representations. Results show that LLMs exhibit moderate ability to recover feature information from problem instances, either through direct querying or probing. Notably, the predictive power of LLM hidden-layer representations proves comparable to that achieved through traditional feature extraction, suggesting that LLMs capture meaningful structural information relevant to optimization performance.",
    "published": "2025-12-15T14:28:35Z",
    "authors": [
      "Francesca Da Ros",
      "Luca Di Gaspero",
      "Kevin Roitero"
    ],
    "categories": [
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13363",
    "title": "Detecting Emotion Drift in Mental Health Text Using Pre-Trained Transformers",
    "abstract": "This study investigates emotion drift: the change in emotional state across a single text, within mental health-related messages. While sentiment analysis typically classifies an entire message as positive, negative, or neutral, the nuanced shift of emotions over the course of a message is often overlooked. This study detects sentence-level emotions and measures emotion drift scores using pre-trained transformer models such as DistilBERT and RoBERTa. The results provide insights into patterns of emotional escalation or relief in mental health conversations. This methodology can be applied to better understand emotional dynamics in content.",
    "published": "2025-12-15T14:18:12Z",
    "authors": [
      "Shibani Sankpal"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13361",
    "title": "Automated User Identification from Facial Thermograms with Siamese Networks",
    "abstract": "The article analyzes the use of thermal imaging technologies for biometric identification based on facial thermograms. It presents a comparative analysis of infrared spectral ranges (NIR, SWIR, MWIR, and LWIR). The paper also defines key requirements for thermal cameras used in biometric systems, including sensor resolution, thermal sensitivity, and a frame rate of at least 30 Hz. Siamese neural networks are proposed as an effective approach for automating the identification process. In experiments conducted on a proprietary dataset, the proposed method achieved an accuracy of approximately 80%. The study also examines the potential of hybrid systems that combine visible and infrared spectra to overcome the limitations of individual modalities. The results indicate that thermal imaging is a promising technology for developing reliable security systems.",
    "published": "2025-12-15T14:13:49Z",
    "authors": [
      "Elizaveta Prozorova",
      "Anton Konev",
      "Vladimir Faerman"
    ],
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13360",
    "title": "UCRBench: Benchmarking LLMs on Use Case Recovery",
    "abstract": "Use cases are widely employed to specify functional requirements, yet existing benchmarks are scarce and face the risk of being misaligned with actual system behavior, similarly limiting the rigorous evaluation of large language models (LLMs) in generating use cases from source code. We address this gap by introducing code-aligned use case benchmarks, constructed through manual validation of both user-goal and subfunction use cases across nine real-world software projects. Using this benchmark, we conduct the first systematic study of LLMs and propose a hierarchical evaluation protocol that assesses actor correctness, name accuracy, path fidelity, and behavioral coverage. The results show that while LLMs can partially reconstruct system functionality, their performance varies significantly across projects, with particularly noticeable shortcomings in domain-specific and multi-module systems. The models also exhibit high omission rates and struggle to maintain consistent abstraction when aggregating subfunctions into user-goal use cases, highlighting both the potential and current limitations of LLM-based use case reverse engineering.",
    "published": "2025-12-15T14:12:57Z",
    "authors": [
      "Shuyuan Xiao",
      "Yiran Zhang",
      "Weisong Sun",
      "Xiaohong Chen",
      "Yang Liu",
      "Zhi Jin"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13359",
    "title": "Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles",
    "abstract": "Autonomous Underwater Vehicles (AUVs) require reliable six-degree-of-freedom (6-DOF) position control to operate effectively in complex and dynamic marine environments. Traditional controllers are effective under nominal conditions but exhibit degraded performance when faced with unmodeled dynamics or environmental disturbances. Reinforcement learning (RL) provides a powerful alternative but training is typically slow and sim-to-real transfer remains challenging. This work introduces a GPU-accelerated RL training pipeline built in JAX and MuJoCo-XLA (MJX). By jointly JIT-compiling large-scale parallel physics simulation and learning updates, we achieve training times of under two minutes.Through systematic evaluation of multiple RL algorithms, we show robust 6-DOF trajectory tracking and effective disturbance rejection in real underwater experiments, with policies transferred zero-shot from simulation. Our results provide the first explicit real-world demonstration of RL-based AUV position control across all six degrees of freedom.",
    "published": "2025-12-15T14:12:32Z",
    "authors": [
      "Sümer Tunçay",
      "Alain Andres",
      "Ignacio Carlucho"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13356",
    "title": "Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)",
    "abstract": "This paper proposes a reinforcement learning (RL) framework for controlling and stabilizing the Twin Rotor Aerodynamic System (TRAS) at specific pitch and azimuth angles and tracking a given trajectory. The complex dynamics and non-linear characteristics of the TRAS make it challenging to control using traditional control algorithms. However, recent developments in RL have attracted interest due to their potential applications in the control of multirotors. The Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm was used in this paper to train the RL agent. This algorithm is used for environments with continuous state and action spaces, similar to the TRAS, as it does not require a model of the system. The simulation results illustrated the effectiveness of the RL control method. Next, external disturbances in the form of wind disturbances were used to test the controller's effectiveness compared to conventional PID controllers. Lastly, experiments on a laboratory setup were carried out to confirm the controller's effectiveness in real-world applications.",
    "published": "2025-12-15T14:10:04Z",
    "authors": [
      "Zeyad Gamal",
      "Youssef Mahran",
      "Ayman El-Badawy"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13352",
    "title": "On the Effectiveness of Membership Inference in Targeted Data Extraction from Large Language Models",
    "abstract": "Large Language Models (LLMs) are prone to memorizing training data, which poses serious privacy risks. Two of the most prominent concerns are training data extraction and Membership Inference Attacks (MIAs). Prior research has shown that these threats are interconnected: adversaries can extract training data from an LLM by querying the model to generate a large volume of text and subsequently applying MIAs to verify whether a particular data point was included in the training set. In this study, we integrate multiple MIA techniques into the data extraction pipeline to systematically benchmark their effectiveness. We then compare their performance in this integrated setting against results from conventional MIA benchmarks, allowing us to evaluate their practical utility in real-world extraction scenarios.",
    "published": "2025-12-15T14:05:49Z",
    "authors": [
      "Ali Al Sahili",
      "Ali Chehab",
      "Razane Tajeddine"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13340",
    "title": "Link-Aware Energy-Frugal Continual Learning for Fault Detection in IoT Networks",
    "abstract": "The use of lightweight machine learning (ML) models in internet of things (IoT) networks enables resource constrained IoT devices to perform on-device inference for several critical applications. However, the inference accuracy deteriorates due to the non-stationarity in the IoT environment and limited initial training data. To counteract this, the deployed models can be updated occasionally with new observed data samples. However, this approach consumes additional energy, which is undesirable for energy constrained IoT devices. This letter introduces an event-driven communication framework that strategically integrates continual learning (CL) in IoT networks for energy-efficient fault detection. Our framework enables the IoT device and the edge server (ES) to collaboratively update the lightweight ML model by adapting to the wireless link conditions for communication and the available energy budget. Evaluation on real-world datasets show that the proposed approach can outperform both periodic sampling and non-adaptive CL in terms of inference recall; our proposed approach achieves up to a 42.8% improvement, even under tight energy and bandwidth constraint.",
    "published": "2025-12-15T13:54:38Z",
    "authors": [
      "Henrik C. M. Frederiksen",
      "Junya Shiraishi",
      "Cedomir Stefanovic",
      "Hei Victor Cheng",
      "Shashi Raj Pandey"
    ],
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13337",
    "title": "FROC: A Unified Framework with Risk-Optimized Control for Machine Unlearning in LLMs",
    "abstract": "Machine unlearning (MU) seeks to eliminate the influence of specific training examples from deployed models. As large language models (LLMs) become widely used, managing risks arising from insufficient forgetting or utility loss is increasingly crucial. Current MU techniques lack effective mechanisms for evaluating and controlling these risks, hindering the selection of strategies that appropriately balance safety and utility, and raising trust concerns surrounding the \"right to be forgotten.\" To address these issues, we propose FROC, a unified framework with Risk-Optimized Control for machine unlearning in LLMs. FROC is built around a conformal-style risk-control formulation that expresses a user-specified risk budget on unlearning behavior. This probability-based constraint enables FROC to compare MU strategies, identify feasible operating regions, and guide hyperparameter selection according to desired trade-offs between forgetting sufficiency and utility preservation. To operationalize this constraint, FROC introduces a smoothly varying continuous risk model that aggregates forgetting deficiency and utility degradation into a single configuration-level score. Building on conformal risk analysis, FROC computes (1) the Conformal Unlearning Risk (CUR), a data-driven estimated value on the probability that forgotten samples continue to influence model predictions, and (2) risk-controlled configuration sets, which identify unlearning hyperparameters that are valid under the specified risk budget. Experiments across multiple LLM MU methods demonstrate that FROC produces stable, interpretable risk landscapes and reveals consistent relationships between unlearning configurations, semantic shift, and utility impact. FROC reframes MU as a controllable, risk-aware process and offers a practical foundation for managing unlearning behavior in large-scale LLM deployments.",
    "published": "2025-12-15T13:53:12Z",
    "authors": [
      "Si Qi Goh",
      "Yongsen Zheng",
      "Ziyao Liu",
      "Sami Hormi",
      "Kwok-Yan Lam"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13336",
    "title": "KD-PINN: Knowledge-Distilled PINNs for ultra-low-latency real-time neural PDE solvers",
    "abstract": "This work introduces Knowledge-Distilled Physics-Informed Neural Networks (KD-PINN), a framework that transfers the predictive accuracy of a high-capacity teacher model to a compact student through a continuous adaptation of the Kullback-Leibler divergence. To confirm its generality for various dynamics and dimensionalities, the framework is evaluated on a representative set of partial differential equations (PDEs). In all tested cases, the student model preserved the teacher's physical accuracy, with a mean RMSE increase below 0.64%, and achieved inference speedups ranging from 4.8x (Navier-Stokes) to 6.9x (Burgers). The distillation process also revealed a regularizing effect. With an average inference latency of 5.3 ms on CPU, the distilled models enter the ultra-low-latency real-time regime defined by sub-10 ms performance. Finally, this study examines how knowledge distillation reduces inference latency in PINNs to contribute to the development of accurate ultra-low-latency neural PDE solvers.",
    "published": "2025-12-15T13:51:20Z",
    "authors": [
      "Karim Bounja",
      "Lahcen Laayouni",
      "Abdeljalil Sakat"
    ],
    "categories": [
      "cs.LG",
      "math.NA"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13333",
    "title": "Quantum Disruption: An SOK of How Post-Quantum Attackers Reshape Blockchain Security and Performance",
    "abstract": "As quantum computing advances toward practical deployment, it threatens a wide range of classical cryptographic mechanisms, including digital signatures, key exchange protocols, public-key encryption, and certain hash-based constructions that underpin modern network infrastructures. These primitives form the security backbone of most blockchain platforms, raising serious concerns about the long-term viability of blockchain systems in a post-quantum world. Although migrating to post-quantum cryptography may appear straightforward, the substantially larger key sizes and higher computational costs of post-quantum primitives can introduce significant challenges and, in some cases, render such transitions impractical for blockchain environments.   In this paper, we examine the implications of adopting post-quantum cryptography in blockchain systems across four key dimensions. We begin by identifying the cryptographic primitives within blockchain architectures that are most vulnerable to quantum attacks, particularly those used in consensus mechanisms, identity management, and transaction validation. We then survey proposed post-quantum adaptations across existing blockchain designs, analyzing their feasibility within decentralized and resource-constrained settings. Building on this analysis, we evaluate how replacing classical primitives with post-quantum alternatives affects system performance, protocol dynamics, and the incentive and trust structures that sustain blockchain ecosystems. Our study demonstrates that integrating post-quantum signature schemes into blockchain systems is not a simple drop-in replacement; instead, it requires careful architectural redesign, as naive substitutions risk undermining both security guarantees and operational efficiency.",
    "published": "2025-12-15T13:48:14Z",
    "authors": [
      "Tushin Mallick",
      "Maya Zeldin",
      "Murat Cenk",
      "Cristina Nita-Rotaru"
    ],
    "categories": [
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13330",
    "title": "FIN-bench-v2: A Unified and Robust Benchmark Suite for Evaluating Finnish Large Language Models",
    "abstract": "We introduce FIN-bench-v2, a unified benchmark suite for evaluating large language models in Finnish. FIN-bench-v2 consolidates Finnish versions of widely used benchmarks together with an updated and expanded version of the original FIN-bench into a single, consistently formatted collection, covering multiple-choice and generative tasks across reading comprehension, commonsense reasoning, sentiment analysis, world knowledge, and alignment. All datasets are converted to HuggingFace Datasets, which include both cloze and multiple-choice prompt formulations with five variants per task, and we incorporate human annotation or review for machine-translated resources such as GoldenSwag and XED. To select robust tasks, we pretrain a set of 2.15B-parameter decoder-only models and use their learning curves to compute monotonicity, signal-to-noise, non-random performance, and model ordering consistency, retaining only tasks that satisfy all criteria. We further evaluate a set of larger instruction-tuned models to characterize performance across tasks and prompt formulations. All datasets, prompts, and evaluation configurations are publicly available via our fork of the Language Model Evaluation Harness at https://github.com/LumiOpen/lm-evaluation-harness. Supplementary resources are released in a separate repository at https://github.com/TurkuNLP/FIN-bench-v2.",
    "published": "2025-12-15T13:41:41Z",
    "authors": [
      "Joona Kytöniemi",
      "Jousia Piha",
      "Akseli Reunamo",
      "Fedor Vitiugin",
      "Farrokh Mehryary",
      "Sampo Pyysalo"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13325",
    "title": "Security and Detectability Analysis of Unicode Text Watermarking Methods Against Large Language Models",
    "abstract": "Securing digital text is becoming increasingly relevant due to the widespread use of large language models. Individuals' fear of losing control over data when it is being used to train such machine learning models or when distinguishing model-generated output from text written by humans. Digital watermarking provides additional protection by embedding an invisible watermark within the data that requires protection. However, little work has been taken to analyze and verify if existing digital text watermarking methods are secure and undetectable by large language models. In this paper, we investigate the security-related area of watermarking and machine learning models for text data. In a controlled testbed of three experiments, ten existing Unicode text watermarking methods were implemented and analyzed across six large language models: GPT-5, GPT-4o, Teuken 7B, Llama 3.3, Claude Sonnet 4, and Gemini 2.5 Pro. The findings of our experiments indicate that, especially the latest reasoning models, can detect a watermarked text. Nevertheless, all models fail to extract the watermark unless implementation details in the form of source code are provided. We discuss the implications for security researchers and practitioners and outline future research opportunities to address security concerns.",
    "published": "2025-12-15T13:40:00Z",
    "authors": [
      "Malte Hellmeier"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13323",
    "title": "Error-Driven Prompt Optimization for Arithmetic Reasoning",
    "abstract": "Recent advancements in artificial intelligence have sparked interest in industrial agents capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation Agent (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evaluation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arithmetic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iteratively, dramatically improves performance, elevating the model's accuracy to 70.8\\%. Our results suggest that developing reliable, interpretable, and industrially deployable AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger language models (GPT-3.5 Turbo) in a privacy-compliant manner.",
    "published": "2025-12-15T13:39:14Z",
    "authors": [
      "Árpád Pándy",
      "Róbert Lakatos",
      "András Hajdu"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13319",
    "title": "Temporal parallelisation of continuous-time maximum-a-posteriori trajectory estimation",
    "abstract": "This paper proposes a parallel-in-time method for computing continuous-time maximum-a-posteriori (MAP) trajectory estimates of the states of partially observed stochastic differential equations (SDEs), with the goal of improving computational speed on parallel architectures. The MAP estimation problem is reformulated as a continuous-time optimal control problem based on the Onsager-Machlup functional. This reformulation enables the use of a previously proposed parallel-in-time solution for optimal control problems, which we adapt to the current problem. The structure of the resulting optimal control problem admits a parallel solution based on parallel associative scan algorithms. In the linear Gaussian special case, it yields a parallel Kalman-Bucy filter and a parallel continuous-time Rauch-Tung-Striebel smoother. These linear computational methods are further extended to nonlinear continuous-time state-space models through Taylor expansions. We also present the corresponding parallel two-filter smoother. The graphics processing unit (GPU) experiments on linear and nonlinear models demonstrate that the proposed framework achieves a significant speedup in computations while maintaining the accuracy of sequential algorithms.",
    "published": "2025-12-15T13:37:14Z",
    "authors": [
      "Hassan Razavi",
      "Ángel F. García-Fernández",
      "Simo Särkkä"
    ],
    "categories": [
      "cs.DC",
      "eess.SP",
      "eess.SY",
      "stat.CO"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13317",
    "title": "Face Identity Unlearning for Retrieval via Embedding Dispersion",
    "abstract": "Face recognition systems rely on learning highly discriminative and compact identity clusters to enable accurate retrieval. However, as with other surveillance-oriented technologies, such systems raise serious privacy concerns due to their potential for unauthorized identity tracking. While several works have explored machine unlearning as a means of privacy protection, their applicability to face retrieval - especially for modern embedding-based recognition models - remains largely unexplored. In this work, we study the problem of face identity unlearning for retrieval systems and present its inherent challenges. The goal is to make selected identities unretrievable by dispersing their embeddings on the hypersphere and preventing the formation of compact identity clusters that enable re-identification in the gallery. The primary challenge is to achieve this forgetting effect while preserving the discriminative structure of the embedding space and the retrieval performance of the model for the remaining identities. To address this, we evaluate several existing approximate class unlearning methods (e.g., Random Labeling, Gradient Ascent, Boundary Unlearning, and other recent approaches) in the context of face retrieval and propose a simple yet effective dispersion-based unlearning approach. Extensive experiments on standard benchmarks (VGGFace2, CelebA) demonstrate that our method achieves superior forgetting behavior while preserving retrieval utility.",
    "published": "2025-12-15T13:35:28Z",
    "authors": [
      "Mikhail Zakharov"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13316",
    "title": "ALIGN-FL: Architecture-independent Learning through Invariant Generative component sharing in Federated Learning",
    "abstract": "We present ALIGN-FL, a novel approach to distributed learning that addresses the challenge of learning from highly disjoint data distributions through selective sharing of generative components. Instead of exchanging full model parameters, our framework enables privacy-preserving learning by transferring only generative capabilities across clients, while the server performs global training using synthetic samples. Through complementary privacy mechanisms: DP-SGD with adaptive clipping and Lipschitz regularized VAE decoders and a stateful architecture supporting heterogeneous clients, we experimentally validate our approach on MNIST and Fashion-MNIST datasets with cross-domain outliers. Our analysis demonstrates that both privacy mechanisms effectively map sensitive outliers to typical data points while maintaining utility in extreme Non-IID scenarios typical of cross-silo collaborations.   Index Terms: Client-invariant Learning, Federated Learning (FL), Privacy-preserving Generative Models, Non-Independent and Identically Distributed (Non-IID), Heterogeneous Architectures",
    "published": "2025-12-15T13:35:27Z",
    "authors": [
      "Mayank Gulati",
      "Benedikt Groß",
      "Gerhard Wunder"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13313",
    "title": "KlingAvatar 2.0 Technical Report",
    "abstract": "Avatar video generation models have achieved remarkable progress in recent years. However, prior work exhibits limited efficiency in generating long-duration high-resolution videos, suffering from temporal drifting, quality degradation, and weak prompt following as video length increases. To address these challenges, we propose KlingAvatar 2.0, a spatio-temporal cascade framework that performs upscaling in both spatial resolution and temporal dimension. The framework first generates low-resolution blueprint video keyframes that capture global semantics and motion, and then refines them into high-resolution, temporally coherent sub-clips using a first-last frame strategy, while retaining smooth temporal transitions in long-form videos. To enhance cross-modal instruction fusion and alignment in extended videos, we introduce a Co-Reasoning Director composed of three modality-specific large language model (LLM) experts. These experts reason about modality priorities and infer underlying user intent, converting inputs into detailed storylines through multi-turn dialogue. A Negative Director further refines negative prompts to improve instruction alignment. Building on these components, we extend the framework to support ID-specific multi-character control. Extensive experiments demonstrate that our model effectively addresses the challenges of efficient, multimodally aligned long-form high-resolution video generation, delivering enhanced visual clarity, realistic lip-teeth rendering with accurate lip synchronization, strong identity preservation, and coherent multimodal instruction following.",
    "published": "2025-12-15T13:30:51Z",
    "authors": [
      "Kling Team",
      "Jialu Chen",
      "Yikang Ding",
      "Zhixue Fang",
      "Kun Gai",
      "Yuan Gao",
      "Kang He",
      "Jingyun Hua",
      "Boyuan Jiang",
      "Mingming Lao",
      "Xiaohan Li",
      "Hui Liu",
      "Jiwen Liu",
      "Xiaoqiang Liu",
      "Yuan Liu",
      "Shun Lu",
      "Yongsen Mao",
      "Yingchao Shao",
      "Huafeng Shi",
      "Xiaoyu Shi",
      "Peiqin Sun",
      "Songlin Tang",
      "Pengfei Wan",
      "Chao Wang",
      "Xuebo Wang",
      "Haoxian Zhang",
      "Yuanxing Zhang",
      "Yan Zhou"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13303",
    "title": "ShowTable: Unlocking Creative Table Visualization with Collaborative Reflection and Refinement",
    "abstract": "While existing generation and unified models excel at general image generation, they struggle with tasks requiring deep reasoning, planning, and precise data-to-visual mapping abilities beyond general scenarios. To push beyond the existing limitations, we introduce a new and challenging task: creative table visualization, requiring the model to generate an infographic that faithfully and aesthetically visualizes the data from a given table. To address this challenge, we propose ShowTable, a pipeline that synergizes MLLMs with diffusion models via a progressive self-correcting process. The MLLM acts as the central orchestrator for reasoning the visual plan and judging visual errors to provide refined instructions, the diffusion execute the commands from MLLM, achieving high-fidelity results. To support this task and our pipeline, we introduce three automated data construction pipelines for training different modules. Furthermore, we introduce TableVisBench, a new benchmark with 800 challenging instances across 5 evaluation dimensions, to assess performance on this task. Experiments demonstrate that our pipeline, instantiated with different models, significantly outperforms baselines, highlighting its effective multi-modal reasoning, generation, and error correction capabilities.",
    "published": "2025-12-15T13:21:50Z",
    "authors": [
      "Zhihang Liu",
      "Xiaoyi Bao",
      "Pandeng Li",
      "Junjie Zhou",
      "Zhaohe Liao",
      "Yefei He",
      "Kaixun Jiang",
      "Chen-Wei Xie",
      "Yun Zheng",
      "Hongtao Xie"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13300",
    "title": "No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction",
    "abstract": "In most real-world online advertising systems, advertisers typically have diverse customer acquisition goals. A common solution is to use multi-task learning (MTL) to train a unified model on post-click data to estimate the conversion rate (CVR) for these diverse targets. In practice, CVR prediction often encounters missing conversion data as many advertisers submit only a subset of user conversion actions due to privacy or other constraints, making the labels of multi-task data incomplete. If the model is trained on all available samples where advertisers submit user conversion actions, it may struggle when deployed to serve a subset of advertisers targeting specific conversion actions, as the training and deployment data distributions are mismatched. While considerable MTL efforts have been made, a long-standing challenge is how to effectively train a unified model with the incomplete and skewed multi-label data. In this paper, we propose a fine-grained Knowledge transfer framework for Asymmetric Multi-Label data (KAML). We introduce an attribution-driven masking strategy (ADM) to better utilize data with asymmetric multi-label data in training. However, the more relaxed masking in ADM is a double-edged sword: it provides additional training signals but also introduces noise due to skewed data. To address this, we propose a hierarchical knowledge extraction mechanism (HKE) to model the sample discrepancy within the target task tower. Finally, to maximize the utility of unlabeled samples, we incorporate ranking loss strategy to further enhance our model. The effectiveness of KAML has been demonstrated through comprehensive evaluations on offline industry datasets and online A/B tests, which show significant performance improvements over existing MTL baselines.",
    "published": "2025-12-15T13:14:20Z",
    "authors": [
      "Qinglin Jia",
      "Zhaocheng Du",
      "Chuhan Wu",
      "Huifeng Guo",
      "Ruiming Tang",
      "Shuting Shi",
      "Muyu Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13298",
    "title": "MiniLingua: A Small Open-Source LLM for European Languages",
    "abstract": "Large language models are powerful but often limited by high computational cost, privacy concerns, and English-centric training. Recent progress demonstrates that small, efficient models with around one billion parameters can deliver strong results and enable on-device use. This paper introduces MiniLingua, a multilingual open-source LLM of one billion parameters trained from scratch for 13 European languages, designed to balance coverage and instruction-following capabilities. Based on evaluation results, the instruction-tuned version of MiniLingua outperforms EuroLLM, a model with a similar training approach but a larger training budget, on summarization, classification and both open- and closed-book question answering. Moreover, it remains competitive with more advanced state-of-the-art models on open-ended generation tasks. We release model weights, tokenizer and source code used for data processing and model training.",
    "published": "2025-12-15T13:12:42Z",
    "authors": [
      "Anna Aksenova",
      "Boris Zverkov",
      "Nicola Dainese",
      "Alexander Nikitin",
      "Pekka Marttinen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13297",
    "title": "MedInsightBench: Evaluating Medical Analytics Agents Through Multi-Step Insight Discovery in Multimodal Medical Data",
    "abstract": "In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and agent frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated agent framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight Agent, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.",
    "published": "2025-12-15T13:10:42Z",
    "authors": [
      "Zhenghao Zhu",
      "Chuxue Cao",
      "Sirui Han",
      "Yuanfeng Song",
      "Xing Chen",
      "Caleb Chen Cao",
      "Yike Guo"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13293",
    "title": "Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration",
    "abstract": "This paper investigates the application of reinforcement learning (RL) to multi-robot social formation navigation, a critical capability for enabling seamless human-robot coexistence. While RL offers a promising paradigm, the inherent unpredictability and often uncooperative dynamics of pedestrian behavior pose substantial challenges, particularly concerning the efficiency of coordinated exploration among robots. To address this, we propose a novel coordinated-exploration multi-robot RL algorithm introducing an intrinsic motivation exploration. Its core component is a self-learning intrinsic reward mechanism designed to collectively alleviate policy conservatism. Moreover, this algorithm incorporates a dual-sampling mode within the centralized training and decentralized execution framework to enhance the representation of both the navigation policy and the intrinsic reward, leveraging a two-time-scale update rule to decouple parameter updates. Empirical results on social formation navigation benchmarks demonstrate the proposed algorithm's superior performance over existing state-of-the-art methods across crucial metrics. Our code and video demos are available at: https://github.com/czxhunzi/CEMRRL.",
    "published": "2025-12-15T13:03:08Z",
    "authors": [
      "Hao Fua",
      "Wei Liu",
      "Shuai Zhoua"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13290",
    "title": "LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models",
    "abstract": "Diffusion models (DMs) have achieved remarkable success in image and video generation. However, they still struggle with (1) physical alignment and (2) out-of-distribution (OOD) instruction following. We argue that these issues stem from the models' failure to learn causal directions and to disentangle causal factors for novel recombination. We introduce the Causal Scene Graph (CSG) and the Physical Alignment Probe (PAP) dataset to enable diagnostic interventions. This analysis yields three key insights. First, DMs struggle with multi-hop reasoning for elements not explicitly determined in the prompt. Second, the prompt embedding contains disentangled representations for texture and physics. Third, visual causal structure is disproportionately established during the initial, computationally limited denoising steps. Based on these findings, we introduce LINA (Learning INterventions Adaptively), a novel framework that learns to predict prompt-specific interventions, which employs (1) targeted guidance in the prompt and visual latent spaces, and (2) a reallocated, causality-aware denoising schedule. Our approach enforces both physical alignment and OOD instruction following in image and video DMs, achieving state-of-the-art performance on challenging causal generation tasks and the Winoground dataset. Our project page is at https://opencausalab.github.io/LINA.",
    "published": "2025-12-15T12:59:59Z",
    "authors": [
      "Shu Yu",
      "Chaochao Lu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13286",
    "title": "Integrating Causal Reasoning into Automated Fact-Checking",
    "abstract": "In fact-checking applications, a common reason to reject a claim is to detect the presence of erroneous cause-effect relationships between the events at play. However, current automated fact-checking methods lack dedicated causal-based reasoning, potentially missing a valuable opportunity for semantically rich explainability. To address this gap, we propose a methodology that combines event relation extraction, semantic similarity computation, and rule-based reasoning to detect logical inconsistencies between chains of events mentioned in a claim and in an evidence. Evaluated on two fact-checking datasets, this method establishes the first baseline for integrating fine-grained causal event relationships into fact-checking and enhance explainability of verdict prediction.",
    "published": "2025-12-15T12:56:00Z",
    "authors": [
      "Youssra Rebboud",
      "Pasquale Lisena",
      "Raphael Troncy"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13285",
    "title": "CausalCLIP: Causally-Informed Feature Disentanglement and Filtering for Generalizable Detection of Generated Images",
    "abstract": "The rapid advancement of generative models has increased the demand for generated image detectors capable of generalizing across diverse and evolving generation techniques. However, existing methods, including those leveraging pre-trained vision-language models, often produce highly entangled representations, mixing task-relevant forensic cues (causal features) with spurious or irrelevant patterns (non-causal features), thus limiting generalization. To address this issue, we propose CausalCLIP, a framework that explicitly disentangles causal from non-causal features and employs targeted filtering guided by causal inference principles to retain only the most transferable and discriminative forensic cues. By modeling the generation process with a structural causal model and enforcing statistical independence through Gumbel-Softmax-based feature masking and Hilbert-Schmidt Independence Criterion (HSIC) constraints, CausalCLIP isolates stable causal features robust to distribution shifts. When tested on unseen generative models from different series, CausalCLIP demonstrates strong generalization ability, achieving improvements of 6.83% in accuracy and 4.06% in average precision over state-of-the-art methods.",
    "published": "2025-12-15T12:48:27Z",
    "authors": [
      "Bo Liu",
      "Qiao Qin",
      "Qinghui He"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13281",
    "title": "Video Reality Test: Can AI-Generated ASMR Videos fool VLMs and Humans?",
    "abstract": "Recent advances in video generation have produced vivid content that are often indistinguishable from real videos, making AI-generated video detection an emerging societal challenge. Prior AIGC detection benchmarks mostly evaluate video without audio, target broad narrative domains, and focus on classification solely. Yet it remains unclear whether state-of-the-art video generation models can produce immersive, audio-paired videos that reliably deceive humans and VLMs. To this end, we introduce Video Reality Test, an ASMR-sourced video benchmark suite for testing perceptual realism under tight audio-visual coupling, featuring the following dimensions: \\textbf{(i) Immersive ASMR video-audio sources.} Built on carefully curated real ASMR videos, the benchmark targets fine-grained action-object interactions with diversity across objects, actions, and backgrounds. \\textbf{(ii) Peer-Review evaluation.} An adversarial creator-reviewer protocol where video generation models act as creators aiming to fool reviewers, while VLMs serve as reviewers seeking to identify fakeness. Our experimental findings show: The best creator Veo3.1-Fast even fools most VLMs: the strongest reviewer (Gemini 2.5-Pro) achieves only 56\\% accuracy (random 50\\%), far below that of human experts (81.25\\%). Adding audio improves real-fake discrimination, yet superficial cues such as watermarks can still significantly mislead models. These findings delineate the current boundary of video generation realism and expose limitations of VLMs in perceptual fidelity and audio-visual consistency. Our code is available at https://github.com/video-reality-test/video-reality-test.",
    "published": "2025-12-15T12:41:23Z",
    "authors": [
      "Jiaqi Wang",
      "Weijia Wu",
      "Yi Zhan",
      "Rui Zhao",
      "Ming Hu",
      "James Cheng",
      "Wei Liu",
      "Philip Torr",
      "Kevin Qinghong Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13279",
    "title": "AIR: Post-training Data Selection for Reasoning via Attention Head Influence",
    "abstract": "LLMs achieve remarkable multi-step reasoning capabilities, yet effectively transferring these skills via post-training distillation remains challenging. Existing data selection methods, ranging from manual curation to heuristics based on length, entropy, or overall loss, fail to capture the causal importance of individual reasoning steps, limiting distillation efficiency. To address this, we propose Attention Influence for Reasoning (AIR), a principled, unsupervised and training-free framework that leverages mechanistic insights of the retrieval head to select high-value post-training data. AIR first identifies reasoning-critical attention heads of an off-the-shelf model, then constructs a weakened reference model with disabled head influence, and finally quantifies the resulting loss divergence as the Attention Influence Score. This score enables fine-grained assessment at both the step and sample levels, supporting step-level weighted fine-tuning and global sample selection. Experiments across multiple reasoning benchmarks show that AIR consistently improves reasoning accuracy, surpassing heuristic baselines and effectively isolating the most critical steps and samples. Our work establishes a mechanism-driven, data-efficient approach for reasoning distillation in LLMs.",
    "published": "2025-12-15T12:38:24Z",
    "authors": [
      "Jinrui Liu",
      "Jeff Wu",
      "Xuanguang Pan",
      "Gavin Cheung",
      "Shuai Ma",
      "Chongyang Tao"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13278",
    "title": "AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning",
    "abstract": "Agentic reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM agents' adaptability to new or evolving toolsets. We present AutoTool, a framework that equips LLM agents with dynamic tool-selection capabilities throughout their reasoning trajectories. We first construct a 200k dataset with explicit tool-selection rationales across 1,000+ tools and 100+ tasks spanning mathematics, science, code generation, and multimodal reasoning. Building on this data foundation, AutoTool employs a dual-phase optimization pipeline: (i) supervised and RL-based trajectory stabilization for coherent reasoning, and (ii) KL-regularized Plackett-Luce ranking to refine consistent multi-step tool selection. Across ten diverse benchmarks, we train two base models, Qwen3-8B and Qwen2.5-VL-7B, with AutoTool. With fewer parameters, AutoTool consistently outperforms advanced LLM agents and tool-integration methods, yielding average gains of 6.4% in math & science reasoning, 4.5% in search-based QA, 7.7% in code generation, and 6.9% in multimodal understanding. In addition, AutoTool exhibits stronger generalization by dynamically leveraging unseen tools from evolving toolsets during inference.",
    "published": "2025-12-15T12:38:04Z",
    "authors": [
      "Jiaru Zou",
      "Ling Yang",
      "Yunzhe Qi",
      "Sirui Chen",
      "Mengting Ai",
      "Ke Shen",
      "Jingrui He",
      "Mengdi Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13276",
    "title": "CogniEdit: Dense Gradient Flow Optimization for Fine-Grained Image Editing",
    "abstract": "Instruction-based image editing with diffusion models has achieved impressive results, yet existing methods struggle with fine-grained instructions specifying precise attributes such as colors, positions, and quantities. While recent approaches employ Group Relative Policy Optimization (GRPO) for alignment, they optimize only at individual sampling steps, providing sparse feedback that limits trajectory-level control. We propose a unified framework CogniEdit, combining multi-modal reasoning with dense reward optimization that propagates gradients across consecutive denoising steps, enabling trajectory-level gradient flow through the sampling process. Our method comprises three components: (1) Multi-modal Large Language Models for decomposing complex instructions into actionable directives, (2) Dynamic Token Focus Relocation that adaptively emphasizes fine-grained attributes, and (3) Dense GRPO-based optimization that propagates gradients across consecutive steps for trajectory-level supervision. Extensive experiments on benchmark datasets demonstrate that our CogniEdit achieves state-of-the-art performance in balancing fine-grained instruction following with visual quality and editability preservation",
    "published": "2025-12-15T12:36:50Z",
    "authors": [
      "Yan Li",
      "Lin Liu",
      "Xiaopeng Zhang",
      "Wei Xue",
      "Wenhan Luo",
      "Yike Guo",
      "Qi Tian"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13268",
    "title": "SPARS: A Reinforcement Learning-Enabled Simulator for Power Management in HPC Job Scheduling",
    "abstract": "High-performance computing (HPC) clusters consume enormous amounts of energy, with idle nodes as a major source of waste. Powering down unused nodes can mitigate this problem, but poorly timed transitions introduce long delays and reduce overall performance. To address this trade-off, we present SPARS, a reinforcement learning-enabled simulator for power management in HPC job scheduling. SPARS integrates job scheduling and node power state management within a discrete-event simulation framework. It supports traditional scheduling policies such as First Come First Served and EASY Backfilling, along with enhanced variants that employ reinforcement learning agents to dynamically decide when nodes should be powered on or off. Users can configure workloads and platforms in JSON format, specifying job arrivals, execution times, node power models, and transition delays. The simulator records comprehensive metrics-including energy usage, wasted power, job waiting times, and node utilization-and provides Gantt chart visualizations to analyze scheduling dynamics and power transitions. Unlike widely used Batsim-based frameworks that rely on heavy inter-process communication, SPARS provides lightweight event handling and consistent simulation results, making experiments easier to reproduce and extend. Its modular design allows new scheduling heuristics or learning algorithms to be integrated with minimal effort. By providing a flexible, reproducible, and extensible platform, SPARS enables researchers and practitioners to systematically evaluate power-aware scheduling strategies, explore the trade-offs between energy efficiency and performance, and accelerate the development of sustainable HPC operations.",
    "published": "2025-12-15T12:28:08Z",
    "authors": [
      "Muhammad Alfian Amrizal",
      "Raka Satya Prasasta",
      "Santana Yuda Pradata",
      "Kadek Gemilang Santiyuda",
      "Reza Pulungan",
      "Hiroyuki Takizawa"
    ],
    "categories": [
      "cs.DC"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13262",
    "title": "Post-Training and Test-Time Scaling of Generative Agent Behavior Models for Interactive Autonomous Driving",
    "abstract": "Learning interactive motion behaviors among multiple agents is a core challenge in autonomous driving. While imitation learning models generate realistic trajectories, they often inherit biases from datasets dominated by safe demonstrations, limiting robustness in safety-critical cases. Moreover, most studies rely on open-loop evaluation, overlooking compounding errors in closed-loop execution. We address these limitations with two complementary strategies. First, we propose Group Relative Behavior Optimization (GRBO), a reinforcement learning post-training method that fine-tunes pretrained behavior models via group relative advantage maximization with human regularization. Using only 10% of the training dataset, GRBO improves safety performance by over 40% while preserving behavioral realism. Second, we introduce Warm-K, a warm-started Top-K sampling strategy that balances consistency and diversity in motion selection. Our Warm-K method-based test-time scaling enhances behavioral consistency and reactivity at test time without retraining, mitigating covariate shift and reducing performance discrepancies. Demo videos are available in the supplementary material.",
    "published": "2025-12-15T12:18:50Z",
    "authors": [
      "Hyunki Seong",
      "Jeong-Kyun Lee",
      "Heesoo Myeong",
      "Yongho Shin",
      "Hyun-Mook Cho",
      "Duck Hoon Kim",
      "Pranav Desai",
      "Monu Surana"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13255",
    "title": "BézierFlow: Bézier Stochastic Interpolant Schedulers for Few-Step Generation",
    "abstract": "We introduce BézierFlow, a lightweight training approach for few-step generation with pretrained diffusion and flow models. BézierFlow achieves a 2-3x performance improvement for sampling with $\\leq$ 10 NFEs while requiring only 15 minutes of training. Recent lightweight training approaches have shown promise by learning optimal timesteps, but their scope remains restricted to ODE discretizations. To broaden this scope, we propose learning the optimal transformation of the sampling trajectory by parameterizing stochastic interpolant (SI) schedulers. The main challenge lies in designing a parameterization that satisfies critical desiderata, including boundary conditions, differentiability, and monotonicity of the SNR. To effectively meet these requirements, we represent scheduler functions as Bézier functions, where control points naturally enforce these properties. This reduces the problem to learning an ordered set of points in the time range, while the interpretation of the points changes from ODE timesteps to Bézier control points. Across a range of pretrained diffusion and flow models, BézierFlow consistently outperforms prior timestep-learning methods, demonstrating the effectiveness of expanding the search space from discrete timesteps to Bézier-based trajectory transformations.",
    "published": "2025-12-15T12:09:32Z",
    "authors": [
      "Yunhong Min",
      "Juil Koo",
      "Seungwoo Yoo",
      "Minhyuk Sung"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13250",
    "title": "Toward Ambulatory Vision: Learning Visually-Grounded Active View Selection",
    "abstract": "Vision Language Models (VLMs) excel at visual question answering (VQA) but remain limited to snapshot vision, reasoning from static images. In contrast, embodied agents require ambulatory vision, actively moving to obtain more informative views. We introduce Visually Grounded Active View Selection (VG-AVS), a task that selects the most informative next viewpoint using only the visual information in the current image, without relying on scene memory or external knowledge. To support this task, we construct a synthetic dataset with automatically generated paired query-target views and question-answer prompts. We also propose a framework that fine-tunes pretrained VLMs through supervised fine-tuning (SFT) followed by RL-based policy optimization. Our approach achieves strong question answering performance based on viewpoint selection and generalizes robustly to unseen synthetic and real scenes. Furthermore, incorporating our learned VG-AVS framework into existing scene-exploration-based EQA systems improves downstream question-answering accuracy.",
    "published": "2025-12-15T12:04:26Z",
    "authors": [
      "Juil Koo",
      "Daehyeon Choi",
      "Sangwoo Youn",
      "Phillip Y. Lee",
      "Minhyuk Sung"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13247",
    "title": "STARCaster: Spatio-Temporal AutoRegressive Video Diffusion for Identity- and View-Aware Talking Portraits",
    "abstract": "This paper presents STARCaster, an identity-aware spatio-temporal video diffusion model that addresses both speech-driven portrait animation and free-viewpoint talking portrait synthesis, given an identity embedding or reference image, within a unified framework. Existing 2D speech-to-video diffusion models depend heavily on reference guidance, leading to limited motion diversity. At the same time, 3D-aware animation typically relies on inversion through pre-trained tri-plane generators, which often leads to imperfect reconstructions and identity drift. We rethink reference- and geometry-based paradigms in two ways. First, we deviate from strict reference conditioning at pre-training by introducing softer identity constraints. Second, we address 3D awareness implicitly within the 2D video domain by leveraging the inherent multi-view nature of video data. STARCaster adopts a compositional approach progressing from ID-aware motion modeling, to audio-visual synchronization via lip reading-based supervision, and finally to novel view animation through temporal-to-spatial adaptation. To overcome the scarcity of 4D audio-visual data, we propose a decoupled learning approach in which view consistency and temporal coherence are trained independently. A self-forcing training scheme enables the model to learn from longer temporal contexts than those generated at inference, mitigating the overly static animations common in existing autoregressive approaches. Comprehensive evaluations demonstrate that STARCaster generalizes effectively across tasks and identities, consistently surpassing prior approaches in different benchmarks.",
    "published": "2025-12-15T11:59:01Z",
    "authors": [
      "Foivos Paraperas Papantoniou",
      "Stathis Galanakis",
      "Rolandos Alexandros Potamias",
      "Bernhard Kainz",
      "Stefanos Zafeiriou"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13240",
    "title": "Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection",
    "abstract": "Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which both the chosen and rejected responses are generated by the same policy, suffers from a weak learning signal because the two responses often share similar errors and exhibit small Kullback-Leibler (KL) divergence. This leads to slow and unstable convergence. To address this limitation, we introduce Reflective Preference Optimization (RPO), a new framework that incorporates hint-guided reflection into the DPO paradigm. RPO uses external models to identify hallucination sources and generate concise reflective hints, enabling the construction of on-policy preference pairs with stronger contrastiveness and clearer preference signals. We theoretically show that conditioning on hints increases the expected preference margin through mutual information and improves sample efficiency while remaining within the policy distribution family. Empirically, RPO achieves superior alignment with fewer training samples and iterations, substantially reducing hallucination rates and delivering state-of-the-art performance across multimodal benchmarks.",
    "published": "2025-12-15T11:55:55Z",
    "authors": [
      "Zihui Zhao",
      "Zechang Li"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13239",
    "title": "A Decision Support Framework for Blockchain Pattern Selection Based on Soft Goals",
    "abstract": "Blockchain technology is gaining momentum across many sectors. Whereas blockchain solutions have important positive effects on the business domain, they also introduce constraints and may cause delayed or unforeseen negative effects, undermining business strategies. The diversity of blockchain patterns and lack of standardized frameworks linking business goals to technical design decisions make pattern selection a complex task for system architects. To address this challenge, we propose Blockchain--Technology-Aware Enterprise Modeling (BC-TEAEM), a decision support framework that combines ontologies of blockchain patterns and domain-independent soft goals with a multi-criteria decision-making approach. The framework focuses on the interplay between a domain expert and a technical expert to ensure alignment and traceability. By iteratively capturing and refining preferences, BC-TEAEM supports systematic selection of blockchain patterns. We develop a prototype decision support tool implementing our method and validate it through a case study of a pharmaceutical company's supply chain traceability system, demonstrating the framework's applicability. %a supply chain traceability case study.",
    "published": "2025-12-15T11:54:00Z",
    "authors": [
      "Eddy Kiomba Kambilo",
      "Nicolas Herbaut",
      "Irina Rychkova",
      "Carine Souveyet"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13238",
    "title": "Ego-EXTRA: video-language Egocentric Dataset for EXpert-TRAinee assistance",
    "abstract": "We present Ego-EXTRA, a video-language Egocentric Dataset for EXpert-TRAinee assistance. Ego-EXTRA features 50 hours of unscripted egocentric videos of subjects performing procedural activities (the trainees) while guided by real-world experts who provide guidance and answer specific questions using natural language. Following a ``Wizard of OZ'' data collection paradigm, the expert enacts a wearable intelligent assistant, looking at the activities performed by the trainee exclusively from their egocentric point of view, answering questions when asked by the trainee, or proactively interacting with suggestions during the procedures. This unique data collection protocol enables Ego-EXTRA to capture a high-quality dialogue in which expert-level feedback is provided to the trainee. Two-way dialogues between experts and trainees are recorded, transcribed, and used to create a novel benchmark comprising more than 15k high-quality Visual Question Answer sets, which we use to evaluate Multimodal Large Language Models. The results show that Ego-EXTRA is challenging and highlight the limitations of current models when used to provide expert-level assistance to the user. The Ego-EXTRA dataset is publicly available to support the benchmark of egocentric video-language assistants: https://fpv-iplab.github.io/Ego-EXTRA/.",
    "published": "2025-12-15T11:53:35Z",
    "authors": [
      "Francesco Ragusa",
      "Michele Mazzamuto",
      "Rosario Forte",
      "Irene D'Ambra",
      "James Fort",
      "Jakob Engel",
      "Antonino Furnari",
      "Giovanni Maria Farinella"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13237",
    "title": "Learning to Retrieve with Weakened Labels: Robust Training under Label Noise",
    "abstract": "Neural Encoders are frequently used in the NLP domain to perform dense retrieval tasks, for instance, to generate the candidate documents for a given query in question-answering tasks. However, sparse annotation and label noise in the training data make it challenging to train or fine-tune such retrieval models. Although existing works have attempted to mitigate these problems by incorporating modified loss functions or data cleaning, these approaches either require some hyperparameters to tune during training or add substantial complexity to the training setup. In this work, we consider a label weakening approach to generate robust retrieval models in the presence of label noise. Instead of enforcing a single, potentially erroneous label for each query document pair, we allow for a set of plausible labels derived from both the observed supervision and the model's confidence scores. We perform an extensive evaluation considering two retrieval models, one re-ranking model, considering four diverse ranking datasets. To this end, we also consider a realistic noisy setting by using a semantic-aware noise generation technique to generate different ratios of noise. Our initial results show that label weakening can improve the performance of the retrieval tasks in comparison to 10 different state-of-the-art loss functions.",
    "published": "2025-12-15T11:52:13Z",
    "authors": [
      "Arnab Sharma"
    ],
    "categories": [
      "cs.LG",
      "cs.IR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13235",
    "title": "CORE: Contrastive Masked Feature Reconstruction on Graphs",
    "abstract": "In the rapidly evolving field of self-supervised learning on graphs, generative and contrastive methodologies have emerged as two dominant approaches. Our study focuses on masked feature reconstruction (MFR), a generative technique where a model learns to restore the raw features of masked nodes in a self-supervised manner. We observe that both MFR and graph contrastive learning (GCL) aim to maximize agreement between similar elements. Building on this observation, we reveal a novel theoretical insight: under specific conditions, the objectives of MFR and node-level GCL converge, despite their distinct operational mechanisms. This theoretical connection suggests these approaches are complementary rather than fundamentally different, prompting us to explore their integration to enhance self-supervised learning on graphs. Our research presents Contrastive Masked Feature Reconstruction (CORE), a novel graph self-supervised learning framework that integrates contrastive learning into MFR. Specifically, we form positive pairs exclusively between the original and reconstructed features of masked nodes, encouraging the encoder to prioritize contextual information over the node's own features. Additionally, we leverage the masked nodes themselves as negative samples, combining MFR's reconstructive power with GCL's discriminative ability to better capture intrinsic graph structures. Empirically, our proposed framework CORE significantly outperforms MFR across node and graph classification tasks, demonstrating state-of-the-art results. In particular, CORE surpasses GraphMAE and GraphMAE2 by up to 2.80% and 3.72% on node classification tasks, and by up to 3.82% and 3.76% on graph classification tasks.",
    "published": "2025-12-15T11:48:48Z",
    "authors": [
      "Jianyuan Bo",
      "Yuan Fang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13228",
    "title": "ModSSC: A Modular Framework for Semi-Supervised Classification on Heterogeneous Data",
    "abstract": "Semi-supervised classification leverages both labeled and unlabeled data to improve predictive performance, but existing software support is fragmented across methods and modalities. We introduce ModSSC, an open source Python framework that unifies inductive and transductive semi-supervised classification in a modular code base. ModSSC implements a broad range of classical and recent algorithms, provides loaders for tabular, image, text, audio and graph datasets, and exposes a single configuration interface for specifying datasets, models and evaluation protocols. It supports both lightweight classical methods on small datasets running on CPU and recent deep approaches that can exploit multiple GPUs within the same experimental framework. Experiments are described declaratively in YAML, which facilitates reproducing existing work and running large comparative studies. ModSSC 1.0.0 is released under the MIT license with extensive documentation and tests, and is available at https://github.com/ModSSC/ModSSC.",
    "published": "2025-12-15T11:43:14Z",
    "authors": [
      "Melvin Barbaux"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13227",
    "title": "Better LMO-based Momentum Methods with Second-Order Information",
    "abstract": "The use of momentum in stochastic optimization algorithms has shown empirical success across a range of machine learning tasks. Recently, a new class of stochastic momentum algorithms has emerged within the Linear Minimization Oracle (LMO) framework--leading to state-of-the-art methods, such as Muon, Scion, and Gluon, that effectively solve deep neural network training problems. However, traditional stochastic momentum methods offer convergence guarantees no better than the ${O}(1/K^{1/4})$ rate. While several approaches--such as Hessian-Corrected Momentum (HCM)--have aimed to improve this rate, their theoretical results are generally restricted to the Euclidean norm setting. This limitation hinders their applicability in problems, where arbitrary norms are often required. In this paper, we extend the LMO-based framework by integrating HCM, and provide convergence guarantees under relaxed smoothness and arbitrary norm settings. We establish improved convergence rates of ${O}(1/K^{1/3})$ for HCM, which can adapt to the geometry of the problem and achieve a faster rate than traditional momentum. Experimental results on training Multi-Layer Perceptrons (MLPs) and Long Short-Term Memory (LSTM) networks verify our theoretical observations.",
    "published": "2025-12-15T11:43:09Z",
    "authors": [
      "Sarit Khirirat",
      "Abdurakhmon Sadiev",
      "Yury Demidovich",
      "Peter Richtárik"
    ],
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13217",
    "title": "Rethinking Physics-Informed Regression Beyond Training Loops and Bespoke Architectures",
    "abstract": "We revisit the problem of physics-informed regression, and propose a method that directly computes the state at the prediction point, simultaneously with the derivative and curvature information of the existing samples. We frame each prediction as a constrained optimisation problem, leveraging multivariate Taylor series expansions and explicitly enforcing physical laws. Each individual query can be processed with low computational cost without any pre- or re-training, in contrast to global function approximator-based solutions such as neural networks. Our comparative benchmarks on a reaction-diffusion system show competitive predictive accuracy relative to a neural network-based solution, while completely eliminating the need for long training loops, and remaining robust to changes in the sampling layout.",
    "published": "2025-12-15T11:31:41Z",
    "authors": [
      "Lorenzo Sabug",
      "Eric Kerrigan"
    ],
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13213",
    "title": "Towards Secure Decentralized Applications and Consensus Protocols in Blockchains (on Selfish Mining, Undercutting Attacks, DAG-Based Blockchains, E-Voting, Cryptocurrency Wallets, Secure-Logging, and CBDC)",
    "abstract": "With the rise of cryptocurrencies, many new applications built on decentralized blockchains have emerged. Blockchains are full-stack distributed systems where multiple sub-systems interact. While many deployed blockchains and decentralized applications need better scalability and performance, security is also critical. Due to their complexity, assessing blockchain and DAPP security requires a more holistic view than for traditional distributed or centralized systems.   In this thesis, we summarize our contributions to blockchain and decentralized application security. We propose a security reference architecture to support standardized vulnerability and threat analysis. We study consensus security in single-chain Proof-of-Work blockchains, including resistance to selfish mining, undercutting, and greedy transaction selection, as well as related issues in DAG-based systems. We contribute to wallet security with a new classification of authentication schemes and a two-factor method based on One-Time Passwords. We advance e-voting with a practical boardroom voting protocol, extend it to a scalable version for millions of participants while preserving security and privacy, and introduce a repetitive voting framework that enables vote changes between elections while avoiding peak-end effects. Finally, we improve secure logging using blockchains and trusted computing through a centralized ledger that guarantees non-equivocation, integrity, and censorship evidence, then build on it to propose an interoperability protocol for central bank digital currencies that ensures atomic transfers.",
    "published": "2025-12-15T11:26:43Z",
    "authors": [
      "Ivan Homoliak"
    ],
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.GT"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13207",
    "title": "Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting",
    "abstract": "Deep learning and federated learning (FL) are becoming powerful partners for next-generation weather forecasting. Deep learning enables high-resolution spatiotemporal forecasts that can surpass traditional numerical models, while FL allows institutions in different locations to collaboratively train models without sharing raw data, addressing efficiency and security concerns. While FL has shown promise across heterogeneous regions, its distributed nature introduces new vulnerabilities. In particular, data poisoning attacks, in which compromised clients inject manipulated training data, can degrade performance or introduce systematic biases. These threats are amplified by spatial dependencies in meteorological data, allowing localized perturbations to influence broader regions through global model aggregation. In this study, we investigate how adversarial clients distort federated surface temperature forecasts trained on the Copernicus European Regional ReAnalysis (CERRA) dataset. We simulate geographically distributed clients and evaluate patch-based and global biasing attacks on regional temperature forecasts. Our results show that even a small fraction of poisoned clients can mislead predictions across large, spatially connected areas. A global temperature bias attack from a single compromised client shifts predictions by up to -1.7 K, while coordinated patch attacks more than triple the mean squared error and produce persistent regional anomalies exceeding +3.5 K. Finally, we assess trimmed mean aggregation as a defense mechanism, showing that it successfully defends against global bias attacks (2-13\\% degradation) but fails against patch attacks (281-603\\% amplification), exposing limitations of outlier-based defenses for spatially correlated data.",
    "published": "2025-12-15T11:22:24Z",
    "authors": [
      "Karina Chichifoi",
      "Fabio Merizzi",
      "Michele Colajanni"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13199",
    "title": "Investigation of a Bit-Sequence Reconciliation Protocol Based on Neural TPM Networks in Secure Quantum Communications",
    "abstract": "The article discusses a key reconciliation protocol for quantum key distribution (QKD) systems based on Tree Parity Machines (TPM). The idea of transforming key material into neural network weights is presented. Two experiments were conducted to study how the number of synchronization iterations and the amount of leaked information depend on the quantum bit error rate (QBER) and the range of neural network weights. The results show a direct relationship between the average number of synchronization iterations and QBER, an increase in iterations when the weight range is expanded, and a reduction in leaked information as the weight range increases. Based on these results, conclusions are drawn regarding the applicability of the protocol and the prospects for further research on neural cryptographic methods in the context of key reconciliation.",
    "published": "2025-12-15T11:14:00Z",
    "authors": [
      "Matvey Yorkhov",
      "Vladimir Faerman",
      "Anton Konev"
    ],
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13197",
    "title": "MicroPhaseNO: Adapting an Earthquake-Trained Phase Neural Operator for Microseismic Phase Picking",
    "abstract": "Seismic phase picking is very often used for microseismic monitoring and subsurface imaging. Traditional manual processing is not feasible for either real-time applications or large arrays. Deep learning-based pickers trained on large earthquake catalogs offer an automated alternative. However, they are typically optimized for high signal-to-noise, long-duration networks and struggle with the challenges presented by microseismic datasets, which are purpose-built for limited time without previously detected seismicity. In this study, we demonstrate how a network-wide earthquake phase picker, the Phase Neural Operator (PhaseNO), can be adapted to microseismic monitoring using transfer learning. Starting from a PhaseNO model pre-trained on more than 57,000 three-component earthquake and noise records, we fine-tune the model using only 200 labeled and noise seismograms from induced events in hydraulic-fracturing settings. The fine-tuned model thus preserves the rich spatio-temporal representation learned from abundant earthquake data, while adapting to the characteristics and labeling conventions of microseismic phases, which are often picked on peaks or troughs rather than onsets. We evaluate performance on three distinct real-world microseismic datasets with different network geometries and acquisition parameters. Compared to the original PhaseNO and a conventional workflow, the adapted model increases F1 score and accuracy by up to 30%, and strongly reduces systematic timing bias and pick uncertainty. Because the adaptation relies on a small, campaign-specific calibration set, the approach is readily transferable to other microseismic tasks where public earthquake data and pre-trained models are accessible. The associated code will be released openly at https://github.com/ayratabd/MicroPhaseNO.",
    "published": "2025-12-15T11:13:21Z",
    "authors": [
      "Ayrat Abdullin",
      "Umair bin Waheed",
      "Leo Eisner",
      "Naveed Iqbal"
    ],
    "categories": [
      "physics.geo-ph",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13196",
    "title": "Noise-Resilient Quantum Aggregation on NISQ for Federated ADAS Learning",
    "abstract": "Advanced Driver Assistance Systems (ADAS) increasingly employ Federated Learning (FL) to collaboratively train models across distributed vehicular nodes while preserving data privacy. Yet, conventional FL aggregation remains susceptible to noise, latency, and security constraints inherent to real-time vehicular networks. This paper introduces Noise-Resilient Quantum Federated Learning (NR-QFL), a hybrid quantum-classical framework that enables secure, low-latency aggregation through variational quantum circuits (VQCs) operating under Noisy Intermediate-Scale Quantum (NISQ) conditions. The framework encodes model parameters as quantum states with adaptive gate reparameterization, ensuring bounded-error convergence and provable resilience under Completely Positive Trace-Preserving (CPTP) dynamics. NR-QFL employs quantum entropy-based client selection and multi-server coordination for fairness and stability. Empirical validation shows consistent convergence with reduced gradient variance, lower communication overhead, and enhanced noise tolerance under constrained edge conditions. The framework establishes a scalable foundation for quantum-enhanced federated learning, enabling secure, efficient, and dynamically stable ADAS intelligence at the vehicular edge.",
    "published": "2025-12-15T11:10:40Z",
    "authors": [
      "Chethana Prasad Kabgere",
      "Sudarshan T S B"
    ],
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13194",
    "title": "Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models",
    "abstract": "Speculative Decoding is a prominent technique for accelerating the autoregressive inference of large language models (LLMs) by employing a fast draft model to propose candidate token sequences and a large target model to verify them in parallel. However, its core component -- the rejection sampling mechanism -- relies on a fixed, context-independent random threshold. This leads to a significant \"random rejection\" problem in high-uncertainty generation scenarios, where plausible candidate tokens are frequently rejected due to random chance, undermining inference efficiency. This paper introduces Efficient Adaptive Rejection Sampling (EARS), a novel method that dynamically adjusts the acceptance threshold by incorporating the target model's own predictive uncertainty, measured as \\(1 - \\max(P_{\\mathrm{target}})\\). By introducing a tolerance term proportional to this uncertainty, EARS intelligently relaxes the acceptance criterion when the model is uncertain, effectively reducing random rejections while maintaining strict standards when the model is confident. Experiments on creative writing and open-domain QA tasks demonstrate that EARS significantly enhances the efficiency of speculative decoding, achieving up to an 18.12% increase in throughput with a negligible 0.84% accuracy drop on the GSM8K benchmark. The method requires no modifications to model architectures and can be seamlessly integrated into existing speculative decoding frameworks.",
    "published": "2025-12-15T11:08:56Z",
    "authors": [
      "Chendong Sun"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13192",
    "title": "POLAR: A Portrait OLAT Dataset and Generative Framework for Illumination-Aware Face Modeling",
    "abstract": "Face relighting aims to synthesize realistic portraits under novel illumination while preserving identity and geometry. However, progress remains constrained by the limited availability of large-scale, physically consistent illumination data. To address this, we introduce POLAR, a large-scale and physically calibrated One-Light-at-a-Time (OLAT) dataset containing over 200 subjects captured under 156 lighting directions, multiple views, and diverse expressions. Building upon POLAR, we develop a flow-based generative model POLARNet that predicts per-light OLAT responses from a single portrait, capturing fine-grained and direction-aware illumination effects while preserving facial identity. Unlike diffusion or background-conditioned methods that rely on statistical or contextual cues, our formulation models illumination as a continuous, physically interpretable transformation between lighting states, enabling scalable and controllable relighting. Together, POLAR and POLARNet form a unified illumination learning framework that links real data, generative synthesis, and physically grounded relighting, establishing a self-sustaining \"chicken-and-egg\" cycle for scalable and reproducible portrait illumination.",
    "published": "2025-12-15T11:04:09Z",
    "authors": [
      "Zhuo Chen",
      "Chengqun Yang",
      "Zhuo Su",
      "Zheng Lv",
      "Jingnan Gao",
      "Xiaoyuan Zhang",
      "Xiaokang Yang",
      "Yichao Yan"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13191",
    "title": "CoRA: A Collaborative Robust Architecture with Hybrid Fusion for Efficient Perception",
    "abstract": "Collaborative perception has garnered significant attention as a crucial technology to overcome the perceptual limitations of single-agent systems. Many state-of-the-art (SOTA) methods have achieved communication efficiency and high performance via intermediate fusion. However, they share a critical vulnerability: their performance degrades under adverse communication conditions due to the misalignment induced by data transmission, which severely hampers their practical deployment. To bridge this gap, we re-examine different fusion paradigms, and recover that the strengths of intermediate and late fusion are not a trade-off, but a complementary pairing. Based on this key insight, we propose CoRA, a novel collaborative robust architecture with a hybrid approach to decouple performance from robustness with low communication. It is composed of two components: a feature-level fusion branch and an object-level correction branch. Its first branch selects critical features and fuses them efficiently to ensure both performance and scalability. The second branch leverages semantic relevance to correct spatial displacements, guaranteeing resilience against pose errors. Experiments demonstrate the superiority of CoRA. Under extreme scenarios, CoRA improves upon its baseline performance by approximately 19% in AP@0.7 with more than 5x less communication volume, which makes it a promising solution for robust collaborative perception.",
    "published": "2025-12-15T11:00:38Z",
    "authors": [
      "Gong Chen",
      "Chaokun Zhang",
      "Pengcheng Lv",
      "Xiaohui Xie"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13190",
    "title": "WAY: Estimation of Vessel Destination in Worldwide AIS Trajectory",
    "abstract": "The Automatic Identification System (AIS) enables data-driven maritime surveillance but suffers from reliability issues and irregular intervals. We address vessel destination estimation using global-scope AIS data by proposing a differentiated approach that recasts long port-to-port trajectories as a nested sequence structure. Using spatial grids, this method mitigates spatio-temporal bias while preserving detailed resolution. We introduce a novel deep learning architecture, WAY, designed to process these reformulated trajectories for long-term destination estimation days to weeks in advance. WAY comprises a trajectory representation layer and Channel-Aggregative Sequential Processing (CASP) blocks. The representation layer generates multi-channel vector sequences from kinematic and non-kinematic features. CASP blocks utilize multi-headed channel- and self-attention for aggregation and sequential information delivery. Additionally, we propose a task-specialized Gradient Dropout (GD) technique to enable many-to-many training on single labels, preventing biased feedback surges by stochastically blocking gradient flow based on sample length. Experiments on 5-year AIS data demonstrate WAY's superiority over conventional spatial grid-based approaches regardless of trajectory progression. Results further confirm that adopting GD leads to performance gains. Finally, we explore WAY's potential for real-world application through multitask learning for ETA estimation.",
    "published": "2025-12-15T10:55:20Z",
    "authors": [
      "Jin Sob Kim",
      "Hyun Joon Park",
      "Wooseok Shin",
      "Dongil Park",
      "Sung Won Han"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13186",
    "title": "PolySet: Restoring the Statistical Ensemble Nature of Polymers for Machine Learning",
    "abstract": "Machine-learning (ML) models in polymer science typically treat a polymer as a single, perfectly defined molecular graph, even though real materials consist of stochastic ensembles of chains with distributed lengths. This mismatch between physical reality and digital representation limits the ability of current models to capture polymer behaviour. Here we introduce PolySet, a framework that represents a polymer as a finite, weighted ensemble of chains sampled from an assumed molar-mass distribution. This ensemble-based encoding is independent of chemical detail, compatible with any molecular representation and illustrated here in the homopolymer case using a minimal language model. We show that PolySet retains higher-order distributional moments (such as Mz, Mz+1), enabling ML models to learn tail-sensitive properties with greatly improved stability and accuracy. By explicitly acknowledging the statistical nature of polymer matter, PolySet establishes a physically grounded foundation for future polymer machine learning, naturally extensible to copolymers, block architectures, and other complex topologies.",
    "published": "2025-12-15T10:50:48Z",
    "authors": [
      "Khalid Ferji"
    ],
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13177",
    "title": "MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion",
    "abstract": "Vision-language models enable the understanding and reasoning of complex traffic scenarios through multi-source information fusion, establishing it as a core technology for autonomous driving. However, existing vision-language models are constrained by the image understanding paradigm in 2D plane, which restricts their capability to perceive 3D spatial information and perform deep semantic fusion, resulting in suboptimal performance in complex autonomous driving environments. This study proposes MMDrive, an multimodal vision-language model framework that extends traditional image understanding to a generalized 3D scene understanding framework. MMDrive incorporates three complementary modalities, including occupancy maps, LiDAR point clouds, and textual scene descriptions. To this end, it introduces two novel components for adaptive cross-modal fusion and key information extraction. Specifically, the Text-oriented Multimodal Modulator dynamically weights the contributions of each modality based on the semantic cues in the question, guiding context-aware feature integration. The Cross-Modal Abstractor employs learnable abstract tokens to generate compact, cross-modal summaries that highlight key regions and essential semantics. Comprehensive evaluations on the DriveLM and NuScenes-QA benchmarks demonstrate that MMDrive achieves significant performance gains over existing vision-language models for autonomous driving, with a BLEU-4 score of 54.56 and METEOR of 41.78 on DriveLM, and an accuracy score of 62.7% on NuScenes-QA. MMDrive effectively breaks the traditional image-only understanding barrier, enabling robust multimodal reasoning in complex driving environments and providing a new foundation for interpretable autonomous driving scene understanding.",
    "published": "2025-12-15T10:37:59Z",
    "authors": [
      "Minghui Hou",
      "Wei-Hsing Huang",
      "Shaofeng Liang",
      "Daizong Liu",
      "Tai-Hao Wen",
      "Gang Wang",
      "Runwei Guan",
      "Weiping Ding"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13175",
    "title": "Seeing the Whole Picture: Distribution-Guided Data-Free Distillation for Semantic Segmentation",
    "abstract": "Semantic segmentation requires a holistic understanding of the physical world, as it assigns semantic labels to spatially continuous and structurally coherent objects rather than to isolated pixels. However, existing data-free knowledge distillation (DFKD) methods-primarily designed for classification-often disregard this continuity, resulting in significant performance degradation when applied directly to segmentation tasks. In this paper, we introduce DFSS, a novel data-free distillation framework tailored for semantic segmentation. Unlike prior approaches that treat pixels independently, DFSS respects the structural and contextual continuity of real-world scenes. Our key insight is to leverage Batch Normalization (BN) statistics from a teacher model to guide Approximate Distribution Sampling (ADS), enabling the selection of data that better reflects the original training distribution-without relying on potentially misleading teacher predictions. Additionally, we propose Weighted Distribution Progressive Distillation (WDPD), which dynamically prioritizes reliable samples that are more closely aligned with the original data distribution early in training and gradually incorporates more challenging cases, mirroring the natural progression of learning in human perception. Extensive experiments on standard benchmarks demonstrate that DFSS consistently outperforms existing data-free distillation methods for semantic segmentation, achieving state-of-the-art results with significantly reduced reliance on auxiliary data.",
    "published": "2025-12-15T10:37:05Z",
    "authors": [
      "Hongxuan Sun",
      "Tao Wu"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13174",
    "title": "Carrot, stick, or both? Price incentives for sustainable food choice in competitive environments",
    "abstract": "Meat consumption is a major driver of global greenhouse gas emissions. While pricing interventions have shown potential to reduce meat intake, previous studies have focused on highly constrained environments with limited consumer choice. Here, we present the first large-scale field experiment to evaluate multiple pricing interventions in a real-world, competitive setting. Using a sequential crossover design with matched menus in a Swiss university campus, we systematically compared vegetarian-meal discounts (-2.5 CHF), meat surcharges (+2.5 CHF), and a combined scheme (-1.2 CHF=+1.2 CHF) across four campus cafeterias. Only the surcharge and combined interventions led to significant increases in vegetarian meal uptake--by 26.4% and 16.6%, respectively--and reduced CO2 emissions per meal by 7.4% and 11.3%, respectively. The surcharge, while effective, triggered a 12.3% drop in sales at intervention sites and a corresponding 14.9% increase in non-treated locations, hence causing a spillover effect that completely offset environmental gains. In contrast, the combined approach achieved meaningful emission reductions without significant effects on overall sales or revenue, making it both effective and economically viable. Notably, pricing interventions were equally effective for both vegetarian-leaning customers and habitual meat-eaters, stimulating change even within entrenched dietary habits. Our results show that balanced pricing strategies can reduce the carbon footprint of realistic food environments, but require coordinated implementation to maximize climate benefits and avoid unintended spillover effects.",
    "published": "2025-12-15T10:35:44Z",
    "authors": [
      "Francesco Salvi",
      "Giuseppe Russo",
      "Adam Barla",
      "Vincent Moreau",
      "Robert West"
    ],
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13170",
    "title": "Iterative Tuning of Nonlinear Model Predictive Control for Robotic Manufacturing Tasks",
    "abstract": "Manufacturing processes are often perturbed by drifts in the environment and wear in the system, requiring control re-tuning even in the presence of repetitive operations. This paper presents an iterative learning framework for automatic tuning of Nonlinear Model Predictive Control (NMPC) weighting matrices based on task-level performance feedback. Inspired by norm-optimal Iterative Learning Control (ILC), the proposed method adaptively adjusts NMPC weights Q and R across task repetitions to minimize key performance indicators (KPIs) related to tracking accuracy, control effort, and saturation. Unlike gradient-based approaches that require differentiating through the NMPC solver, we construct an empirical sensitivity matrix, enabling structured weight updates without analytic derivatives. The framework is validated through simulation on a UR10e robot performing carbon fiber winding on a tetrahedral core. Results demonstrate that the proposed approach converges to near-optimal tracking performance (RMSE within 0.3% of offline Bayesian Optimization (BO)) in just 4 online repetitions, compared to 100 offline evaluations required by BO algorithm. The method offers a practical solution for adaptive NMPC tuning in repetitive robotic tasks, combining the precision of carefully optimized controllers with the flexibility of online adaptation.",
    "published": "2025-12-15T10:30:40Z",
    "authors": [
      "Deepak Ingole",
      "Valentin Bhend",
      "Shiva Ganesh Murali",
      "Oliver Dobrich",
      "Alisa Rupenayan"
    ],
    "categories": [
      "cs.RO",
      "cs.LG",
      "eess.SY",
      "math.OC"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13168",
    "title": "Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows",
    "abstract": "We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.   We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.   We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.",
    "published": "2025-12-15T10:28:45Z",
    "authors": [
      "Haoyu Dong",
      "Pengkun Zhang",
      "Yan Gao",
      "Xuanyu Dong",
      "Yilin Cheng",
      "Mingzhe Lu",
      "Adina Yakefu",
      "Shuxin Zheng"
    ],
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.IR",
      "cs.MA"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13165",
    "title": "SACn: Soft Actor-Critic with n-step Returns",
    "abstract": "Soft Actor-Critic (SAC) is widely used in practical applications and is now one of the most relevant off-policy online model-free reinforcement learning (RL) methods. The technique of n-step returns is known to increase the convergence speed of RL algorithms compared to their 1-step returns-based versions. However, SAC is notoriously difficult to combine with n-step returns, since their usual combination introduces bias in off-policy algorithms due to the changes in action distribution. While this problem is solved by importance sampling, a method for estimating expected values of one distribution using samples from another distribution, importance sampling may result in numerical instability. In this work, we combine SAC with n-step returns in a way that overcomes this issue. We present an approach to applying numerically stable importance sampling with simplified hyperparameter selection. Furthermore, we analyze the entropy estimation approach of Soft Actor-Critic in the context of the n-step maximum entropy framework and formulate the $τ$-sampled entropy estimation to reduce the variance of the learning target. Finally, we formulate the Soft Actor-Critic with n-step returns (SAC$n$) algorithm that we experimentally verify on MuJoCo simulated environments.",
    "published": "2025-12-15T10:23:13Z",
    "authors": [
      "Jakub Łyskawa",
      "Jakub Lewandowski",
      "Paweł Wawrzyński"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13164",
    "title": "A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis",
    "abstract": "The development of clinical-grade artificial intelligence in pathology is limited by the scarcity of diverse, high-quality annotated datasets. Generative models offer a potential solution but suffer from semantic instability and morphological hallucinations that compromise diagnostic reliability. To address this challenge, we introduce a Correlation-Regulated Alignment Framework for Tissue Synthesis (CRAFTS), the first generative foundation model for pathology-specific text-to-image synthesis. By leveraging a dual-stage training strategy on approximately 2.8 million image-caption pairs, CRAFTS incorporates a novel alignment mechanism that suppresses semantic drift to ensure biological accuracy. This model generates diverse pathological images spanning 30 cancer types, with quality rigorously validated by objective metrics and pathologist evaluations. Furthermore, CRAFTS-augmented datasets enhance the performance across various clinical tasks, including classification, cross-modal retrieval, self-supervised learning, and visual question answering. In addition, coupling CRAFTS with ControlNet enables precise control over tissue architecture from inputs such as nuclear segmentation masks and fluorescence images. By overcoming the critical barriers of data scarcity and privacy concerns, CRAFTS provides a limitless source of diverse, annotated histology data, effectively unlocking the creation of robust diagnostic tools for rare and complex cancer phenotypes.",
    "published": "2025-12-15T10:22:43Z",
    "authors": [
      "Xianchao Guan",
      "Zhiyuan Fan",
      "Yifeng Wang",
      "Fuqiang Chen",
      "Yanjiang Zhou",
      "Zengyang Che",
      "Hongxue Meng",
      "Xin Li",
      "Yaowei Wang",
      "Hongpeng Wang",
      "Min Zhang",
      "Heng Tao Shen",
      "Zheng Zhang",
      "Yongbing Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13159",
    "title": "SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning",
    "abstract": "Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.",
    "published": "2025-12-15T10:08:53Z",
    "authors": [
      "Emre Can Acikgoz",
      "Jinoh Oh",
      "Jie Hao",
      "Joo Hyuk Jeon",
      "Heng Ji",
      "Dilek Hakkani-Tür",
      "Gokhan Tur",
      "Xiang Li",
      "Chengyuan Ma",
      "Xing Fan"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13157",
    "title": "Intrinsic Image Fusion for Multi-View 3D Material Reconstruction",
    "abstract": "We introduce Intrinsic Image Fusion, a method that reconstructs high-quality physically based materials from multi-view images. Material reconstruction is highly underconstrained and typically relies on analysis-by-synthesis, which requires expensive and noisy path tracing. To better constrain the optimization, we incorporate single-view priors into the reconstruction process. We leverage a diffusion-based material estimator that produces multiple, but often inconsistent, candidate decompositions per view. To reduce the inconsistency, we fit an explicit low-dimensional parametric function to the predictions. We then propose a robust optimization framework using soft per-view prediction selection together with confidence-based soft multi-view inlier set to fuse the most consistent predictions of the most confident views into a consistent parametric material space. Finally, we use inverse path tracing to optimize for the low-dimensional parameters. Our results outperform state-of-the-art methods in material disentanglement on both synthetic and real scenes, producing sharp and clean reconstructions suitable for high-quality relighting.",
    "published": "2025-12-15T10:05:59Z",
    "authors": [
      "Peter Kocsis",
      "Lukas Höllein",
      "Matthias Nießner"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13154",
    "title": "MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations",
    "abstract": "Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which agent should initiate a clarification and how agents should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-agent settings remain open. In this paper, we propose MAC (Multi-Agent Clarification), an interactive multi-agent framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple agents to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-agent communication.",
    "published": "2025-12-15T10:02:50Z",
    "authors": [
      "Emre Can Acikgoz",
      "Jinoh Oh",
      "Joo Hyuk Jeon",
      "Jie Hao",
      "Heng Ji",
      "Dilek Hakkani-Tür",
      "Gokhan Tur",
      "Xiang Li",
      "Chengyuan Ma",
      "Xing Fan"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13149",
    "title": "Enhancing Node-Level Graph Domain Adaptation by Alleviating Local Dependency",
    "abstract": "Recent years have witnessed significant advancements in machine learning methods on graphs. However, transferring knowledge effectively from one graph to another remains a critical challenge. This highlights the need for algorithms capable of applying information extracted from a source graph to an unlabeled target graph, a task known as unsupervised graph domain adaptation (GDA). One key difficulty in unsupervised GDA is conditional shift, which hinders transferability. In this paper, we show that conditional shift can be observed only if there exists local dependencies among node features. To support this claim, we perform a rigorous analysis and also further provide generalization bounds of GDA when dependent node features are modeled using markov chains. Guided by the theoretical findings, we propose to improve GDA by decorrelating node features, which can be specifically implemented through decorrelated GCN layers and graph transformer layers. Our experimental results demonstrate the effectiveness of this approach, showing not only substantial performance enhancements over baseline GDA methods but also clear visualizations of small intra-class distances in the learned representations. Our code is available at https://github.com/TechnologyAiGroup/DFT",
    "published": "2025-12-15T10:00:25Z",
    "authors": [
      "Xinwei Tai",
      "Dongmian Zou",
      "Hongfei Wang"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13147",
    "title": "StarryGazer: Leveraging Monocular Depth Estimation Models for Domain-Agnostic Single Depth Image Completion",
    "abstract": "The problem of depth completion involves predicting a dense depth image from a single sparse depth map and an RGB image. Unsupervised depth completion methods have been proposed for various datasets where ground truth depth data is unavailable and supervised methods cannot be applied. However, these models require auxiliary data to estimate depth values, which is far from real scenarios. Monocular depth estimation (MDE) models can produce a plausible relative depth map from a single image, but there is no work to properly combine the sparse depth map with MDE for depth completion; a simple affine transformation to the depth map will yield a high error since MDE are inaccurate at estimating depth difference between objects. We introduce StarryGazer, a domain-agnostic framework that predicts dense depth images from a single sparse depth image and an RGB image without relying on ground-truth depth by leveraging the power of large MDE models. First, we employ a pre-trained MDE model to produce relative depth images. These images are segmented and randomly rescaled to form synthetic pairs for dense pseudo-ground truth and corresponding sparse depths. A refinement network is trained with the synthetic pairs, incorporating the relative depth maps and RGB images to improve the model's accuracy and robustness. StarryGazer shows superior results over existing unsupervised methods and transformed MDE results on various datasets, demonstrating that our framework exploits the power of MDE models while appropriately fixing errors using sparse depth information.",
    "published": "2025-12-15T09:56:09Z",
    "authors": [
      "Sangmin Hong",
      "Suyoung Lee",
      "Kyoung Mu Lee"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13144",
    "title": "Weight Space Correlation Analysis: Quantifying Feature Utilization in Deep Learning Models",
    "abstract": "Deep learning models in medical imaging are susceptible to shortcut learning, relying on confounding metadata (e.g., scanner model) that is often encoded in image embeddings. The crucial question is whether the model actively utilizes this encoded information for its final prediction. We introduce Weight Space Correlation Analysis, an interpretable methodology that quantifies feature utilization by measuring the alignment between the classification heads of a primary clinical task and auxiliary metadata tasks. We first validate our method by successfully detecting artificially induced shortcut learning. We then apply it to probe the feature utilization of an SA-SonoNet model trained for Spontaneous Preterm Birth (sPTB) prediction. Our analysis confirmed that while the embeddings contain substantial metadata, the sPTB classifier's weight vectors were highly correlated with clinically relevant factors (e.g., birth weight) but decoupled from clinically irrelevant acquisition factors (e.g. scanner). Our methodology provides a tool to verify model trustworthiness, demonstrating that, in the absence of induced bias, the clinical model selectively utilizes features related to the genuine clinical signal.",
    "published": "2025-12-15T09:52:46Z",
    "authors": [
      "Chun Kit Wong",
      "Paraskevas Pegios",
      "Nina Weng",
      "Emilie Pi Fogtmann Sejer",
      "Martin Grønnebæk Tolsgaard",
      "Anders Nymark Christensen",
      "Aasa Feragen"
    ],
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13142",
    "title": "Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels",
    "abstract": "As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (anticipated judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.",
    "published": "2025-12-15T09:50:00Z",
    "authors": [
      "Anika Sharma",
      "Malavika Mampally",
      "Chidaksh Ravuru",
      "Kandyce Brennan",
      "Neil Gaikwad"
    ],
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13131",
    "title": "Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning",
    "abstract": "Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.",
    "published": "2025-12-15T09:43:08Z",
    "authors": [
      "Xin Guo",
      "Yifan Zhao",
      "Jia Li"
    ],
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.MM",
      "cs.SD"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13130",
    "title": "LeafTrackNet: A Deep Learning Framework for Robust Leaf Tracking in Top-Down Plant Phenotyping",
    "abstract": "High resolution phenotyping at the level of individual leaves offers fine-grained insights into plant development and stress responses. However, the full potential of accurate leaf tracking over time remains largely unexplored due to the absence of robust tracking methods-particularly for structurally complex crops such as canola. Existing plant-specific tracking methods are typically limited to small-scale species or rely on constrained imaging conditions. In contrast, generic multi-object tracking (MOT) methods are not designed for dynamic biological scenes. Progress in the development of accurate leaf tracking models has also been hindered by a lack of large-scale datasets captured under realistic conditions. In this work, we introduce CanolaTrack, a new benchmark dataset comprising 5,704 RGB images with 31,840 annotated leaf instances spanning the early growth stages of 184 canola plants. To enable accurate leaf tracking over time, we introduce LeafTrackNet, an efficient framework that combines a YOLOv10-based leaf detector with a MobileNetV3-based embedding network. During inference, leaf identities are maintained over time through an embedding-based memory association strategy. LeafTrackNet outperforms both plant-specific trackers and state-of-the-art MOT baselines, achieving a 9% HOTA improvement on CanolaTrack. With our work we provide a new standard for leaf-level tracking under realistic conditions and we provide CanolaTrack - the largest dataset for leaf tracking in agriculture crops, which will contribute to future research in plant phenotyping. Our code and dataset are publicly available at https://github.com/shl-shawn/LeafTrackNet.",
    "published": "2025-12-15T09:43:07Z",
    "authors": [
      "Shanghua Liu",
      "Majharulislam Babor",
      "Christoph Verduyn",
      "Breght Vandenberghe",
      "Bruno Betoni Parodi",
      "Cornelia Weltzien",
      "Marina M. -C. Höhne"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13125",
    "title": "Quanvolutional Neural Networks for Spectrum Peak-Finding",
    "abstract": "The analysis of spectra, such as Nuclear Magnetic Resonance (NMR) spectra, for the comprehensive characterization of peaks is a challenging task for both experts and machines, especially with complex molecules. This process, also known as deconvolution, involves identifying and quantifying the peaks in the spectrum. Machine learning techniques have shown promising results in automating this process. With the advent of quantum computing, there is potential to further enhance these techniques. In this work, inspired by the success of classical Convolutional Neural Networks (CNNs), we explore the use of Quanvolutional Neural Networks (QuanvNNs) for the multi-task peak finding problem, involving both peak counting and position estimation. We implement a simple and interpretable QuanvNN architecture that can be directly compared to its classical CNN counterpart, and evaluate its performance on a synthetic NMR-inspired dataset. Our results demonstrate that QuanvNNs outperform classical CNNs on challenging spectra, achieving an 11\\% improvement in F1 score and a 30\\% reduction in mean absolute error for peak position estimation. Additionally, QuanvNNs appear to exhibit better convergence stability for harder problems.",
    "published": "2025-12-15T09:33:54Z",
    "authors": [
      "Lukas Bischof",
      "Rudolf M. Füchslin",
      "Kurt Stockinger",
      "Pavel Sulimov"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13123",
    "title": "Stopping Rules for Stochastic Gradient Descent via Anytime-Valid Confidence Sequences",
    "abstract": "We study stopping rules for stochastic gradient descent (SGD) for convex optimization from the perspective of anytime-valid confidence sequences. Classical analyses of SGD provide convergence guarantees in expectation or at a fixed horizon, but offer no statistically valid way to assess, at an arbitrary time, how close the current iterate is to the optimum. We develop an anytime-valid, data-dependent upper confidence sequence for the weighted average suboptimality of projected SGD, constructed via nonnegative supermartingales and requiring no smoothness or strong convexity. This confidence sequence yields a simple stopping rule that is provably $\\varepsilon$-optimal with probability at least $1-α$ and is almost surely finite under standard stochastic approximation stepsizes. To the best of our knowledge, these are the first rigorous, time-uniform performance guarantees and finite-time $\\varepsilon$-optimality certificates for projected SGD with general convex objectives, based solely on observable trajectory quantities.",
    "published": "2025-12-15T09:26:45Z",
    "authors": [
      "Liviu Aolaritei",
      "Michael I. Jordan"
    ],
    "categories": [
      "math.OC",
      "cs.LG",
      "math.ST",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13122",
    "title": "DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass",
    "abstract": "Current methods for dense 3D point tracking in dynamic scenes typically rely on pairwise processing, require known camera poses, or assume a temporal ordering to input frames, constraining their flexibility and applicability. Additionally, recent advances have successfully enabled efficient 3D reconstruction from large-scale, unposed image collections, underscoring opportunities for unified approaches to dynamic scene understanding. Motivated by this, we propose DePT3R, a novel framework that simultaneously performs dense point tracking and 3D reconstruction of dynamic scenes from multiple images in a single forward pass. This multi-task learning is achieved by extracting deep spatio-temporal features with a powerful backbone and regressing pixel-wise maps with dense prediction heads. Crucially, DePT3R operates without requiring camera poses, substantially enhancing its adaptability and efficiency-especially important in dynamic environments with rapid changes. We validate DePT3R on several challenging benchmarks involving dynamic scenes, demonstrating strong performance and significant improvements in memory efficiency over existing state-of-the-art methods. Data and codes are available via the open repository: https://github.com/StructuresComp/DePT3R",
    "published": "2025-12-15T09:21:28Z",
    "authors": [
      "Vivek Alumootil",
      "Tuan-Anh Vu",
      "M. Khalid Jawed"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13120",
    "title": "Towards Practical Large-scale Dynamical Heterogeneous Graph Embedding: Cold-start Resilient Recommendation",
    "abstract": "Deploying dynamic heterogeneous graph embeddings in production faces key challenges of scalability, data freshness, and cold-start. This paper introduces a practical, two-stage solution that balances deep graph representation with low-latency incremental updates. Our framework combines HetSGFormer, a scalable graph transformer for static learning, with Incremental Locally Linear Embedding (ILLE), a lightweight, CPU-based algorithm for real-time updates. HetSGFormer captures global structure with linear scalability, while ILLE provides rapid, targeted updates to incorporate new data, thus avoiding costly full retraining. This dual approach is cold-start resilient, leveraging the graph to create meaningful embeddings from sparse data. On billion-scale graphs, A/B tests show HetSGFormer achieved up to a 6.11% lift in Advertiser Value over previous methods, while the ILLE module added another 3.22% lift and improved embedding refresh timeliness by 83.2%. Our work provides a validated framework for deploying dynamic graph learning in production environments.",
    "published": "2025-12-15T09:19:23Z",
    "authors": [
      "Mabiao Long",
      "Jiaxi Liu",
      "Yufeng Li",
      "Hao Xiong",
      "Junchi Yan",
      "Kefan Wang",
      "Yi Cao",
      "Jiandong Ding"
    ],
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13119",
    "title": "Less Is More: Sparse and Cooperative Perturbation for Point Cloud Attacks",
    "abstract": "Most adversarial attacks on point clouds perturb a large number of points, causing widespread geometric changes and limiting applicability in real-world scenarios. While recent works explore sparse attacks by modifying only a few points, such approaches often struggle to maintain effectiveness due to the limited influence of individual perturbations. In this paper, we propose SCP, a sparse and cooperative perturbation framework that selects and leverages a compact subset of points whose joint perturbations produce amplified adversarial effects. Specifically, SCP identifies the subset where the misclassification loss is locally convex with respect to their joint perturbations, determined by checking the positivedefiniteness of the corresponding Hessian block. The selected subset is then optimized to generate high-impact adversarial examples with minimal modifications. Extensive experiments show that SCP achieves 100% attack success rates, surpassing state-of-the-art sparse attacks, and delivers superior imperceptibility to dense attacks with far fewer modifications.",
    "published": "2025-12-15T09:18:27Z",
    "authors": [
      "Keke Tang",
      "Tianyu Hao",
      "Xiaofei Wang",
      "Weilong Peng",
      "Denghui Zhang",
      "Peican Zhu",
      "Zhihong Tian"
    ],
    "categories": [
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13111",
    "title": "From Overfitting to Reliability: Introducing the Hierarchical Approximate Bayesian Neural Network",
    "abstract": "In recent years, neural networks have revolutionized various domains, yet challenges such as hyperparameter tuning and overfitting remain significant hurdles. Bayesian neural networks offer a framework to address these challenges by incorporating uncertainty directly into the model, yielding more reliable predictions, particularly for out-of-distribution data. This paper presents Hierarchical Approximate Bayesian Neural Network, a novel approach that uses a Gaussian-inverse-Wishart distribution as a hyperprior of the network's weights to increase both the robustness and performance of the model. We provide analytical representations for the predictive distribution and weight posterior, which amount to the calculation of the parameters of Student's t-distributions in closed form with linear complexity with respect to the number of weights. Our method demonstrates robust performance, effectively addressing issues of overfitting and providing reliable uncertainty estimates, particularly for out-of-distribution tasks. Experimental results indicate that HABNN not only matches but often outperforms state-of-the-art models, suggesting a promising direction for future applications in safety-critical environments.",
    "published": "2025-12-15T09:08:42Z",
    "authors": [
      "Hayk Amirkhanian",
      "Marco F. Huber"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13109",
    "title": "Uncovering the Role of Initial Saliency in U-Shaped Attention Bias: Scaling Initial Token Weight for Enhanced Long-Text Processing",
    "abstract": "Large language models (LLMs) have demonstrated strong performance on a variety of natural language processing (NLP) tasks. However, they often struggle with long-text sequences due to the ``lost in the middle'' phenomenon. This issue has been shown to arise from a U-shaped attention bias, where attention is disproportionately focused on the beginning and end of a text, leaving the middle section underrepresented. While previous studies have attributed this bias to position encoding, our research first identifies an additional factor: initial saliency. It means that in the attention computation for each token, tokens with higher attention weights relative to the initial token tend to receive more attention in the prediction of the next token. We further find that utilizing this property by scaling attention weight between the initial token and others improves the model's ability to process long contexts, achieving a maximum improvement of 3.6\\% in MDQA dataset. Moreover, combining this approach with existing methods to reduce position encoding bias further enhances performance, achieving a maximum improvement of 3.4\\% in KV-Retrieval tasks.",
    "published": "2025-12-15T09:04:06Z",
    "authors": [
      "Zewen Qiang",
      "Sendong Zhao",
      "Haochun Wang",
      "Bing Qin",
      "Ting Liu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13107",
    "title": "Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather",
    "abstract": "Multi-modal 3D object detection is important for reliable perception in robotics and autonomous driving. However, its effectiveness remains limited under adverse weather conditions due to weather-induced distortions and misalignment between different data modalities. In this work, we propose DiffFusion, a novel framework designed to enhance robustness in challenging weather through diffusion-based restoration and adaptive cross-modal fusion. Our key insight is that diffusion models possess strong capabilities for denoising and generating data that can adapt to various weather conditions. Building on this, DiffFusion introduces Diffusion-IR restoring images degraded by weather effects and Point Cloud Restoration (PCR) compensating for corrupted LiDAR data using image object cues. To tackle misalignments between two modalities, we develop Bidirectional Adaptive Fusion and Alignment Module (BAFAM). It enables dynamic multi-modal fusion and bidirectional bird's-eye view (BEV) alignment to maintain consistent spatial correspondence. Extensive experiments on three public datasets show that DiffFusion achieves state-of-the-art robustness under adverse weather while preserving strong clean-data performance. Zero-shot results on the real-world DENSE dataset further validate its generalization. The implementation of our DiffFusion will be released as open-source.",
    "published": "2025-12-15T09:03:46Z",
    "authors": [
      "Zhijian He",
      "Feifei Liu",
      "Yuwei Li",
      "Zhanpeng Liu",
      "Jintao Cheng",
      "Xieyuanli Chen",
      "Xiaoyu Tang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13106",
    "title": "TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in training large reasoning models (LRMs) by leveraging answer-verifiable signals to guide policy optimization, which, however, suffers from high annotation costs. To alleviate this problem, recent work has explored unsupervised RLVR methods that derive rewards solely from the model's internal consistency, such as through entropy and majority voting. While seemingly promising, these methods often suffer from model collapse in the later stages of training, which may arise from the reinforcement of incorrect reasoning patterns in the absence of external supervision. In this work, we investigate a novel semi-supervised RLVR paradigm that utilizes a small labeled set to guide RLVR training on unlabeled samples. Our key insight is that supervised rewards are essential for stabilizing consistency-based training on unlabeled samples, ensuring that only reasoning patterns verified on labeled instances are incorporated into RL training. Technically, we propose an effective policy optimization algorithm, TraPO, that identifies reliable unlabeled samples by matching their learning trajectory similarity to labeled ones. Building on this, TraPO achieves remarkable data efficiency and strong generalization on six widely used mathematical reasoning benchmarks (AIME24/25, AMC, MATH-500, Minerva, and Olympiad) and three out-of-distribution tasks (ARC-c, GPQA-diamond, and MMLU-pro). With only 1K labeled and 3K unlabeled samples, TraPO reaches 42.6% average accuracy, surpassing the best unsupervised method trained on 45K unlabeled samples (38.3%). Notably, when using 4K labeled and 12K unlabeled samples, TraPO even outperforms the fully supervised model trained on the full 45K labeled samples on all benchmarks, while using only 10% of the labeled data. The code is available via https://github.com/ShenzhiYang2000/TRAPO.",
    "published": "2025-12-15T09:03:45Z",
    "authors": [
      "Shenzhi Yang",
      "Guangcheng Zhu",
      "Xing Zheng",
      "Yingfan MA",
      "Zhongqi Chen",
      "Bowen Song",
      "Weiqiang Wang",
      "Junbo Zhao",
      "Gang Chen",
      "Haobo Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13104",
    "title": "FID-Net: A Feature-Enhanced Deep Learning Network for Forest Infestation Detection",
    "abstract": "Forest pests threaten ecosystem stability, requiring efficient monitoring. To overcome the limitations of traditional methods in large-scale, fine-grained detection, this study focuses on accurately identifying infected trees and analyzing infestation patterns. We propose FID-Net, a deep learning model that detects pest-affected trees from UAV visible-light imagery and enables infestation analysis via three spatial metrics. Based on YOLOv8n, FID-Net introduces a lightweight Feature Enhancement Module (FEM) to extract disease-sensitive cues, an Adaptive Multi-scale Feature Fusion Module (AMFM) to align and fuse dual-branch features (RGB and FEM-enhanced), and an Efficient Channel Attention (ECA) mechanism to enhance discriminative information efficiently. From detection results, we construct a pest situation analysis framework using: (1) Kernel Density Estimation to locate infection hotspots; (2) neighborhood evaluation to assess healthy trees' infection risk; (3) DBSCAN clustering to identify high-density healthy clusters as priority protection zones. Experiments on UAV imagery from 32 forest plots in eastern Tianshan, China, show that FID-Net achieves 86.10% precision, 75.44% recall, 82.29% mAP@0.5, and 64.30% mAP@0.5:0.95, outperforming mainstream YOLO models. Analysis confirms infected trees exhibit clear clustering, supporting targeted forest protection. FID-Net enables accurate tree health discrimination and, combined with spatial metrics, provides reliable data for intelligent pest monitoring, early warning, and precise management.",
    "published": "2025-12-15T09:01:10Z",
    "authors": [
      "Yan Zhang",
      "Baoxin Li",
      "Han Sun",
      "Yuhang Gao",
      "Mingtai Zhang",
      "Pei Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13102",
    "title": "Socratic Students: Teaching Language Models to Learn by Asking Questions",
    "abstract": "Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provides guidance. In this work, we shift the focus to the student and investigate effective strategies to actively query the teacher in seeking useful information. Across math and coding benchmarks, where baseline student models begin with near-zero performance, we show that student-led approaches consistently yield absolute Pass@k improvements of at least 0.5 over static baselines. To improve question quality, we train students using Direct Preference Optimization (DPO) with guidance from either self or stronger students. We find that this guided training enables smaller models to learn how to ask better questions, further enhancing learning efficiency.",
    "published": "2025-12-15T08:59:19Z",
    "authors": [
      "Rajeev Bhatt Ambati",
      "Tianyi Niu",
      "Aashu Singh",
      "Shlok Mishra",
      "Shashank Srivastava",
      "Snigdha Chaturvedi"
    ],
    "categories": [
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13101",
    "title": "Harmonizing Generalization and Specialization: Uncertainty-Informed Collaborative Learning for Semi-supervised Medical Image Segmentation",
    "abstract": "Vision foundation models have demonstrated strong generalization in medical image segmentation by leveraging large-scale, heterogeneous pretraining. However, they often struggle to generalize to specialized clinical tasks under limited annotations or rare pathological variations, due to a mismatch between general priors and task-specific requirements. To address this, we propose Uncertainty-informed Collaborative Learning (UnCoL), a dual-teacher framework that harmonizes generalization and specialization in semi-supervised medical image segmentation. Specifically, UnCoL distills both visual and semantic representations from a frozen foundation model to transfer general knowledge, while concurrently maintaining a progressively adapting teacher to capture fine-grained and task-specific representations. To balance guidance from both teachers, pseudo-label learning in UnCoL is adaptively regulated by predictive uncertainty, which selectively suppresses unreliable supervision and stabilizes learning in ambiguous regions. Experiments on diverse 2D and 3D segmentation benchmarks show that UnCoL consistently outperforms state-of-the-art semi-supervised methods and foundation model baselines. Moreover, our model delivers near fully supervised performance with markedly reduced annotation requirements.",
    "published": "2025-12-15T08:57:49Z",
    "authors": [
      "Wenjing Lu",
      "Yi Hong",
      "Yang Yang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13100",
    "title": "OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning",
    "abstract": "Large and diverse datasets are needed for training generalist robot policies that have potential to control a variety of robot embodiments -- robot arm and gripper combinations -- across diverse tasks and environments. As re-collecting demonstrations and retraining for each new hardware platform are prohibitively costly, we show that existing robot data can be augmented for transfer and generalization. The Open X-Embodiment (OXE) dataset, which aggregates demonstrations from over 60 robot datasets, has been widely used as the foundation for training generalist policies. However, it is highly imbalanced: the top four robot types account for over 85\\% of its real data, which risks overfitting to robot-scene combinations. We present AugE-Toolkit, a scalable robot augmentation pipeline, and OXE-AugE, a high-quality open-source dataset that augments OXE with 9 different robot embodiments. OXE-AugE provides over 4.4 million trajectories, more than triple the size of the original OXE. We conduct a systematic study of how scaling robot augmentation impacts cross-embodiment learning. Results suggest that augmenting datasets with diverse arms and grippers improves policy performance not only on the augmented robots, but also on unseen robots and even the original robots under distribution shifts. In physical experiments, we demonstrate that state-of-the-art generalist policies such as OpenVLA and $π_0$ benefit from fine-tuning on OXE-AugE, improving success rates by 24-45% on previously unseen robot-gripper combinations across four real-world manipulation tasks. Project website: https://OXE-AugE.github.io/.",
    "published": "2025-12-15T08:57:15Z",
    "authors": [
      "Guanhua Ji",
      "Harsha Polavaram",
      "Lawrence Yunliang Chen",
      "Sandeep Bajamahal",
      "Zehan Ma",
      "Simeon Adebola",
      "Chenfeng Xu",
      "Ken Goldberg"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13096",
    "title": "Toward Self-Healing Networks-on-Chip: RL-Driven Routing in 2D Torus Architectures",
    "abstract": "We investigate adaptive minimal routing in 2D torus networks on chip NoCs under node fault conditions comparing a reinforcement learning RL based strategy to an adaptive routing baseline A torus topology is used for its low diameter high connectivity properties The RL approach models each router as an agent that learns to forward packets based on network state while the adaptive scheme uses fixed minimal paths with simple rerouting around faults We implement both methods in simulation injecting up to 50 node faults uniformly at random Key metrics are measured 1 throughput vs offered load at fault density 02 2 packet delivery ratio PDR vs fault density and 3 a fault adaptive score FT vs fault density Experimental results show the RL method achieves significantly higher throughput at high load approximately 2030 gain and maintains higher reliability under increasing faults The RL router delivers more packets per cycle and adapts to faults by exploiting path diversity whereas the adaptive scheme degrades sharply as faults accumulate In particular the RL approach preserves end to end connectivity longer PDR remains above 90 until approximately 3040 faults while adaptive PDR drops to approximately 70 at the same point The fault adaptive score likewise favors RL routing Thus RL based adaptive routing demonstrates clear advantages in throughput and fault resilience for torus NoCs",
    "published": "2025-12-15T08:54:43Z",
    "authors": [
      "Mohammad Walid Charrwi",
      "Zaid Hussain"
    ],
    "categories": [
      "cs.DC"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13095",
    "title": "ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning",
    "abstract": "To combine the advantages of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), recent methods have integrated ''hints'' into post-training, which are prefix segments of complete reasoning trajectories, aiming for powerful knowledge expansion and reasoning generalization. However, existing hint-based RL methods typically ignore difficulty when scheduling hint ratios and estimating relative advantages, leading to unstable learning and excessive imitation of off-policy hints. In this work, we propose ADHint, which treats difficulty as a key factor in both hint-ratio schedule and relative-advantage estimation to achieve a better trade-off between exploration and imitation. Specifically, we propose Adaptive Hint with Sample Difficulty Prior, which evaluates each sample's difficulty under the policy model and accordingly schedules an appropriate hint ratio to guide its rollouts. We also introduce Consistency-based Gradient Modulation and Selective Masking for Hint Preservation to modulate token-level gradients within hints, preventing biased and destructive updates. Additionally, we propose Advantage Estimation with Rollout Difficulty Posterior, which leverages the relative difficulty of rollouts with and without hints to estimate their respective advantages, thereby achieving more balanced updates. Extensive experiments across diverse modalities, model scales, and domains demonstrate that ADHint delivers superior reasoning ability and out-of-distribution generalization, consistently surpassing existing methods in both pass@1 and avg@8. Our code and dataset will be made publicly available upon paper acceptance.",
    "published": "2025-12-15T08:53:47Z",
    "authors": [
      "Feng Zhang",
      "Zezhong Tan",
      "Xinhong Ma",
      "Ziqiang Dong",
      "Xi Leng",
      "Jianfei Zhao",
      "Xin Sun",
      "Yang Yang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13094",
    "title": "Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation",
    "abstract": "Imitation learning (IL) has emerged as a central paradigm in autonomous driving. While IL excels in matching expert behavior in open-loop settings by minimizing per-step prediction errors, its performance degrades unexpectedly in closed-loop due to the gradual accumulation of small, often imperceptible errors over time.Over successive planning cycles, these errors compound, potentially resulting in severe failures.Current research efforts predominantly rely on increasingly sophisticated network architectures or high-fidelity training datasets to enhance the robustness of IL planners against error accumulation, focusing on the state-level robustness at a single time point. However, autonomous driving is inherently a continuous-time process, and leveraging the temporal scale to enhance robustness may provide a new perspective for addressing this issue.To this end, we propose a method termed Sequence of Experts (SoE), a temporal alternation policy that enhances closed-loop performance without increasing model size or data requirements. Our experiments on large-scale autonomous driving benchmarks nuPlan demonstrate that SoE method consistently and significantly improves the performance of all the evaluated models, and achieves state-of-the-art performance.This module may provide a key and widely applicable support for improving the training efficiency of autonomous driving models.",
    "published": "2025-12-15T08:50:23Z",
    "authors": [
      "Xiang Li",
      "Gang Liu",
      "Weitao Zhou",
      "Hongyi Zhu",
      "Zhong Cao"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13093",
    "title": "PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations",
    "abstract": "Achieving efficient and robust whole-body control (WBC) is essential for enabling humanoid robots to perform complex tasks in dynamic environments. Despite the success of reinforcement learning (RL) in this domain, its sample inefficiency remains a significant challenge due to the intricate dynamics and partial observability of humanoid robots. To address this limitation, we propose PvP, a Proprioceptive-Privileged contrastive learning framework that leverages the intrinsic complementarity between proprioceptive and privileged states. PvP learns compact and task-relevant latent representations without requiring hand-crafted data augmentations, enabling faster and more stable policy learning. To support systematic evaluation, we develop SRL4Humanoid, the first unified and modular framework that provides high-quality implementations of representative state representation learning (SRL) methods for humanoid robot learning. Extensive experiments on the LimX Oli robot across velocity tracking and motion imitation tasks demonstrate that PvP significantly improves sample efficiency and final performance compared to baseline SRL methods. Our study further provides practical insights into integrating SRL with RL for humanoid WBC, offering valuable guidance for data-efficient humanoid robot learning.",
    "published": "2025-12-15T08:50:20Z",
    "authors": [
      "Mingqi Yuan",
      "Tao Yu",
      "Haolin Song",
      "Bo Li",
      "Xin Jin",
      "Hua Chen",
      "Wenjun Zeng"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13089",
    "title": "UniVCD: A New Method for Unsupervised Change Detection in the Open-Vocabulary Era",
    "abstract": "Change detection (CD) identifies scene changes from multi-temporal observations and is widely used in urban development and environmental monitoring. Most existing CD methods rely on supervised learning, making performance strongly dataset-dependent and incurring high annotation costs; they typically focus on a few predefined categories and generalize poorly to diverse scenes. With the rise of vision foundation models such as SAM2 and CLIP, new opportunities have emerged to relax these constraints. We propose Unified Open-Vocabulary Change Detection (UniVCD), an unsupervised, open-vocabulary change detection method built on frozen SAM2 and CLIP. UniVCD detects category-agnostic changes across diverse scenes and imaging geometries without any labeled data or paired change images. A lightweight feature alignment module is introduced to bridge the spatially detailed representations from SAM2 and the semantic priors from CLIP, enabling high-resolution, semantically aware change estimation while keeping the number of trainable parameters small. On top of this, a streamlined post-processing pipeline is further introduced to suppress noise and pseudo-changes, improving the detection accuracy for objects with well-defined boundaries. Experiments on several public BCD (Binary Change Detection) and SCD (Semantic Change Detection) benchmarks show that UniVCD achieves consistently strong performance and matches or surpasses existing open-vocabulary CD methods in key metrics such as F1 and IoU. The results demonstrate that unsupervised change detection with frozen vision foundation models and lightweight multi-modal alignment is a practical and effective paradigm for open-vocabulary CD. Code and pretrained models will be released at https://github.com/Die-Xie/UniVCD.",
    "published": "2025-12-15T08:42:23Z",
    "authors": [
      "Ziqiang Zhu",
      "Bowei Yang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13083",
    "title": "DiRe: Diversity-promoting Regularization for Dataset Condensation",
    "abstract": "In Dataset Condensation, the goal is to synthesize a small dataset that replicates the training utility of a large original dataset. Existing condensation methods synthesize datasets with significant redundancy, so there is a dire need to reduce redundancy and improve the diversity of the synthesized datasets. To tackle this, we propose an intuitive Diversity Regularizer (DiRe) composed of cosine similarity and Euclidean distance, which can be applied off-the-shelf to various state-of-the-art condensation methods. Through extensive experiments, we demonstrate that the addition of our regularizer improves state-of-the-art condensation methods on various benchmark datasets from CIFAR-10 to ImageNet-1K with respect to generalization and diversity metrics.",
    "published": "2025-12-15T08:33:44Z",
    "authors": [
      "Saumyaranjan Mohanty",
      "Aravind Reddy",
      "Konda Reddy Mopuri"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13078",
    "title": "Heart Disease Prediction using Case Based Reasoning (CBR)",
    "abstract": "This study provides an overview of heart disease prediction using an intelligent system. Predicting disease accurately is crucial in the medical field, but traditional methods relying solely on a doctor's experience often lack precision. To address this limitation, intelligent systems are applied as an alternative to traditional approaches. While various intelligent system methods exist, this study focuses on three: Fuzzy Logic, Neural Networks, and Case-Based Reasoning (CBR). A comparison of these techniques in terms of accuracy was conducted, and ultimately, Case-Based Reasoning (CBR) was selected for heart disease prediction. In the prediction phase, the heart disease dataset underwent data pre-processing to clean the data and data splitting to separate it into training and testing sets. The chosen intelligent system was then employed to predict heart disease outcomes based on the processed data. The experiment concluded with Case-Based Reasoning (CBR) achieving a notable accuracy rate of 97.95% in predicting heart disease. The findings also revealed that the probability of heart disease was 57.76% for males and 42.24% for females. Further analysis from related studies suggests that factors such as smoking and alcohol consumption are significant contributors to heart disease, particularly among males.",
    "published": "2025-12-15T08:20:47Z",
    "authors": [
      "Mohaiminul Islam Bhuiyan",
      "Chan Hue Wah",
      "Nur Shazwani Kamarudin",
      "Nur Hafieza Ismail",
      "Ahmad Fakhri Ab Nasir"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13077",
    "title": "LikeBench: Evaluating Subjective Likability in LLMs for Personalization",
    "abstract": "A personalized LLM should remember user facts, apply them correctly, and adapt over time to provide responses that the user prefers. Existing LLM personalization benchmarks are largely centered on two axes: accurately recalling user information and accurately applying remembered information in downstream tasks. We argue that a third axis, likability, is both subjective and central to user experience, yet under-measured by current benchmarks. To measure likability holistically, we introduce LikeBench, a multi-session, dynamic evaluation framework that measures likability across multiple dimensions by how much an LLM can adapt over time to a user's preferences to provide more likable responses. In LikeBench, the LLMs engage in conversation with a simulated user and learn preferences only from the ongoing dialogue. As the interaction unfolds, models try to adapt to responses, and after each turn, they are evaluated for likability across seven dimensions by the same simulated user. To the best of our knowledge, we are the first to decompose likability into multiple diagnostic metrics: emotional adaptation, formality matching, knowledge adaptation, reference understanding, conversation length fit, humor fit, and callback, which makes it easier to pinpoint where a model falls short. To make the simulated user more realistic and discriminative, LikeBench uses fine-grained, psychologically grounded descriptive personas rather than the coarse high/low trait rating based personas used in prior work. Our benchmark shows that strong memory performance does not guarantee high likability: DeepSeek R1, with lower memory accuracy (86%, 17 facts/profile), outperformed Qwen3 by 28% on likability score despite Qwen3's higher memory accuracy (93%, 43 facts/profile). Even SOTA models like GPT-5 adapt well in short exchanges but show only limited robustness in longer, noisier interactions.",
    "published": "2025-12-15T08:18:42Z",
    "authors": [
      "Md Awsafur Rahman",
      "Adam Gabrys",
      "Doug Kang",
      "Jingjing Sun",
      "Tian Tan",
      "Ashwin Chandramouli"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13074",
    "title": "A Simple and Effective Framework for Symmetric Consistent Indexing in Large-Scale Dense Retrieval",
    "abstract": "Dense retrieval has become the industry standard in large-scale information retrieval systems due to its high efficiency and competitive accuracy. Its core relies on a coarse-to-fine hierarchical architecture that enables rapid candidate selection and precise semantic matching, achieving millisecond-level response over billion-scale corpora. This capability makes it essential not only in traditional search and recommendation scenarios but also in the emerging paradigm of generative recommendation driven by large language models, where semantic IDs-themselves a form of coarse-to-fine representation-play a foundational role. However, the widely adopted dual-tower encoding architecture introduces inherent challenges, primarily representational space misalignment and retrieval index inconsistency, which degrade matching accuracy, retrieval stability, and performance on long-tail queries. These issues are further magnified in semantic ID generation, ultimately limiting the performance ceiling of downstream generative models.   To address these challenges, this paper proposes a simple and effective framework named SCI comprising two synergistic modules: a symmetric representation alignment module that employs an innovative input-swapping mechanism to unify the dual-tower representation space without adding parameters, and an consistent indexing with dual-tower synergy module that redesigns retrieval paths using a dual-view indexing strategy to maintain consistency from training to inference. The framework is systematic, lightweight, and engineering-friendly, requiring minimal overhead while fully supporting billion-scale deployment. We provide theoretical guarantees for our approach, with its effectiveness validated by results across public datasets and real-world e-commerce datasets.",
    "published": "2025-12-15T08:11:24Z",
    "authors": [
      "Huimu Wang",
      "Yiming Qiu",
      "Xingzhi Yao",
      "Zhiguo Chen",
      "Guoyu Tang",
      "Songlin Wang",
      "Sulong Xu",
      "Mingming Li"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13072",
    "title": "Forging a Dynamic Memory: Retrieval-Guided Continual Learning for Generalist Medical Foundation Models",
    "abstract": "Multimodal biomedical Vision-Language Models (VLMs) exhibit immense potential in the field of Continual Learning (CL). However, they confront a core dilemma: how to preserve fine-grained intra-modality features while bridging the significant domain gap across different modalities. To address this challenge, we propose a comprehensive framework. Leveraging our 18-million multimodal and comprehensive medical retrieval database derived from PubMed scientific papers, we pioneer the integration of Retrieval-Augmented Generation (RAG) into CL. Specifically, we employ a multi-modal, multi-layer RAG system that provides real-time guidance for model fine-tuning through dynamic, on-demand knowledge retrieval. Building upon this, we introduce a dynamic knowledge distillation framework. This framework precisely resolves the aforementioned core dilemma by dynamically modulating the importance of the parameter space, the granularity of the distilled knowledge, and the data distribution of the reference dataset in accordance with the required level of detail. To thoroughly validate the clinical value of our strategy, we have designed a more rigorous \\textbf{M}edical Generalist Task Incremental Learning (MGTIL) benchmark. This benchmark is engineered to simultaneously evaluate the model's capacity for adaptation to significant domain shifts, retention of subtle intra-domain features, and real-time learning of novel and complex medical tasks. Extensive experimental results demonstrate that our proposed method achieves state-of-the-art (SOTA) performance across all metrics. The code is provided in the supplementary materials.",
    "published": "2025-12-15T08:09:40Z",
    "authors": [
      "Zizhi Chen",
      "Yizhen Gao",
      "Minghao Han",
      "Yizhou Liu",
      "Zhaoyu Chen",
      "Dingkang Yang",
      "Lihua Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13070",
    "title": "M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization",
    "abstract": "Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a \"policy collapse\" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.",
    "published": "2025-12-15T08:07:23Z",
    "authors": [
      "Bizhe Bai",
      "Hongming Wu",
      "Peng Ye",
      "Tao Chen"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 2
  },
  {
    "arxiv_id": "2512.13069",
    "title": "Multi-fidelity aerodynamic data fusion by autoencoder transfer learning",
    "abstract": "Accurate aerodynamic prediction often relies on high-fidelity simulations; however, their prohibitive computational costs severely limit their applicability in data-driven modeling. This limitation motivates the development of multi-fidelity strategies that leverage inexpensive low-fidelity information without compromising accuracy. Addressing this challenge, this work presents a multi-fidelity deep learning framework that combines autoencoder-based transfer learning with a newly developed Multi-Split Conformal Prediction (MSCP) strategy to achieve uncertainty-aware aerodynamic data fusion under extreme data scarcity. The methodology leverages abundant Low-Fidelity (LF) data to learn a compact latent physics representation, which acts as a frozen knowledge base for a decoder that is subsequently fine-tuned using scarce HF samples. Tested on surface-pressure distributions for NACA airfoils (2D) and a transonic wing (3D) databases, the model successfully corrects LF deviations and achieves high-accuracy pressure predictions using minimal HF training data. Furthermore, the MSCP framework produces robust, actionable uncertainty bands with pointwise coverage exceeding 95%. By combining extreme data efficiency with uncertainty quantification, this work offers a scalable and reliable solution for aerodynamic regression in data-scarce environments.",
    "published": "2025-12-15T08:06:52Z",
    "authors": [
      "Javier Nieto-Centenero",
      "Esther Andrés",
      "Rodrigo Castellanos"
    ],
    "categories": [
      "cs.LG",
      "physics.flu-dyn",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13063",
    "title": "LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators",
    "abstract": "Bilateral negotiation is a complex, context-sensitive task in which human negotiators dynamically adjust anchors, pacing, and flexibility to exploit power asymmetries and informal cues. We introduce a unified mathematical framework for modeling concession dynamics based on a hyperbolic tangent curve, and propose two metrics burstiness tau and the Concession-Rigidity Index (CRI) to quantify the timing and rigidity of offer trajectories. We conduct a large-scale empirical comparison between human negotiators and four state-of-the-art large language models (LLMs) across natural-language and numeric-offers settings, with and without rich market context, as well as six controlled power-asymmetry scenarios. Our results reveal that, unlike humans who smoothly adapt to situations and infer the opponents position and strategies, LLMs systematically anchor at extremes of the possible agreement zone for negotiations and optimize for fixed points irrespective of leverage or context. Qualitative analysis further shows limited strategy diversity and occasional deceptive tactics used by LLMs. Moreover the ability of LLMs to negotiate does not improve with better models. These findings highlight fundamental limitations in current LLM negotiation capabilities and point to the need for models that better internalize opponent reasoning and context-dependent strategy.",
    "published": "2025-12-15T07:50:09Z",
    "authors": [
      "Cheril Shah",
      "Akshit Agarwal",
      "Kanak Garg",
      "Mourad Heddaya"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13060",
    "title": "Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments",
    "abstract": "This paper addresses the challenges of low scheduling efficiency, unbalanced resource allocation, and poor adaptability in ETL (Extract-Transform-Load) processes under heterogeneous data environments by proposing an intelligent scheduling optimization framework based on deep Q-learning. The framework formalizes the ETL scheduling process as a Markov Decision Process and enables adaptive decision-making by a reinforcement learning agent in high-dimensional state spaces to dynamically optimize task allocation and resource scheduling. The model consists of a state representation module, a feature embedding network, a Q-value estimator, and a reward evaluation mechanism, which collectively consider task dependencies, node load states, and data flow characteristics to derive the optimal scheduling strategy in complex environments. A multi-objective reward function is designed to balance key performance indicators such as average scheduling delay, task completion rate, throughput, and resource utilization. Sensitivity experiments further verify the model's robustness under changes in hyperparameters, environmental dynamics, and data scale. Experimental results show that the proposed deep Q-learning scheduling framework significantly reduces scheduling delay, improves system throughput, and enhances execution stability under multi-source heterogeneous task conditions, demonstrating the strong potential of reinforcement learning in complex data scheduling and resource management, and providing an efficient and scalable optimization strategy for intelligent data pipeline construction.",
    "published": "2025-12-15T07:38:47Z",
    "authors": [
      "Kangning Gao",
      "Yi Hu",
      "Cong Nie",
      "Wei Li"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13059",
    "title": "An Open and Reproducible Deep Research Agent for Long-Form Question Answering",
    "abstract": "We present an open deep research system for long-form question answering, selected as a winning system in the text-to-text track of the MMU-RAG competition at NeurIPS 2025. The system combines an open-source large language model (LLM) with an open web search API to perform iterative retrieval, reasoning, and synthesis in real-world open-domain settings. To enhance reasoning quality, we apply preference tuning based on LLM-as-a-judge feedback that evaluates multiple aspects, including clarity, insightfulness, and factuality. Our experimental results show that the proposed method consistently improves answer quality across all three aspects. Our source code is publicly available at https://github.com/efficient-deep-research/efficient-deep-research.",
    "published": "2025-12-15T07:37:53Z",
    "authors": [
      "Ikuya Yamada",
      "Wataru Ikeda",
      "Ko Yoshida",
      "Mengyu Ye",
      "Hinata Sugimoto",
      "Masatoshi Suzuki",
      "Hisanori Ozaki",
      "Jun Suzuki"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13055",
    "title": "Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing",
    "abstract": "Visual Place Recognition (VPR) has advanced significantly with high-capacity foundation models like DINOv2, achieving remarkable performance. Nonetheless, their substantial computational cost makes deployment on resource-constrained devices impractical. In this paper, we introduce an efficient asymmetric VPR framework that incorporates a high-capacity gallery model for offline feature extraction with a lightweight query network for online processing. A key challenge in this setting is ensuring compatibility between these heterogeneous networks, which conventional approaches address through computationally expensive k-NN-based compatible training. To overcome this, we propose a geographical memory bank that structures gallery features using geolocation metadata inherent in VPR databases, eliminating the need for exhaustive k-NN computations. Additionally, we introduce an implicit embedding augmentation technique that enhances the query network to model feature variations despite its limited capacity. Extensive experiments demonstrate that our method not only significantly reduces computational costs but also outperforms existing asymmetric retrieval techniques, establishing a new aspect for VPR in resource-limited environments. The code is available at https://github.com/jaeyoon1603/AsymVPR",
    "published": "2025-12-15T07:30:17Z",
    "authors": [
      "Jaeyoon Kim",
      "Yoonki Cho",
      "Sung-Eui Yoon"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13047",
    "title": "Sharpen the Spec, Cut the Code: A Case for Generative File System with SYSSPEC",
    "abstract": "File systems are critical OS components that require constant evolution to support new hardware and emerging application needs. However, the traditional paradigm of developing features, fixing bugs, and maintaining the system incurs significant overhead, especially as systems grow in complexity. This paper proposes a new paradigm, generative file systems, which leverages Large Language Models (LLMs) to generate and evolve a file system from prompts, effectively addressing the need for robust evolution. Despite the widespread success of LLMs in code generation, attempts to create a functional file system have thus far been unsuccessful, mainly due to the ambiguity of natural language prompts.   This paper introduces SYSSPEC, a framework for developing generative file systems. Its key insight is to replace ambiguous natural language with principles adapted from formal methods. Instead of imprecise prompts, SYSSPEC employs a multi-part specification that accurately describes a file system's functionality, modularity, and concurrency. The specification acts as an unambiguous blueprint, guiding LLMs to generate expected code flexibly. To manage evolution, we develop a DAG-structured patch that operates on the specification itself, enabling new features to be added without violating existing invariants. Moreover, the SYSSPEC toolchain features a set of LLM-based agents with mechanisms to mitigate hallucination during construction and evolution. We demonstrate our approach by generating SPECFS, a concurrent file system. SPECFS passes hundreds of regression tests, matching a manually-coded baseline. We further confirm its evolvability by seamlessly integrating 10 real-world features from Ext4. Our work shows that a specification-guided approach makes generating and evolving complex systems not only feasible but also highly effective.",
    "published": "2025-12-15T07:15:01Z",
    "authors": [
      "Qingyuan Liu",
      "Zou Mo",
      "Hengbin Zhang",
      "Dong Du",
      "Yubin Xia",
      "Haibo Chen"
    ],
    "categories": [
      "cs.OS",
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13043",
    "title": "GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training",
    "abstract": "Multi-turn reinforcement learning (RL) for multi-modal agents built upon vision-language models (VLMs) is hampered by sparse rewards and long-horizon credit assignment. Recent methods densify the reward by querying a teacher that provides step-level feedback, e.g., Guided Thought Reinforcement (GTR) and On-Policy Distillation, but rely on costly, often privileged models as the teacher, limiting practicality and reproducibility. We introduce GTR-Turbo, a highly efficient upgrade to GTR, which matches the performance without training or querying an expensive teacher model. Specifically, GTR-Turbo merges the weights of checkpoints produced during the ongoing RL training, and then uses this merged model as a \"free\" teacher to guide the subsequent RL via supervised fine-tuning or soft logit distillation. This design removes dependence on privileged VLMs (e.g., GPT or Gemini), mitigates the \"entropy collapse\" observed in prior work, and keeps training stable. Across diverse visual agentic tasks, GTR-Turbo improves the accuracy of the baseline model by 10-30% while reducing wall-clock training time by 50% and compute cost by 60% relative to GTR.",
    "published": "2025-12-15T07:11:56Z",
    "authors": [
      "Tong Wei",
      "Yijun Yang",
      "Changhao Zhang",
      "Junliang Xing",
      "Yuanchun Shi",
      "Zongqing Lu",
      "Deheng Ye"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13040",
    "title": "Understanding Structured Financial Data with LLMs: A Case Study on Fraud Detection",
    "abstract": "Detecting fraud in financial transactions typically relies on tabular models that demand heavy feature engineering to handle high-dimensional data and offer limited interpretability, making it difficult for humans to understand predictions. Large Language Models (LLMs), in contrast, can produce human-readable explanations and facilitate feature analysis, potentially reducing the manual workload of fraud analysts and informing system refinements. However, they perform poorly when applied directly to tabular fraud detection due to the difficulty of reasoning over many features, the extreme class imbalance, and the absence of contextual information. To bridge this gap, we introduce FinFRE-RAG, a two-stage approach that applies importance-guided feature reduction to serialize a compact subset of numeric/categorical attributes into natural language and performs retrieval-augmented in-context learning over label-aware, instance-level exemplars. Across four public fraud datasets and three families of open-weight LLMs, FinFRE-RAG substantially improves F1/MCC over direct prompting and is competitive with strong tabular baselines in several settings. Although these LLMs still lag behind specialized classifiers, they narrow the performance gap and provide interpretable rationales, highlighting their value as assistive tools in fraud analysis.",
    "published": "2025-12-15T07:09:11Z",
    "authors": [
      "Xuwei Tan",
      "Yao Ma",
      "Xueru Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13039",
    "title": "Bi-Erasing: A Bidirectional Framework for Concept Removal in Diffusion Models",
    "abstract": "Concept erasure, which fine-tunes diffusion models to remove undesired or harmful visual concepts, has become a mainstream approach to mitigating unsafe or illegal image generation in text-to-image models.However, existing removal methods typically adopt a unidirectional erasure strategy by either suppressing the target concept or reinforcing safe alternatives, making it difficult to achieve a balanced trade-off between concept removal and generation quality. To address this limitation, we propose a novel Bidirectional Image-Guided Concept Erasure (Bi-Erasing) framework that performs concept suppression and safety enhancement simultaneously. Specifically, based on the joint representation of text prompts and corresponding images, Bi-Erasing introduces two decoupled image branches: a negative branch responsible for suppressing harmful semantics and a positive branch providing visual guidance for safe alternatives. By jointly optimizing these complementary directions, our approach achieves a balance between erasure efficacy and generation usability. In addition, we apply mask-based filtering to the image branches to prevent interference from irrelevant content during the erasure process. Across extensive experiment evaluations, the proposed Bi-Erasing outperforms baseline methods in balancing concept removal effectiveness and visual fidelity.",
    "published": "2025-12-15T07:08:35Z",
    "authors": [
      "Hao Chen",
      "Yiwei Wang",
      "Songze Li"
    ],
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13037",
    "title": "Progressive Refinement of E-commerce Search Ranking Based on Short-Term Activities of the Buyer",
    "abstract": "In e-commerce shopping, aligning search results with a buyer's immediate needs and preferences presents a significant challenge, particularly in adapting search results throughout the buyer's shopping journey as they move from the initial stages of browsing to making a purchase decision or shift from one intent to another. This study presents a systematic approach to adapting e-commerce search results based on the current context. We start with basic methods and incrementally incorporate more contextual information and state-of-the-art techniques to improve the search outcomes. By applying this evolving contextual framework to items displayed on the search engine results page (SERP), we progressively align search outcomes more closely with the buyer's interests and current search intentions. Our findings demonstrate that this incremental enhancement, from simple heuristic autoregressive features to advanced sequence models, significantly improves ranker performance. The integration of contextual techniques enhances the performance of our production ranker, leading to improved search results in both offline and online A/B testing in terms of Mean Reciprocal Rank (MRR). Overall, the paper details iterative methodologies and their substantial contributions to search result contextualization on e-commerce platforms.",
    "published": "2025-12-15T07:07:32Z",
    "authors": [
      "Taoran Sheng",
      "Sathappan Muthiah",
      "Atiq Islam",
      "Jinming Feng"
    ],
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13034",
    "title": "Alada: Alternating Adaptation of Momentum Method for Memory-Efficient Matrix Optimization",
    "abstract": "This work proposes Alada, an adaptive momentum method for stochastic optimization over large-scale matrices. Alada employs a rank-one factorization approach to estimate the second moment of gradients, where factors are updated alternatively to minimize the estimation error. Alada achieves sublinear memory overheads and can be readily extended to optimizing tensor-shaped variables.We also equip Alada with a first moment estimation rule, which enhances the algorithm's robustness without incurring additional memory overheads. The theoretical performance of Alada aligns with that of traditional methods such as Adam. Numerical studies conducted on several natural language processing tasks demonstrate the reduction in memory overheads and the robustness in training large models relative to Adam and its variants.",
    "published": "2025-12-15T07:04:51Z",
    "authors": [
      "Xiaoyu He",
      "Yu Cai",
      "Jin Jia",
      "Canxi Huang",
      "Wenqing Chen",
      "Zibin Zheng"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13033",
    "title": "Scaling Bidirectional Spans and Span Violations in Attention Mechanism",
    "abstract": "The canonical $O(N^2)$ Transformer remains the empirical performance frontier in sequence modeling, and its training can be further optimized by addressing geometric inefficiency. We propose an optimization framework that leverages an asymmetric projection to decompose the backward-pass gradients into parallel spans and orthogonal violations, while keeping the canonical forward-pass $QKV$ structure intact. Through consistent experimental validation across various decomposition and projection setups, we provide strong theoretical evidence: the standard attention gradient is suboptimal. We demonstrated that selectively scaling these components, focusing primarily on $0^{th}$ order bidirectional parallel spans, yields the most effective learning signal. On the limited WikiText-2 dataset, and using a crude configuration, this method achieved a $0.56\\%$ reduction in validation loss, confirming the framework's fundamental validity and suggesting significant potential gains on larger datasets and deeper training regimes",
    "published": "2025-12-15T07:03:24Z",
    "authors": [
      "Jongwook Kim",
      "Sangheon Yun",
      "Sukjin Yoon"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13031",
    "title": "Comprehensive Evaluation of Rule-Based, Machine Learning, and Deep Learning in Human Estimation Using Radio Wave Sensing: Accuracy, Spatial Generalization, and Output Granularity Trade-offs",
    "abstract": "This study presents the first comprehensive comparison of rule-based methods, traditional machine learning models, and deep learning models in radio wave sensing with frequency modulated continuous wave multiple input multiple output radar. We systematically evaluated five approaches in two indoor environments with distinct layouts: a rule-based connected component method; three traditional machine learning models, namely k-nearest neighbors, random forest, and support vector machine; and a deep learning model combining a convolutional neural network and long short term memory. In the training environment, the convolutional neural network long short term memory model achieved the highest accuracy, while traditional machine learning models provided moderate performance. In a new layout, however, all learning based methods showed significant degradation, whereas the rule-based method remained stable. Notably, for binary detection of presence versus absence of people, all models consistently achieved high accuracy across layouts. These results demonstrate that high capacity models can produce fine grained outputs with high accuracy in the same environment, but they are vulnerable to domain shift. In contrast, rule-based methods cannot provide fine grained outputs but exhibit robustness against domain shift. Moreover, regardless of the model type, a clear trade off was revealed between spatial generalization performance and output granularity.",
    "published": "2025-12-15T07:02:06Z",
    "authors": [
      "Tomoya Tanaka",
      "Tomonori Ikeda",
      "Ryo Yonemoto"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13030",
    "title": "Motus: A Unified Latent Action World Model",
    "abstract": "While a general embodied agent must function as a unified system, current methods are built on isolated models for understanding, world modeling, and control. This fragmentation prevents unifying multimodal generative capabilities and hinders learning from large-scale, heterogeneous data. In this paper, we propose Motus, a unified latent action world model that leverages existing general pretrained models and rich, sharable motion information. Motus introduces a Mixture-of-Transformer (MoT) architecture to integrate three experts (i.e., understanding, video generation, and action) and adopts a UniDiffuser-style scheduler to enable flexible switching between different modeling modes (i.e., world models, vision-language-action models, inverse dynamics models, video generation models, and video-action joint prediction models). Motus further leverages the optical flow to learn latent actions and adopts a recipe with three-phase training pipeline and six-layer data pyramid, thereby extracting pixel-level \"delta action\" and enabling large-scale action pretraining. Experiments show that Motus achieves superior performance against state-of-the-art methods in both simulation (a +15% improvement over X-VLA and a +45% improvement over Pi0.5) and real-world scenarios(improved by +11~48%), demonstrating unified modeling of all functionalities and priors significantly benefits downstream robotic tasks.",
    "published": "2025-12-15T06:58:40Z",
    "authors": [
      "Hongzhe Bi",
      "Hengkai Tan",
      "Shenghao Xie",
      "Zeyuan Wang",
      "Shuhe Huang",
      "Haitian Liu",
      "Ruowen Zhao",
      "Yao Feng",
      "Chendong Xiang",
      "Yinze Rong",
      "Hongyan Zhao",
      "Hanyu Liu",
      "Zhizhong Su",
      "Lei Ma",
      "Hang Su",
      "Jun Zhu"
    ],
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13019",
    "title": "SneakPeek: Future-Guided Instructional Streaming Video Generation",
    "abstract": "Instructional video generation is an emerging task that aims to synthesize coherent demonstrations of procedural activities from textual descriptions. Such capability has broad implications for content creation, education, and human-AI interaction, yet existing video diffusion models struggle to maintain temporal consistency and controllability across long sequences of multiple action steps. We introduce a pipeline for future-driven streaming instructional video generation, dubbed SneakPeek, a diffusion-based autoregressive framework designed to generate precise, stepwise instructional videos conditioned on an initial image and structured textual prompts. Our approach introduces three key innovations to enhance consistency and controllability: (1) predictive causal adaptation, where a causal model learns to perform next-frame prediction and anticipate future keyframes; (2) future-guided self-forcing with a dual-region KV caching scheme to address the exposure bias issue at inference time; (3) multi-prompt conditioning, which provides fine-grained and procedural control over multi-step instructions. Together, these components mitigate temporal drift, preserve motion consistency, and enable interactive video generation where future prompt updates dynamically influence ongoing streaming video generation. Experimental results demonstrate that our method produces temporally coherent and semantically faithful instructional videos that accurately follow complex, multi-step task descriptions.",
    "published": "2025-12-15T06:32:57Z",
    "authors": [
      "Cheeun Hong",
      "German Barquero",
      "Fadime Sener",
      "Markos Georgopoulos",
      "Edgar Schönfeld",
      "Stefan Popov",
      "Yuming Du",
      "Oscar Mañas",
      "Albert Pumarola"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13018",
    "title": "Comprehensive Deployment-Oriented Assessment for Cross-Environment Generalization in Deep Learning-Based mmWave Radar Sensing",
    "abstract": "This study presents the first comprehensive evaluation of spatial generalization techniques, which are essential for the practical deployment of deep learning-based radio-frequency (RF) sensing. Focusing on people counting in indoor environments using frequency-modulated continuous-wave (FMCW) multiple-input multiple-output (MIMO) radar, we systematically investigate a broad set of approaches, including amplitude-based statistical preprocessing (sigmoid weighting and threshold zeroing), frequency-domain filtering, autoencoder-based background suppression, data augmentation strategies, and transfer learning. Experimental results collected across two environments with different layouts demonstrate that sigmoid-based amplitude weighting consistently achieves superior cross-environment performance, yielding 50.1% and 55.2% reductions in root-mean-square error (RMSE) and mean absolute error (MAE), respectively, compared with baseline methods. Data augmentation provides additional though modest benefits, with improvements up to 8.8% in MAE. By contrast, transfer learning proves indispensable for large spatial shifts, achieving 82.1% and 91.3% reductions in RMSE and MAE, respectively, with 540 target-domain samples. Taken together, these findings establish a highly practical direction for developing radar sensing systems capable of maintaining robust accuracy under spatial variations by integrating deep learning models with amplitude-based preprocessing and efficient transfer learning.",
    "published": "2025-12-15T06:29:51Z",
    "authors": [
      "Tomoya Tanaka",
      "Tomonori Ikeda",
      "Ryo Yonemoto"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13015",
    "title": "What Happens Next? Next Scene Prediction with a Unified Video Model",
    "abstract": "Recent unified models for joint understanding and generation have significantly advanced visual generation capabilities. However, their focus on conventional tasks like text-to-video generation has left the temporal reasoning potential of unified models largely underexplored. To address this gap, we introduce Next Scene Prediction (NSP), a new task that pushes unified video models toward temporal and causal reasoning. Unlike text-to-video generation, NSP requires predicting plausible futures from preceding context, demanding deeper understanding and reasoning. To tackle this task, we propose a unified framework combining Qwen-VL for comprehension and LTX for synthesis, bridged by a latent query embedding and a connector module. This model is trained in three stages on our newly curated, large-scale NSP dataset: text-to-video pre-training, supervised fine-tuning, and reinforcement learning (via GRPO) with our proposed causal consistency reward. Experiments demonstrate our model achieves state-of-the-art performance on our benchmark, advancing the capability of generalist multimodal systems to anticipate what happens next.",
    "published": "2025-12-15T06:22:57Z",
    "authors": [
      "Xinjie Li",
      "Zhimin Chen",
      "Rui Zhao",
      "Florian Schiffers",
      "Zhenyu Liao",
      "Vimal Bhat"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13014",
    "title": "JoDiffusion: Jointly Diffusing Image with Pixel-Level Annotations for Semantic Segmentation Promotion",
    "abstract": "Given the inherently costly and time-intensive nature of pixel-level annotation, the generation of synthetic datasets comprising sufficiently diverse synthetic images paired with ground-truth pixel-level annotations has garnered increasing attention recently for training high-performance semantic segmentation models. However, existing methods necessitate to either predict pseudo annotations after image generation or generate images conditioned on manual annotation masks, which incurs image-annotation semantic inconsistency or scalability problem. To migrate both problems with one stone, we present a novel dataset generative diffusion framework for semantic segmentation, termed JoDiffusion. Firstly, given a standard latent diffusion model, JoDiffusion incorporates an independent annotation variational auto-encoder (VAE) network to map annotation masks into the latent space shared by images. Then, the diffusion model is tailored to capture the joint distribution of each image and its annotation mask conditioned on a text prompt. By doing these, JoDiffusion enables simultaneously generating paired images and semantically consistent annotation masks solely conditioned on text prompts, thereby demonstrating superior scalability. Additionally, a mask optimization strategy is developed to mitigate the annotation noise produced during generation. Experiments on Pascal VOC, COCO, and ADE20K datasets show that the annotated dataset generated by JoDiffusion yields substantial performance improvements in semantic segmentation compared to existing methods.",
    "published": "2025-12-15T06:21:30Z",
    "authors": [
      "Haoyu Wang",
      "Lei Zhang",
      "Wenrui Liu",
      "Dengyang Jiang",
      "Wei Wei",
      "Chen Ding"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13010",
    "title": "Deep Learning-Driven Inversion Framework for Shear Modulus Estimation in Magnetic Resonance Elastography (DIME)",
    "abstract": "The Multimodal Direct Inversion (MMDI) algorithm is widely used in Magnetic Resonance Elastography (MRE) to estimate tissue shear stiffness. However, MMDI relies on the Helmholtz equation, which assumes wave propagation in a uniform, homogeneous, and infinite medium. Furthermore, the use of the Laplacian operator makes MMDI highly sensitive to noise, which compromises the accuracy and reliability of stiffness estimates. In this study, we propose the Deep-Learning driven Inversion Framework for Shear Modulus Estimation in MRE (DIME), aimed at enhancing the robustness of inversion. DIME is trained on the displacement fields-stiffness maps pair generated through Finite Element Modelling (FEM) simulations. To capture local wave behavior and improve robustness to global image variations, DIME is trained on small image patches. We first validated DIME using homogeneous and heterogeneous datasets simulated with FEM, where DIME produced stiffness maps with low inter-pixel variability, accurate boundary delineation, and higher correlation with ground truth (GT) compared to MMDI. Next, DIME was evaluated in a realistic anatomy-informed simulated liver dataset with known GT and compared directly to MMDI. DIME reproduced ground-truth stiffness patterns with high fidelity (r = 0.99, R^2 = 0.98), while MMDI showed greater underestimation. After validating DIME on synthetic data, we tested the model in in vivo liver MRE data from eight healthy and seven fibrotic subjects. DIME preserved physiologically consistent stiffness patterns and closely matched MMDI, which showed directional bias. Overall, DIME showed higher correlation with ground truth and visually similar stiffness patterns, whereas MMDI displayed a larger bias that can potentially be attributed to directional filtering. These preliminary results highlight the feasibility of DIME for clinical applications in MRE.",
    "published": "2025-12-15T06:13:25Z",
    "authors": [
      "Hassan Iftikhar",
      "Rizwan Ahmad",
      "Arunark Kolipaka"
    ],
    "categories": [
      "cs.LG",
      "q-bio.TO"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13008",
    "title": "TWLR: Text-Guided Weakly-Supervised Lesion Localization and Severity Regression for Explainable Diabetic Retinopathy Grading",
    "abstract": "Accurate medical image analysis can greatly assist clinical diagnosis, but its effectiveness relies on high-quality expert annotations Obtaining pixel-level labels for medical images, particularly fundus images, remains costly and time-consuming. Meanwhile, despite the success of deep learning in medical imaging, the lack of interpretability limits its clinical adoption. To address these challenges, we propose TWLR, a two-stage framework for interpretable diabetic retinopathy (DR) assessment. In the first stage, a vision-language model integrates domain-specific ophthalmological knowledge into text embeddings to jointly perform DR grading and lesion classification, effectively linking semantic medical concepts with visual features. The second stage introduces an iterative severity regression framework based on weakly-supervised semantic segmentation. Lesion saliency maps generated through iterative refinement direct a progressive inpainting mechanism that systematically eliminates pathological features, effectively downgrading disease severity toward healthier fundus appearances. Critically, this severity regression approach achieves dual benefits: accurate lesion localization without pixel-level supervision and providing an interpretable visualization of disease-to-healthy transformations. Experimental results on the FGADR, DDR, and a private dataset demonstrate that TWLR achieves competitive performance in both DR classification and lesion segmentation, offering a more explainable and annotation-efficient solution for automated retinal image analysis.",
    "published": "2025-12-15T06:08:16Z",
    "authors": [
      "Xi Luo",
      "Shixin Xu",
      "Ying Xie",
      "JianZhong Hu",
      "Yuwei He",
      "Yuhui Deng",
      "Huaxiong Huang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13007",
    "title": "Light Field Based 6DoF Tracking of Previously Unobserved Objects",
    "abstract": "Object tracking is an important step in robotics and reautonomous driving pipelines, which has to generalize to previously unseen and complex objects. Existing high-performing methods often rely on pre-captured object views to build explicit reference models, which restricts them to a fixed set of known objects. However, such reference models can struggle with visually complex appearance, reducing the quality of tracking. In this work, we introduce an object tracking method based on light field images that does not depend on a pre-trained model, while being robust to complex visual behavior, such as reflections. We extract semantic and geometric features from light field inputs using vision foundation models and convert them into view-dependent Gaussian splats. These splats serve as a unified object representation, supporting differentiable rendering and pose optimization. We further introduce a light field object tracking dataset containing challenging reflective objects with precise ground truth poses. Experiments demonstrate that our method is competitive with state-of-the-art model-based trackers in these difficult cases, paving the way toward universal object tracking in robotic systems. Code/data available at https://github.com/nagonch/LiFT-6DoF.",
    "published": "2025-12-15T06:04:49Z",
    "authors": [
      "Nikolai Goncharov",
      "James L. Gray",
      "Donald G. Dansereau"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13006",
    "title": "Few-Step Distillation for Text-to-Image Generation: A Practical Guide",
    "abstract": "Diffusion distillation has dramatically accelerated class-conditional image synthesis, but its applicability to open-ended text-to-image (T2I) generation is still unclear. We present the first systematic study that adapts and compares state-of-the-art distillation techniques on a strong T2I teacher model, FLUX.1-lite. By casting existing methods into a unified framework, we identify the key obstacles that arise when moving from discrete class labels to free-form language prompts. Beyond a thorough methodological analysis, we offer practical guidelines on input scaling, network architecture, and hyperparameters, accompanied by an open-source implementation and pretrained student models. Our findings establish a solid foundation for deploying fast, high-fidelity, and resource-efficient diffusion generators in real-world T2I applications. Code is available on github.com/alibaba-damo-academy/T2I-Distill.",
    "published": "2025-12-15T05:58:36Z",
    "authors": [
      "Yifan Pu",
      "Yizeng Han",
      "Zhiwei Tang",
      "Jiasheng Tang",
      "Fan Wang",
      "Bohan Zhuang",
      "Gao Huang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.13003",
    "title": "General OOD Detection via Model-aware and Subspace-aware Variable Priority",
    "abstract": "Out-of-distribution (OOD) detection is essential for determining when a supervised model encounters inputs that differ meaningfully from its training distribution. While widely studied in classification, OOD detection for regression and survival analysis remains limited due to the absence of discrete labels and the challenge of quantifying predictive uncertainty. We introduce a framework for OOD detection that is simultaneously model aware and subspace aware, and that embeds variable prioritization directly into the detection step. The method uses the fitted predictor to construct localized neighborhoods around each test case that emphasize the features driving the model's learned relationship and downweight directions that are less relevant to prediction. It produces OOD scores without relying on global distance metrics or estimating the full feature density. The framework is applicable across outcome types, and in our implementation we use random forests, where the rule structure yields transparent neighborhoods and effective scoring. Experiments on synthetic and real data benchmarks designed to isolate functional shifts show consistent improvements over existing methods. We further demonstrate the approach in an esophageal cancer survival study, where distribution shifts related to lymphadenectomy identify patterns relevant to surgical guidelines.",
    "published": "2025-12-15T05:55:35Z",
    "authors": [
      "Min Lu",
      "Hemant Ishwaran"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12997",
    "title": "Calibrating Uncertainty for Zero-Shot Adversarial CLIP",
    "abstract": "CLIP delivers strong zero-shot classification but remains highly vulnerable to adversarial attacks. Previous work of adversarial fine-tuning largely focuses on matching the predicted logits between clean and adversarial examples, which overlooks uncertainty calibration and may degrade the zero-shot generalization. A common expectation in reliable uncertainty estimation is that predictive uncertainty should increase as inputs become more difficult or shift away from the training distribution. However, we frequently observe the opposite in the adversarial setting: perturbations not only degrade accuracy but also suppress uncertainty, leading to severe miscalibration and unreliable over-confidence. This overlooked phenomenon highlights a critical reliability gap beyond robustness. To bridge this gap, we propose a novel adversarial fine-tuning objective for CLIP considering both prediction accuracy and uncertainty alignments. By reparameterizing the output of CLIP as the concentration parameter of a Dirichlet distribution, we propose a unified representation that captures relative semantic structure and the magnitude of predictive confidence. Our objective aligns these distributions holistically under perturbations, moving beyond single-logit anchoring and restoring calibrated uncertainty. Experiments on multiple zero-shot classification benchmarks demonstrate that our approach effectively restores calibrated uncertainty and achieves competitive adversarial robustness while maintaining clean accuracy.",
    "published": "2025-12-15T05:41:08Z",
    "authors": [
      "Wenjing lu",
      "Zerui Tao",
      "Dongping Zhang",
      "Yuning Qiu",
      "Yang Yang",
      "Qibin Zhao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12989",
    "title": "Quantigence: A Multi-Agent AI Framework for Quantum Security Research",
    "abstract": "Cryptographically Relevant Quantum Computers (CRQCs) pose a structural threat to the global digital economy. Algorithms like Shor's factoring and Grover's search threaten to dismantle the public-key infrastructure (PKI) securing sovereign communications and financial transactions. While the timeline for fault-tolerant CRQCs remains probabilistic, the \"Store-Now, Decrypt-Later\" (SNDL) model necessitates immediate migration to Post-Quantum Cryptography (PQC). This transition is hindered by the velocity of research, evolving NIST standards, and heterogeneous deployment environments. To address this, we present Quantigence, a theory-driven multi-agent AI framework for structured quantum-security analysis. Quantigence decomposes research objectives into specialized roles - Cryptographic Analyst, Threat Modeler, Standards Specialist, and Risk Assessor - coordinated by a supervisory agent. Using \"cognitive parallelism,\" agents reason independently to maintain context purity while execution is serialized on resource-constrained hardware (e.g., NVIDIA RTX 2060). The framework integrates external knowledge via the Model Context Protocol (MCP) and prioritizes vulnerabilities using the Quantum-Adjusted Risk Score (QARS), a formal extension of Mosca's Theorem. Empirical validation shows Quantigence achieves a 67% reduction in research turnaround time and superior literature coverage compared to manual workflows, democratizing access to high-fidelity quantum risk assessment.",
    "published": "2025-12-15T05:27:10Z",
    "authors": [
      "Abdulmalik Alquwayfili"
    ],
    "categories": [
      "cs.MA",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12987",
    "title": "Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning",
    "abstract": "This paper proposes two new algorithms for the lane keeping system (LKS) in autonomous vehicles (AVs) operating under snowy road conditions. These algorithms use deep reinforcement learning (DRL) to handle uncertainties and slippage. They include Action-Robust Recurrent Deep Deterministic Policy Gradient (AR-RDPG) and end-to-end Action-Robust convolutional neural network Attention Deterministic Policy Gradient (AR-CADPG), two action-robust approaches for decision-making. In the AR-RDPG method, within the perception layer, camera images are first denoised using multi-scale neural networks. Then, the centerline coefficients are extracted by a pre-trained deep convolutional neural network (DCNN). These coefficients, concatenated with the driving characteristics, are used as input to the control layer. The AR-CADPG method presents an end-to-end approach in which a convolutional neural network (CNN) and an attention mechanism are integrated within a DRL framework. Both methods are first trained in the CARLA simulator and validated under various snowy scenarios. Real-world experiments on a Jetson Nano-based autonomous vehicle confirm the feasibility and stability of the learned policies. Among the two models, the AR-CADPG approach demonstrates superior path-tracking accuracy and robustness, highlighting the effectiveness of combining temporal memory, adversarial resilience, and attention mechanisms in AVs.",
    "published": "2025-12-15T05:23:23Z",
    "authors": [
      "Amin Jalal Aghdasian",
      "Farzaneh Abdollahi",
      "Ali Kamali Iglie"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12984",
    "title": "VoroLight: Learning Quality Volumetric Voronoi Meshes from General Inputs",
    "abstract": "We present VoroLight, a differentiable framework for 3D shape reconstruction based on Voronoi meshing. Our approach generates smooth, watertight surfaces and topologically consistent volumetric meshes directly from diverse inputs, including images, implicit shape level-set fields, point clouds and meshes. VoroLight operates in three stages: it first initializes a surface using a differentiable Voronoi formulation, then refines surface quality through a polygon-face sphere training stage, and finally reuses the differentiable Voronoi formulation for volumetric optimization with additional interior generator points. Project page: https://jiayinlu19960224.github.io/vorolight/",
    "published": "2025-12-15T05:01:59Z",
    "authors": [
      "Jiayin Lu",
      "Ying Jiang",
      "Yin Yang",
      "Chenfanfu Jiang"
    ],
    "categories": [
      "cs.CG",
      "cs.CV",
      "cs.GR",
      "cs.LG",
      "math.OC"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12982",
    "title": "Scaling Up AI-Generated Image Detection via Generator-Aware Prototypes",
    "abstract": "The pursuit of a universal AI-generated image (AIGI) detector often relies on aggregating data from numerous generators to improve generalization. However, this paper identifies a paradoxical phenomenon we term the Benefit then Conflict dilemma, where detector performance stagnates and eventually degrades as source diversity expands. Our systematic analysis, diagnoses this failure by identifying two core issues: severe data-level heterogeneity, which causes the feature distributions of real and synthetic images to increasingly overlap, and a critical model-level bottleneck from fixed, pretrained encoders that cannot adapt to the rising complexity. To address these challenges, we propose Generator-Aware Prototype Learning (GAPL), a framework that constrain representation with a structured learning paradigm. GAPL learns a compact set of canonical forgery prototypes to create a unified, low-variance feature space, effectively countering data heterogeneity.To resolve the model bottleneck, it employs a two-stage training scheme with Low-Rank Adaptation, enhancing its discriminative power while preserving valuable pretrained knowledge. This approach establishes a more robust and generalizable decision boundary. Through extensive experiments, we demonstrate that GAPL achieves state-of-the-art performance, showing superior detection accuracy across a wide variety of GAN and diffusion-based generators. Code is available at https://github.com/UltraCapture/GAPL",
    "published": "2025-12-15T04:58:08Z",
    "authors": [
      "Ziheng Qin",
      "Yuheng Ji",
      "Renshuai Tao",
      "Yuxuan Tian",
      "Yuyang Liu",
      "Yipu Wang",
      "Xiaolong Zheng"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12981",
    "title": "CoDeQ: End-to-End Joint Model Compression with Dead-Zone Quantizer for High-Sparsity and Low-Precision Networks",
    "abstract": "While joint pruning--quantization is theoretically superior to sequential application, current joint methods rely on auxiliary procedures outside the training loop for finding compression parameters. This reliance adds engineering complexity and hyperparameter tuning, while also lacking a direct data-driven gradient signal, which might result in sub-optimal compression. In this paper, we introduce CoDeQ, a simple, fully differentiable method for joint pruning--quantization. Our approach builds on a key observation: the dead-zone of a scalar quantizer is equivalent to magnitude pruning, and can be used to induce sparsity directly within the quantization operator. Concretely, we parameterize the dead-zone width and learn it via backpropagation, alongside the quantization parameters. This design provides explicit control of sparsity, regularized by a single global hyperparameter, while decoupling sparsity selection from bit-width selection. The result is a method for Compression with Dead-zone Quantizer (CoDeQ) that supports both fixed-precision and mixed-precision quantization (controlled by an optional second hyperparameter). It simultaneously determines the sparsity pattern and quantization parameters in a single end-to-end optimization. Consequently, CoDeQ does not require any auxiliary procedures, making the method architecture-agnostic and straightforward to implement. On ImageNet with ResNet-18, CoDeQ reduces bit operations to ~5% while maintaining close to full precision accuracy in both fixed and mixed-precision regimes.",
    "published": "2025-12-15T04:53:32Z",
    "authors": [
      "Jonathan Wenshøj",
      "Tong Chen",
      "Bob Pepin",
      "Raghavendra Selvan"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12977",
    "title": "VLCache: Computing 2% Vision Tokens and Reusing 98% for Vision-Language Inference",
    "abstract": "This paper presents VLCache, a cache reuse framework that exploits both Key-Value (KV) cache and encoder cache from prior multimodal inputs to eliminate costly recomputation when the same multimodal inputs recur. Unlike previous heuristic approaches, we formally identify the cumulative reuse error effect and demonstrate how to minimize the non-prefix cache reuse error effectively. We further analyze the varying importance of model layers and propose a dynamic, layer-aware recomputation strategy to balance accuracy and efficiency. Experimental results show that VLCache achieves an accuracy on par with full recomputation, while requiring only 2-5% of the tokens to compute, yielding 1.2x-16x TTFT speedups. The proposed VLCache pipeline has been integrated into SGLang, enabling significantly faster inference in practical deployments.",
    "published": "2025-12-15T04:45:47Z",
    "authors": [
      "Shengling Qin",
      "Hao Yu",
      "Chenxin Wu",
      "Zheng Li",
      "Yizhong Cao",
      "Zhengyang Zhuge",
      "Yuxin Zhou",
      "Wentao Yao",
      "Yi Zhang",
      "Zhengheng Wang",
      "Shuai Bai",
      "Jianwei Zhang",
      "Junyang Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12976",
    "title": "Authors Should Annotate",
    "abstract": "The status quo for labeling text is third-party annotation, but there are many cases where information directly from the document's source would be preferable over a third-person proxy, especially for egocentric features like sentiment and belief. We introduce author labeling, an annotation technique where the writer of the document itself annotates the data at the moment of creation. We collaborate with a commercial chatbot with over 10,000 users to deploy an author labeling annotation system for subjective features related to product recommendation. This system identifies task-relevant queries, generates on-the-fly labeling questions, and records authors' answers in real time. We train and deploy an online-learning model architecture for product recommendation that continuously improves from author labeling and find it achieved a 534% increase in click-through rate compared to an industry advertising baseline running concurrently. We then compare the quality and practicality of author labeling to three traditional annotation approaches for sentiment analysis and find author labeling to be higher quality, faster to acquire, and cheaper. These findings reinforce existing literature that annotations, especially for egocentric and subjective beliefs, are significantly higher quality when labeled by the author rather than a third party. To facilitate broader scientific adoption, we release an author labeling service for the research community at academic.echollm.io.",
    "published": "2025-12-15T04:45:09Z",
    "authors": [
      "Marcus Ma",
      "Cole Johnson",
      "Nolan Bridges",
      "Jackson Trager",
      "Georgios Chochlakis",
      "Shrikanth Narayanan"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12975",
    "title": "Application of Deep Learning in Biological Data Compression",
    "abstract": "Cryogenic electron microscopy (Cryo-EM) has become an essential tool for capturing high-resolution biological structures. Despite its advantage in visualizations, the large storage size of Cryo-EM data file poses significant challenges for researchers and educators. This paper investigates the application of deep learning, specifically implicit neural representation (INR), to compress Cryo-EM biological data. The proposed approach first extracts the binary map of each file according to the density threshold. The density map is highly repetitive, ehich can be effectively compressed by GZIP. The neural network then trains to encode spatial density information, allowing the storage of network parameters and learnable latent vectors. To improve reconstruction accuracy, I further incorporate the positional encoding to enhance spatial representation and a weighted Mean Squared Error (MSE) loss function to balance density distribution variations. Using this approach, my aim is to provide a practical and efficient biological data compression solution that can be used for educational and research purpose, while maintaining a reasonable compression ratio and reconstruction quality from file to file.",
    "published": "2025-12-15T04:40:23Z",
    "authors": [
      "Chunyu Zou"
    ],
    "categories": [
      "cs.LG",
      "cs.IT"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12970",
    "title": "Towards Open Standards for Systemic Complexity in Digital Forensics",
    "abstract": "The intersection of artificial intelligence (AI) and digital forensics (DF) is becoming increasingly complex, ubiquitous, and pervasive, with overlapping techniques and technologies being adopted in all types of scientific and technical inquiry. Despite incredible advances, forensic sciences are not exempt from errors and remain vulnerable to fallibility. To mitigate the limitations of errors in DF, the systemic complexity is identified and addressed with the adoption of human-readable artifacts and open standards. A DF AI model schema based on the state of the art is outlined.",
    "published": "2025-12-15T04:18:56Z",
    "authors": [
      "Paola Di Maio"
    ],
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12967",
    "title": "QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management",
    "abstract": "We introduce QwenLong-L1.5, a model that achieves superior long-context reasoning capabilities through systematic post-training innovations. The key technical breakthroughs of QwenLong-L1.5 are as follows: (1) Long-Context Data Synthesis Pipeline: We develop a systematic synthesis framework that generates challenging reasoning tasks requiring multi-hop grounding over globally distributed evidence. By deconstructing documents into atomic facts and their underlying relationships, and then programmatically composing verifiable reasoning questions, our approach creates high-quality training data at scale, moving substantially beyond simple retrieval tasks to enable genuine long-range reasoning capabilities. (2) Stabilized Reinforcement Learning for Long-Context Training: To overcome the critical instability in long-context RL, we introduce task-balanced sampling with task-specific advantage estimation to mitigate reward bias, and propose Adaptive Entropy-Controlled Policy Optimization (AEPO) that dynamically regulates exploration-exploitation trade-offs. (3) Memory-Augmented Architecture for Ultra-Long Contexts: Recognizing that even extended context windows cannot accommodate arbitrarily long sequences, we develop a memory management framework with multi-stage fusion RL training that seamlessly integrates single-pass reasoning with iterative memory-based processing for tasks exceeding 4M tokens. Based on Qwen3-30B-A3B-Thinking, QwenLong-L1.5 achieves performance comparable to GPT-5 and Gemini-2.5-Pro on long-context reasoning benchmarks, surpassing its baseline by 9.90 points on average. On ultra-long tasks (1M~4M tokens), QwenLong-L1.5's memory-agent framework yields a 9.48-point gain over the agent baseline. Additionally, the acquired long-context reasoning ability translates to enhanced performance in general domains like scientific reasoning, memory tool using, and extended dialogue.",
    "published": "2025-12-15T04:11:11Z",
    "authors": [
      "Weizhou Shen",
      "Ziyi Yang",
      "Chenliang Li",
      "Zhiyuan Lu",
      "Miao Peng",
      "Huashan Sun",
      "Yingcheng Shi",
      "Shengyi Liao",
      "Shaopeng Lai",
      "Bo Zhang",
      "Dayiheng Liu",
      "Fei Huang",
      "Jingren Zhou",
      "Ming Yan"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12965",
    "title": "Challenges and Enablers: Remote Work for People with Disabilities in Software Development Teams",
    "abstract": "The increasing adoption of remote and hybrid work modalities in the technology sector has brought new opportunities and challenges for the inclusion of people with disabilities (PWD) in software development teams (SDT). This study investigates how remote work affects PWDs' experience in mixed-ability SDT, focusing on the unique challenges and strategies that emerge in remote environments. We conducted an online survey with \\totalSurveyResponses valid responses, encompassing PWD, their leaders, and teammates, to capture sociotechnical aspects of their experiences with remote collaboration. To deepen our understanding, we carried out 14 structured interviews with software developers who self-identified as having disabilities (six autistic individuals, six with physical disabilities, and two who are d/Deaf). Our analysis combines quantitative data with qualitative coding of open-ended survey responses and interview transcripts. The results reveal that, despite the barriers faced by team members with disabilities, their teammates and leaders have a limited perception of the daily challenges involved in sustaining collaborative remote work. These findings highlight opportunities for improvement in accessibility tools, communication strategies, and adaptive management approaches.",
    "published": "2025-12-15T04:05:36Z",
    "authors": [
      "Thayssa Rocha",
      "Luciano Teran",
      "Marcelle Mota",
      "Cleidson de Souza",
      "Kiev Gama",
      "Gustavo Pinto"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12963",
    "title": "SCAdapter: Content-Style Disentanglement for Diffusion Style Transfer",
    "abstract": "Diffusion models have emerged as the leading approach for style transfer, yet they struggle with photo-realistic transfers, often producing painting-like results or missing detailed stylistic elements. Current methods inadequately address unwanted influence from original content styles and style reference content features. We introduce SCAdapter, a novel technique leveraging CLIP image space to effectively separate and integrate content and style features. Our key innovation systematically extracts pure content from content images and style elements from style references, ensuring authentic transfers. This approach is enhanced through three components: Controllable Style Adaptive Instance Normalization (CSAdaIN) for precise multi-style blending, KVS Injection for targeted style integration, and a style transfer consistency objective maintaining process coherence. Comprehensive experiments demonstrate SCAdapter significantly outperforms state-of-the-art methods in both conventional and diffusion-based baselines. By eliminating DDIM inversion and inference-stage optimization, our method achieves at least $2\\times$ faster inference than other diffusion-based approaches, making it both more effective and efficient for practical applications.",
    "published": "2025-12-15T04:02:14Z",
    "authors": [
      "Luan Thanh Trinh",
      "Kenji Doi",
      "Atsuki Osanai"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12952",
    "title": "Leveraging Compression to Construct Transferable Bitrate Ladders",
    "abstract": "Over the past few years, per-title and per-shot video encoding techniques have demonstrated significant gains as compared to conventional techniques such as constant CRF encoding and the fixed bitrate ladder. These techniques have demonstrated that constructing content-gnostic per-shot bitrate ladders can provide significant bitrate gains and improved Quality of Experience (QoE) for viewers under various network conditions. However, constructing a convex hull for every video incurs a significant computational overhead. Recently, machine learning-based bitrate ladder construction techniques have emerged as a substitute for convex hull construction. These methods operate by extracting features from source videos to train machine learning (ML) models to construct content-adaptive bitrate ladders. Here, we present a new ML-based bitrate ladder construction technique that accurately predicts the VMAF scores of compressed videos, by analyzing the compression procedure and by making perceptually relevant measurements on the source videos prior to compression. We evaluate the performance of our proposed framework against leading prior methods on a large corpus of videos. Since training ML models on every encoder setting is time-consuming, we also investigate how per-shot bitrate ladders perform under different encoding settings. We evaluate the performance of all models against the fixed bitrate ladder and the best possible convex hull constructed using exhaustive encoding with Bjontegaard-delta metrics.",
    "published": "2025-12-15T03:38:26Z",
    "authors": [
      "Krishna Srikar Durbha",
      "Hassene Tmar",
      "Ping-Hao Wu",
      "Ioannis Katsavounidis",
      "Alan C. Bovik"
    ],
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12950",
    "title": "Building from Scratch: A Multi-Agent Framework with Human-in-the-Loop for Multilingual Legal Terminology Mapping",
    "abstract": "Accurately mapping legal terminology across languages remains a significant challenge, especially for language pairs like Chinese and Japanese, which share a large number of homographs with different meanings. Existing resources and standardized tools for these languages are limited. To address this, we propose a human-AI collaborative approach for building a multilingual legal terminology database, based on a multi-agent framework. This approach integrates advanced large language models and legal domain experts throughout the entire process-from raw document preprocessing, article-level alignment, to terminology extraction, mapping, and quality assurance. Unlike a single automated pipeline, our approach places greater emphasis on how human experts participate in this multi-agent system. Humans and AI agents take on different roles: AI agents handle specific, repetitive tasks, such as OCR, text segmentation, semantic alignment, and initial terminology extraction, while human experts provide crucial oversight, review, and supervise the outputs with contextual knowledge and legal judgment. We tested the effectiveness of this framework using a trilingual parallel corpus comprising 35 key Chinese statutes, along with their English and Japanese translations. The experimental results show that this human-in-the-loop, multi-agent workflow not only improves the precision and consistency of multilingual legal terminology mapping but also offers greater scalability compared to traditional manual methods.",
    "published": "2025-12-15T03:29:21Z",
    "authors": [
      "Lingyi Meng",
      "Maolin Liu",
      "Hao Wang",
      "Yilan Cheng",
      "Qi Yang",
      "Idlkaid Mohanmmed"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12949",
    "title": "FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection",
    "abstract": "The scaling of computation throughput continues to outpace improvements in memory bandwidth, making many deep learning workloads memory-bound. Kernel fusion is a key technique to alleviate this problem, but the fusion strategies of existing compilers and frameworks are limited to using local scratchpad memory. When the intermediate results exceed the limited capacity (such as FFN), the fusion fails. Although modern GPUs (like the NVIDIA H100) now incorporate an inter-core connection mechanism known as Distributed Shared Memory(DSM)--providing a larger, high-bandwidth, and low-latency on-chip memory pool--this hardware potential has yet to be exploited by software frameworks. To bridge this gap, we present FlashFuser, the first compiler framework to utilize inter-core connection for kernel fusion on modern GPUs. FlashFuser extends established fusion techniques to the DSM domain through three core contributions. First, we propose a powerful DSM-based communication abstraction that formalizes complex cluster-based data exchange patterns, such as reduce, shuffle and multiply. Second, we introduce a dataflow analyzer that generalizes loop scheduling, resource mapping, and tile selection to the distributed memory hierarchy; it determines the optimal execution order and tile sizes by quantifying data movement across memory levels. Finally, FlashFuser integrates these components into a unified search engine that employs analytical cost modeling and DSM-aware pruning strategies to efficiently discover the optimal execution plan. Our evaluation on an NVIDIA H100 GPU shows that FlashFuser reduces memory access by 58% and delivers kernel speedups of 3.3x against highly-tuned libraries and 4.1x against state-of-the-art compilers, resulting in a 1.24x end-to-end speedup.",
    "published": "2025-12-15T03:27:49Z",
    "authors": [
      "Ziyu Huang",
      "Yangjie Zhou",
      "Zihan Liu",
      "Xinhao Luo",
      "Yijia Diao",
      "Minyi Guo",
      "Jidong Zhai",
      "Yu Feng",
      "Chen Zhang",
      "Anbang Wu",
      "Jingwen Leng"
    ],
    "categories": [
      "cs.DC"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12947",
    "title": "Understanding When Graph Convolutional Networks Help: A Diagnostic Study on Label Scarcity and Structural Properties",
    "abstract": "Graph Convolutional Networks (GCNs) have become a standard approach for semi-supervised node classification, yet practitioners lack clear guidance on when GCNs provide meaningful improvements over simpler baselines. We present a diagnostic study using the Amazon Computers co-purchase data to understand when and why GCNs help. Through systematic experiments with simulated label scarcity, feature ablation, and per-class analysis, we find that GCN performance depends critically on the interaction between graph homophily and feature quality. GCNs provide the largest gains under extreme label scarcity, where they leverage neighborhood structure to compensate for limited supervision. Surprisingly, GCNs can match their original performance even when node features are replaced with random noise, suggesting that structure alone carries sufficient signal on highly homophilous graphs. However, GCNs hurt performance when homophily is low and features are already strong, as noisy neighbors corrupt good predictions. Our quadrant analysis reveals that GCNs help in three of four conditions and only hurt when low homophily meets strong features. These findings offer practical guidance for practitioners deciding whether to adopt graph-based methods.",
    "published": "2025-12-15T03:23:50Z",
    "authors": [
      "Nischal Subedi",
      "Ember Kerstetter",
      "Winnie Li",
      "Silo Murphy"
    ],
    "categories": [
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12945",
    "title": "SLIM-VDB: A Real-Time 3D Probabilistic Semantic Mapping Framework",
    "abstract": "This paper introduces SLIM-VDB, a new lightweight semantic mapping system with probabilistic semantic fusion for closed-set or open-set dictionaries. Advances in data structures from the computer graphics community, such as OpenVDB, have demonstrated significantly improved computational and memory efficiency in volumetric scene representation. Although OpenVDB has been used for geometric mapping in robotics applications, semantic mapping for scene understanding with OpenVDB remains unexplored. In addition, existing semantic mapping systems lack support for integrating both fixed-category and open-language label predictions within a single framework. In this paper, we propose a novel 3D semantic mapping system that leverages the OpenVDB data structure and integrates a unified Bayesian update framework for both closed- and open-set semantic fusion. Our proposed framework, SLIM-VDB, achieves significant reduction in both memory and integration times compared to current state-of-the-art semantic mapping approaches, while maintaining comparable mapping accuracy. An open-source C++ codebase with a Python interface is available at https://github.com/umfieldrobotics/slim-vdb.",
    "published": "2025-12-15T03:16:04Z",
    "authors": [
      "Anja Sheppard",
      "Parker Ewen",
      "Joey Wilson",
      "Advaith V. Sethuraman",
      "Benard Adewole",
      "Anran Li",
      "Yuzhen Chen",
      "Ram Vasudevan",
      "Katherine A. Skinner"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12941",
    "title": "UAGLNet: Uncertainty-Aggregated Global-Local Fusion Network with Cooperative CNN-Transformer for Building Extraction",
    "abstract": "Building extraction from remote sensing images is a challenging task due to the complex structure variations of the buildings. Existing methods employ convolutional or self-attention blocks to capture the multi-scale features in the segmentation models, while the inherent gap of the feature pyramids and insufficient global-local feature integration leads to inaccurate, ambiguous extraction results. To address this issue, in this paper, we present an Uncertainty-Aggregated Global-Local Fusion Network (UAGLNet), which is capable to exploit high-quality global-local visual semantics under the guidance of uncertainty modeling. Specifically, we propose a novel cooperative encoder, which adopts hybrid CNN and transformer layers at different stages to capture the local and global visual semantics, respectively. An intermediate cooperative interaction block (CIB) is designed to narrow the gap between the local and global features when the network becomes deeper. Afterwards, we propose a Global-Local Fusion (GLF) module to complementarily fuse the global and local representations. Moreover, to mitigate the segmentation ambiguity in uncertain regions, we propose an Uncertainty-Aggregated Decoder (UAD) to explicitly estimate the pixel-wise uncertainty to enhance the segmentation accuracy. Extensive experiments demonstrate that our method achieves superior performance to other state-of-the-art methods. Our code is available at https://github.com/Dstate/UAGLNet",
    "published": "2025-12-15T02:59:16Z",
    "authors": [
      "Siyuan Yao",
      "Dongxiu Liu",
      "Taotao Li",
      "Shengjie Li",
      "Wenqi Ren",
      "Xiaochun Cao"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12939",
    "title": "Continuous Edit Distance, Geodesics and Barycenters of Time-varying Persistence Diagrams",
    "abstract": "We introduce the Continuous Edit Distance (CED), a geodesic and elastic distance for time-varying persistence diagrams (TVPDs). The CED extends edit-distance ideas to TVPDs by combining local substitution costs with penalized deletions/insertions, controlled by two parameters: \\(α\\) (trade-off between temporal misalignment and diagram discrepancy) and \\(β\\) (gap penalty). We also provide an explicit construction of CED-geodesics. Building on these ingredients, we present two practical barycenter solvers, one stochastic and one greedy, that monotonically decrease the CED Frechet energy. Empirically, the CED is robust to additive perturbations (both temporal and spatial), recovers temporal shifts, and supports temporal pattern search. On real-life datasets, the CED achieves clustering performance comparable or better than standard elastic dissimilarities, while our clustering based on CED-barycenters yields superior classification results. Overall, the CED equips TVPD analysis with a principled distance, interpretable geodesics, and practical barycenters, enabling alignment, comparison, averaging, and clustering directly in the space of TVPDs. A C++ implementation is provided for reproducibility at the following address https://github.com/sebastien-tchitchek/ContinuousEditDistance.",
    "published": "2025-12-15T02:57:21Z",
    "authors": [
      "Sebastien Tchitchek",
      "Mohamed Kissi",
      "Julien Tierny"
    ],
    "categories": [
      "cs.CG",
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12936",
    "title": "Content Adaptive based Motion Alignment Framework for Learned Video Compression",
    "abstract": "Recent advances in end-to-end video compression have shown promising results owing to their unified end-to-end learning optimization. However, such generalized frameworks often lack content-specific adaptation, leading to suboptimal compression performance. To address this, this paper proposes a content adaptive based motion alignment framework that improves performance by adapting encoding strategies to diverse content characteristics. Specifically, we first introduce a two-stage flow-guided deformable warping mechanism that refines motion compensation with coarse-to-fine offset prediction and mask modulation, enabling precise feature alignment. Second, we propose a multi-reference quality aware strategy that adjusts distortion weights based on reference quality, and applies it to hierarchical training to reduce error propagation. Third, we integrate a training-free module that downsamples frames by motion magnitude and resolution to obtain smooth motion estimation. Experimental results on standard test datasets demonstrate that our framework CAMA achieves significant improvements over state-of-the-art Neural Video Compression models, achieving a 24.95% BD-rate (PSNR) savings over our baseline model DCVC-TCM, while also outperforming reproduced DCVC-DC and traditional codec HM-16.25.",
    "published": "2025-12-15T02:51:47Z",
    "authors": [
      "Tiange Zhang",
      "Xiandong Meng",
      "Siwei Ma"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12935",
    "title": "Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion",
    "abstract": "The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, Agent-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.",
    "published": "2025-12-15T02:50:43Z",
    "authors": [
      "Toan Le Ngo Thanh",
      "Phat Ha Huu",
      "Tan Nguyen Dang Duy",
      "Thong Nguyen Le Minh",
      "Anh Nguyen Nhu Tinh"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12932",
    "title": "Investigating Data Pruning for Pretraining Biological Foundation Models at Scale",
    "abstract": "Biological foundation models (BioFMs), pretrained on large-scale biological sequences, have recently shown strong potential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models often rely on millions to billions of training sequences and billions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessibility, particularly for academic labs. To address these challenges, we investigate the feasibility of data pruning for BioFM pretraining and propose a post-hoc influence-guided data pruning framework tailored to biological domains. Our approach introduces a subset-based self-influence formulation that enables efficient estimation of sample importance at low computational cost, and builds upon it two simple yet effective selection strategies, namely Top-k Influence (Top I) and Coverage-Centric Influence (CCI). We empirically validate our method on two representative BioFMs, RNA-FM and ESM-C. For RNA, our framework consistently outperforms random selection baselines under an extreme pruning rate of over 99 percent, demonstrating its effectiveness. Furthermore, we show the generalizability of our framework on protein-related tasks using ESM-C. In particular, our coreset even outperforms random subsets that are ten times larger in both RNA and protein settings, revealing substantial redundancy in biological sequence datasets. These findings underscore the potential of influence-guided data pruning to substantially reduce the computational cost of BioFM pretraining, paving the way for more efficient, accessible, and sustainable biological AI research.",
    "published": "2025-12-15T02:42:52Z",
    "authors": [
      "Yifan Wu",
      "Jiyue Jiang",
      "Xichen Ye",
      "Yiqi Wang",
      "Chang Zhou",
      "Yitao Xu",
      "Jiayang Chen",
      "He Hu",
      "Weizhong Zhang",
      "Cheng Jin",
      "Jiao Yuan",
      "Yu Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12930",
    "title": "SeVeDo: A Heterogeneous Transformer Accelerator for Low-Bit Inference via Hierarchical Group Quantization and SVD-Guided Mixed Precision",
    "abstract": "Low-bit quantization is a promising technique for efficient transformer inference by reducing computational and memory overhead. However, aggressive bitwidth reduction remains challenging due to activation outliers, leading to accuracy degradation. Existing methods, such as outlier-handling and group quantization, achieve high accuracy but incur substantial energy consumption. To address this, we propose SeVeDo, an energy-efficient SVD-based heterogeneous accelerator that structurally separates outlier-sensitive components into a high-precision low-rank path, while the remaining computations are executed in a low-bit residual datapath with group quantization. To further enhance efficiency, Hierarchical Group Quantization (HGQ) combines coarse-grained floating-point scaling with fine-grained shifting, effectively reducing dequantization cost. Also, SVD-guided mixed precision (SVD-MP) statically allocates higher bitwidths to precision-sensitive components identified through low-rank decomposition, thereby minimizing floating-point operation cost. Experimental results show that SeVeDo achieves a peak energy efficiency of 13.8TOPS/W, surpassing conventional designs, with 12.7TOPS/W on ViT-Base and 13.4TOPS/W on Llama2-7B benchmarks.",
    "published": "2025-12-15T02:29:08Z",
    "authors": [
      "Yuseon Choi",
      "Sangjin Kim",
      "Jungjun Oh",
      "Byeongcheol Kim",
      "Hoi-Jun Yoo"
    ],
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12929",
    "title": "MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation",
    "abstract": "The rapid expansion of video content across online platforms has accelerated the need for retrieval systems capable of understanding not only isolated visual moments but also the temporal structure of complex events. Existing approaches often fall short in modeling temporal dependencies across multiple events and in handling queries that reference unseen or rare visual concepts. To address these challenges, we introduce MADTempo, a video retrieval framework developed by our team, AIO_Trinh, that unifies temporal search with web-scale visual grounding. Our temporal search mechanism captures event-level continuity by aggregating similarity scores across sequential video segments, enabling coherent retrieval of multi-event queries. Complementarily, a Google Image Search-based fallback module expands query representations with external web imagery, effectively bridging gaps in pretrained visual embeddings and improving robustness against out-of-distribution (OOD) queries. Together, these components advance the temporal reasoning and generalization capabilities of modern video retrieval systems, paving the way for more semantically aware and adaptive retrieval across large-scale video corpora.",
    "published": "2025-12-15T02:25:46Z",
    "authors": [
      "Huu-An Vu",
      "Van-Khanh Mai",
      "Trong-Tam Nguyen",
      "Quang-Duc Dam",
      "Tien-Huy Nguyen",
      "Thanh-Huong Le"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12928",
    "title": "PROSERVE: Unified Multi-Priority Request Scheduling for LLM Serving",
    "abstract": "The widespread deployment of large language models (LLMs) for interactive applications necessitates serving systems that can handle thousands of concurrent requests with diverse Service Level Objective (SLO) requirements. A critical yet often overlooked dimension in this context is the inherent priority difference among clients; for instance, business-critical functions demand higher performance guarantees, as fulfilling such requests yields significantly greater business value. However, existing LLM serving schedulers fail to jointly optimize for both SLO attainment and client-level priorities.   To bridge this gap, we first \\textit{formalize multi-priority request scheduling as a service gain maximization problem}, where satisfying latency requirements for requests of different priorities contributes varying levels of gain. We then propose PROSERVE, a unified two-tier scheduling framework designed to maximize overall service gain. At the engine level, SlideBatching dynamically adapts batch formation and request ordering under varying load conditions, employing a sliding boundary mechanism to balance deadline-first and density-first strategies. At the service level, GoRouting performs gain-oriented and capability-aware dispatching across distributed instances, proactively reserving capacity for future high-priority or long requests. Extensive evaluation across four open-source datasets and a real-world industrial trace demonstrates that \\systemname{} consistently outperforms state-of-the-art baselines, improving system gain by up to 35% and boosting SLO attainment by up to 52%.",
    "published": "2025-12-15T02:24:50Z",
    "authors": [
      "Weizhe Huang",
      "Tao Peng",
      "Tongxuan Liu",
      "Donghe Jin",
      "Xianzhe Dong",
      "Ke Zhang"
    ],
    "categories": [
      "cs.DC"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12925",
    "title": "Sharpness-aware Dynamic Anchor Selection for Generalized Category Discovery",
    "abstract": "Generalized category discovery (GCD) is an important and challenging task in open-world learning. Specifically, given some labeled data of known classes, GCD aims to cluster unlabeled data that contain both known and unknown classes. Current GCD methods based on parametric classification adopt the DINO-like pseudo-labeling strategy, where the sharpened probability output of one view is used as supervision information for the other view. However, large pre-trained models have a preference for some specific visual patterns, resulting in encoding spurious correlation for unlabeled data and generating noisy pseudo-labels. To address this issue, we propose a novel method, which contains two modules: Loss Sharpness Penalty (LSP) and Dynamic Anchor Selection (DAS). LSP enhances the robustness of model parameters to small perturbations by minimizing the worst-case loss sharpness of the model, which suppressing the encoding of trivial features, thereby reducing overfitting of noise samples and improving the quality of pseudo-labels. Meanwhile, DAS selects representative samples for the unknown classes based on KNN density and class probability during the model training and assigns hard pseudo-labels to them, which not only alleviates the confidence difference between known and unknown classes but also enables the model to quickly learn more accurate feature distribution for the unknown classes, thus further improving the clustering accuracy. Extensive experiments demonstrate that the proposed method can effectively mitigate the noise of pseudo-labels, and achieve state-of-the-art results on multiple GCD benchmarks.",
    "published": "2025-12-15T02:24:06Z",
    "authors": [
      "Zhimao Peng",
      "Enguang Wang",
      "Fei Yang",
      "Xialei Liu",
      "Ming-Ming Cheng"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12922",
    "title": "LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization",
    "abstract": "In modern financial markets, investors increasingly seek personalized and adaptive portfolio strategies that reflect their individual risk preferences and respond to dynamic market conditions. Traditional rule-based or static optimization approaches often fail to capture the nonlinear interactions among investor behavior, market volatility, and evolving financial objectives. To address these limitations, this paper introduces the LLM-based Personalized Portfolio Recommender , an integrated framework that combines Large Language Models, reinforcement learning, and individualized risk preference modeling to support intelligent investment decision-making.",
    "published": "2025-12-15T02:12:53Z",
    "authors": [
      "Bangyu Li",
      "Boping Gu",
      "Ziyang Ding"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12921",
    "title": "Cisco Integrated AI Security and Safety Framework Report",
    "abstract": "Artificial intelligence (AI) systems are being readily and rapidly adopted, increasingly permeating critical domains: from consumer platforms and enterprise software to networked systems with embedded agents. While this has unlocked potential for human productivity gains, the attack surface has expanded accordingly: threats now span content safety failures (e.g., harmful or deceptive outputs), model and data integrity compromise (e.g., poisoning, supply-chain tampering), runtime manipulations (e.g., prompt injection, tool and agent misuse), and ecosystem risks (e.g., orchestration abuse, multi-agent collusion). Existing frameworks such as MITRE ATLAS, National Institute of Standards and Technology (NIST) AI 100-2 Adversarial Machine Learning (AML) taxonomy, and OWASP Top 10s for Large Language Models (LLMs) and Agentic AI Applications provide valuable viewpoints, but each covers only slices of this multi-dimensional space.   This paper presents Cisco's Integrated AI Security and Safety Framework (\"AI Security Framework\"), a unified, lifecycle-aware taxonomy and operationalization framework that can be used to classify, integrate, and operationalize the full range of AI risks. It integrates AI security and AI safety across modalities, agents, pipelines, and the broader ecosystem. The AI Security Framework is designed to be practical for threat identification, red-teaming, risk prioritization, and it is comprehensive in scope and can be extensible to emerging deployments in multimodal contexts, humanoids, wearables, and sensory infrastructures. We analyze gaps in prevailing frameworks, discuss design principles for our framework, and demonstrate how the taxonomy provides structure for understanding how modern AI systems fail, how adversaries exploit these failures, and how organizations can build defenses across the AI lifecycle that evolve alongside capability advancements.",
    "published": "2025-12-15T02:12:12Z",
    "authors": [
      "Amy Chang",
      "Tiffany Saade",
      "Sanket Mendapara",
      "Adam Swanda",
      "Ankit Garg"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12918",
    "title": "Satisfiability Modulo Theory Meets Inductive Logic Programming",
    "abstract": "Inductive Logic Programming (ILP) provides interpretable rule learning in relational domains, yet remains limited in its ability to induce and reason with numerical constraints. Classical ILP systems operate over discrete predicates and typically rely on discretisation or hand-crafted numerical predicates, making it difficult to infer thresholds or arithmetic relations that must hold jointly across examples. Recent work has begun to address these limitations through tighter integrations of ILP with Satisfiability Modulo Theories (SMT) or specialised numerical inference mechanisms. In this paper we investigate a modular alternative that couples the ILP system PyGol with the SMT solver Z3. Candidate clauses proposed by PyGol are interpreted as quantifier-free formulas over background theories such as linear or nonlinear real arithmetic, allowing numerical parameters to be instantiated and verified by the SMT solver while preserving ILP's declarative relational bias. This supports the induction of hybrid rules that combine symbolic predicates with learned numerical constraints, including thresholds, intervals, and multi-literal arithmetic relations. We formalise this SMT-ILP setting and evaluate it on a suite of synthetic datasets designed to probe linear, relational, nonlinear, and multi-hop reasoning. The results illustrate how a modular SMT-ILP architecture can extend the expressivity of symbolic rule learning, complementing prior numerical ILP approaches while providing a flexible basis for future extensions toward richer theory-aware induction.",
    "published": "2025-12-15T02:08:32Z",
    "authors": [
      "Nijesh Upreti",
      "Vaishak Belle"
    ],
    "categories": [
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12917",
    "title": "Efficient Quantum-resistant Delegable Data Analysis Scheme with Revocation and Keyword Search in Mobile Cloud Computing",
    "abstract": "With the rapid growth of smart devices and mobile internet, large-scale data processing is becoming increasingly important, while mobile devices remain resource-constrained. Mobile Cloud Computing (MCC) addresses this limitation by offloading tasks to the cloud. Nevertheless, the widespread adoption of MCC also raises challenges such as data privacy, selective computation, efficient revocation, and keyword search. Additionally, the development of quantum computers also threatens data security in MCC. To address these challenges, we propose an efficient quantum-resistant delegable data analysis scheme with revocation and keyword search (EQDDA-RKS) for MCC. In the proposed scheme, an authorised mobile device can perform keyword searches and compute inner product values over encrypted data without disclosing any additional information. Meanwhile, if a user's function key is compromised, it can be revoked. To alleviate the burden on mobile devices, most of the computation which should be executed by the mobile device is outsourced to a cloud server, and the mobile device only needs to interact with a central authority once. Furthermore, an authorised mobile device can temporarily delegate its keyword search and function computation rights to a delegatee in case the device becomes unavailable due to power depletion, going offline, etc. Our scheme is formally proven secure in the standard model against quantum attacks, chosen plaintext attacks, chosen keyword attacks, and outside keyword guessing attacks. Furthermore, the analysis demonstrates that the number of interactions between a mobile device and the central authority is $O(1)$ in our scheme, rather than growing linearly with the number of functions, which is well-suited for MCC scenarios.",
    "published": "2025-12-15T02:07:52Z",
    "authors": [
      "Yue Han",
      "Jinguang Han",
      "Jianying Zhou"
    ],
    "categories": [
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12914",
    "title": "CTIGuardian: A Few-Shot Framework for Mitigating Privacy Leakage in Fine-Tuned LLMs",
    "abstract": "Large Language Models (LLMs) are often fine-tuned to adapt their general-purpose knowledge to specific tasks and domains such as cyber threat intelligence (CTI). Fine-tuning is mostly done through proprietary datasets that may contain sensitive information. Owners expect their fine-tuned model to not inadvertently leak this information to potentially adversarial end users. Using CTI as a use case, we demonstrate that data-extraction attacks can recover sensitive information from fine-tuned models on CTI reports, underscoring the need for mitigation. Retraining the full model to eliminate this leakage is computationally expensive and impractical. We propose an alternative approach, which we call privacy alignment, inspired by safety alignment in LLMs. Just like safety alignment teaches the model to abide by safety constraints through a few examples, we enforce privacy alignment through few-shot supervision, integrating a privacy classifier and a privacy redactor, both handled by the same underlying LLM. We evaluate our system, called CTIGuardian, using GPT-4o mini and Mistral-7B Instruct models, benchmarking against Presidio, a named entity recognition (NER) baseline. Results show that CTIGuardian provides a better privacy-utility trade-off than NER based models. While we demonstrate its effectiveness on a CTI use case, the framework is generic enough to be applicable to other sensitive domains.",
    "published": "2025-12-15T01:59:14Z",
    "authors": [
      "Shashie Dilhara Batan Arachchige",
      "Benjamin Zi Hao Zhao",
      "Hassan Jameel Asghar",
      "Dinusha Vatsalan",
      "Dali Kaafar"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12911",
    "title": "Evaluating Singular Value Thresholds for DNN Weight Matrices based on Random Matrix Theory",
    "abstract": "This study evaluates thresholds for removing singular values from singular value decomposition-based low-rank approximations of deep neural network weight matrices. Each weight matrix is modeled as the sum of signal and noise matrices. The low-rank approximation is obtained by removing noise-related singular values using a threshold based on random matrix theory. To assess the adequacy of this threshold, we propose an evaluation metric based on the cosine similarity between the singular vectors of the signal and original weight matrices. The proposed metric is used in numerical experiments to compare two threshold estimation methods.",
    "published": "2025-12-15T01:49:20Z",
    "authors": [
      "Kohei Nishikawa",
      "Koki Shimizu",
      "Hashiguchi Hiroki"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12907",
    "title": "Machine Learning Architectures for the Estimation of Predicted Occupancy Grids in Road Traffic",
    "abstract": "This paper introduces a novel machine learning architecture for an efficient estimation of the probabilistic space-time representation of complex traffic scenarios. A detailed representation of the future traffic scenario is of significant importance for autonomous driving and for all active safety systems. In order to predict the future space-time representation of the traffic scenario, first the type of traffic scenario is identified and then the machine learning algorithm maps the current state of the scenario to possible future states. The input to the machine learning algorithms is the current state representation of a traffic scenario, termed as the Augmented Occupancy Grid (AOG). The output is the probabilistic space-time representation which includes uncertainties regarding the behaviour of the traffic participants and is termed as the Predicted Occupancy Grid (POG). The novel architecture consists of two Stacked Denoising Autoencoders (SDAs) and a set of Random Forests. It is then compared with the other two existing architectures that comprise of SDAs and DeconvNet. The architectures are validated with the help of simulations and the comparisons are made both in terms of accuracy and computational time. Also, a brief overview on the applications of POGs in the field of active safety is presented.",
    "published": "2025-12-15T01:24:02Z",
    "authors": [
      "Parthasarathy Nadarajan",
      "Michael Botsch",
      "Sebastian Sardina"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12906",
    "title": "Predictive Sample Assignment for Semantically Coherent Out-of-Distribution Detection",
    "abstract": "Semantically coherent out-of-distribution detection (SCOOD) is a recently proposed realistic OOD detection setting: given labeled in-distribution (ID) data and mixed in-distribution and out-of-distribution unlabeled data as the training data, SCOOD aims to enable the trained model to accurately identify OOD samples in the testing data. Current SCOOD methods mainly adopt various clustering-based in-distribution sample filtering (IDF) strategies to select clean ID samples from unlabeled data, and take the remaining samples as auxiliary OOD data, which inevitably introduces a large number of noisy samples in training. To address the above issue, we propose a concise SCOOD framework based on predictive sample assignment (PSA). PSA includes a dual-threshold ternary sample assignment strategy based on the predictive energy score that can significantly improve the purity of the selected ID and OOD sample sets by assigning unconfident unlabeled data to an additional discard sample set, and a concept contrastive representation learning loss to further expand the distance between ID and OOD samples in the representation space to assist ID/OOD discrimination. In addition, we also introduce a retraining strategy to help the model fully fit the selected auxiliary ID/OOD samples. Experiments on two standard SCOOD benchmarks demonstrate that our approach outperforms the state-of-the-art methods by a significant margin.",
    "published": "2025-12-15T01:18:38Z",
    "authors": [
      "Zhimao Peng",
      "Enguang Wang",
      "Xialei Liu",
      "Ming-Ming Cheng"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12905",
    "title": "PAC-Bayes Bounds for Multivariate Linear Regression and Linear Autoencoders",
    "abstract": "Linear Autoencoders (LAEs) have shown strong performance in state-of-the-art recommender systems. However, this success remains largely empirical, with limited theoretical understanding. In this paper, we investigate the generalizability -- a theoretical measure of model performance in statistical learning -- of multivariate linear regression and LAEs. We first propose a PAC-Bayes bound for multivariate linear regression, extending the earlier bound for single-output linear regression by Shalaeva et al., and establish sufficient conditions for its convergence. We then show that LAEs, when evaluated under a relaxed mean squared error, can be interpreted as constrained multivariate linear regression models on bounded data, to which our bound adapts. Furthermore, we develop theoretical methods to improve the computational efficiency of optimizing the LAE bound, enabling its practical evaluation on large models and real-world datasets. Experimental results demonstrate that our bound is tight and correlates well with practical ranking metrics such as Recall@K and NDCG@K.",
    "published": "2025-12-15T01:12:11Z",
    "authors": [
      "Ruixin Guo",
      "Ruoming Jin",
      "Xinyu Li",
      "Yang Zhou"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12904",
    "title": "OptHQC: Optimize HQC for High-Performance Post-Quantum Cryptography",
    "abstract": "As post-quantum cryptography (PQC) becomes increasingly critical for securing future communication systems, the performance overhead introduced by quantum-resistant algorithms presents a major computing challenge. HQC (Hamming Quasi-Cyclic) is a newly standardized code-based PQC scheme designed to replace classical key exchange methods. In this paper, we propose OptHQC, an optimized implementation of the HQC scheme to deliver high-performance cryptographic operations. Our approach provides a comprehensive analysis of each computational blocks in HQC and introduces optimizations across all three stages: key generation, encryption, and decryption. We first exploit data-level sparsity in vector multiplication to accelerate polynomial operations during vector generation. We then leverage instruction-level acceleration (e.g., AVX2) in hash computation to further improve performance. Last, we transform multiplication into lookup table indexing and optimize memory access patterns in syndrome computation and error vector recovery, which are the most computationally intensive operations in HQC. Overall, OptHQC achieves an average 55% speedup over the reference HQC implementation on CPU.",
    "published": "2025-12-15T01:07:57Z",
    "authors": [
      "Ben Dong",
      "Hui Feng",
      "Qian Wang"
    ],
    "categories": [
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12903",
    "title": "Next-generation reservoir computing validated by classification task",
    "abstract": "An emerging computing paradigm, so-called next-generation reservoir computing (NG-RC) is investigated. True to its namesake, NG-RC requires no actual reservoirs for input data mixing but rather computing the polynomial terms directly from the time series inputs. However, benchmark tests so far reported have been one-sided, limited to prediction tasks of temporal waveforms such as Lorenz 63 attractor and Mackey-Glass chaotic signal. We will demonstrate for the first time that NG-RC can perform classification task as good as conventional RC. This validates the versatile computational capability of NG-RC in tasks of both prediction and classification.",
    "published": "2025-12-15T01:06:23Z",
    "authors": [
      "Ken-ichi Kitayama"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12901",
    "title": "Predicted-occupancy grids for vehicle safety applications based on autoencoders and the Random Forest algorithm",
    "abstract": "In this paper, a probabilistic space-time representation of complex traffic scenarios is predicted using machine learning algorithms. Such a representation is significant for all active vehicle safety applications especially when performing dynamic maneuvers in a complex traffic scenario. As a first step, a hierarchical situation classifier is used to distinguish the different types of traffic scenarios. This classifier is responsible for identifying the type of the road infrastructure and the safety-relevant traffic participants of the driving environment. With each class representing similar traffic scenarios, a set of Random Forests (RFs) is individually trained to predict the probabilistic space-time representation, which depicts the future behavior of traffic participants. This representation is termed as a Predicted-Occupancy Grid (POG). The input to the RFs is an Augmented Occupancy Grid (AOG). In order to increase the learning accuracy of the RFs and to perform better predictions, the AOG is reduced to low-dimensional features using a Stacked Denoising Autoencoder (SDA). The excellent performance of the proposed machine learning approach consisting of SDAs and RFs is demonstrated in simulations and in experiments with real vehicles. An application of POGs to estimate the criticality of traffic scenarios and to determine safe trajectories is also presented.",
    "published": "2025-12-15T00:59:44Z",
    "authors": [
      "Parthasarathy Nadarajan",
      "Michael Botsch",
      "Sebastian Sardina"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12898",
    "title": "Qonvolution: Towards Learning High-Frequency Signals with Queried Convolution",
    "abstract": "Accurately learning high-frequency signals is a challenge in computer vision and graphics, as neural networks often struggle with these signals due to spectral bias or optimization difficulties. While current techniques like Fourier encodings have made great strides in improving performance, there remains scope for improvement when presented with high-frequency information. This paper introduces Queried-Convolutions (Qonvolutions), a simple yet powerful modification using the neighborhood properties of convolution. Qonvolution convolves a low-frequency signal with queries (such as coordinates) to enhance the learning of intricate high-frequency signals. We empirically demonstrate that Qonvolutions enhance performance across a variety of high-frequency learning tasks crucial to both the computer vision and graphics communities, including 1D regression, 2D super-resolution, 2D image regression, and novel view synthesis (NVS). In particular, by combining Gaussian splatting with Qonvolutions for NVS, we showcase state-of-the-art performance on real-world complex scenes, even outperforming powerful radiance field models on image quality.",
    "published": "2025-12-15T00:46:09Z",
    "authors": [
      "Abhinav Kumar",
      "Tristan Aumentado-Armstrong",
      "Lazar Valkov",
      "Gopal Sharma",
      "Alex Levinshtein",
      "Radek Grzeszczuk",
      "Suren Kumar"
    ],
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12896",
    "title": "Probability Estimation for Predicted-Occupancy Grids in Vehicle Safety Applications Based on Machine Learning",
    "abstract": "This paper presents a method to predict the evolution of a complex traffic scenario with multiple objects. The current state of the scenario is assumed to be known from sensors and the prediction is taking into account various hypotheses about the behavior of traffic participants. This way, the uncertainties regarding the behavior of traffic participants can be modelled in detail. In the first part of this paper a model-based approach is presented to compute Predicted-Occupancy Grids (POG), which are introduced as a grid-based probabilistic representation of the future scenario hypotheses. However, due to the large number of possible trajectories for each traffic participant, the model-based approach comes with a very high computational load. Thus, a machine-learning approach is adopted for the computation of POGs. This work uses a novel grid-based representation of the current state of the traffic scenario and performs the mapping to POGs. This representation consists of augmented cells in an occupancy grid. The adopted machine-learning approach is based on the Random Forest algorithm. Simulations of traffic scenarios are performed to compare the machine-learning with the model-based approach. The results are promising and could enable the real-time computation of POGs for vehicle safety applications. With this detailed modelling of uncertainties, crucial components in vehicle safety systems like criticality estimation and trajectory planning can be improved.",
    "published": "2025-12-15T00:45:26Z",
    "authors": [
      "Parthasarathy Nadarajan",
      "Michael Botsch"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12895",
    "title": "Wait, Wait, Wait... Why Do Reasoning Models Loop?",
    "abstract": "Reasoning models (e.g., DeepSeek-R1) generate long chains of thought to solve harder problems, but they often loop, repeating the same text at low temperatures or with greedy decoding. We study why this happens and what role temperature plays. With open reasoning models, we find that looping is common at low temperature. Larger models tend to loop less, and distilled students loop significantly even when their teachers rarely do. This points to mismatches between the training distribution and the learned model, which we refer to as errors in learning, as a key cause. To understand how such errors cause loops, we introduce a synthetic graph reasoning task and demonstrate two mechanisms. First, risk aversion caused by hardness of learning: when the correct progress-making action is hard to learn but an easy cyclic action is available, the model puts relatively more probability on the cyclic action and gets stuck. Second, even when there is no hardness, Transformers show an inductive bias toward temporally correlated errors, so the same few actions keep being chosen and loops appear. Higher temperature reduces looping by promoting exploration, but it does not fix the errors in learning, so generations remain much longer than necessary at high temperature; in this sense, temperature is a stopgap rather than a holistic solution. We end with a discussion of training-time interventions aimed at directly reducing errors in learning.",
    "published": "2025-12-15T00:44:54Z",
    "authors": [
      "Charilaos Pipis",
      "Shivam Garg",
      "Vasilis Kontonis",
      "Vaishnavi Shrivastava",
      "Akshay Krishnamurthy",
      "Dimitris Papailiopoulos"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12889",
    "title": "Distillation of Discrete Diffusion by Exact Conditional Distribution Matching",
    "abstract": "Discrete diffusion models (DDMs) are a powerful class of generative models for categorical data, but they typically require many function evaluations for a single sample, making inference expensive. Existing acceleration methods either rely on approximate simulators, such as $τ$-leaping, or on distillation schemes that train new student models and auxiliary networks with proxy objectives. We propose a simple and principled distillation alternative based on \\emph{conditional distribution matching}. Our key observation is that the reverse conditional distribution of clean data given a noisy state, $p_{0\\mid t}(x_0 \\mid x_t)$, admits a Markov decomposition through intermediate times and can be recovered from marginal density ratios and the known forward CTMC kernel. We exploit this structure to define distillation objectives that directly match conditional distributions between a pre-trained teacher and a low-NFE student, both for one-step and few-step samplers.",
    "published": "2025-12-15T00:16:10Z",
    "authors": [
      "Yansong Gao",
      "Yu Sun"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12888",
    "title": "Meta-GPT: Decoding the Metasurface Genome with Generative Artificial Intelligence",
    "abstract": "Advancing artificial intelligence for physical sciences requires representations that are both interpretable and compatible with the underlying laws of nature. We introduce METASTRINGS, a symbolic language for photonics that expresses nanostructures as textual sequences encoding materials, geometries, and lattice configurations. Analogous to molecular textual representations in chemistry, METASTRINGS provides a framework connecting human interpretability with computational design by capturing the structural hierarchy of photonic metasurfaces. Building on this representation, we develop Meta-GPT, a foundation transformer model trained on METASTRINGS and finetuned with physics-informed supervised, reinforcement, and chain-of-thought learning. Across various design tasks, the model achieves <3% mean-squared spectral error and maintains >98% syntactic validity, generating diverse metasurface prototypes whose experimentally measured optical responses match their target spectra. These results demonstrate that Meta-GPT can learn the compositional rules of light-matter interactions through METASTRINGS, laying a rigorous foundation for AI-driven photonics and representing an important step toward a metasurface genome project.",
    "published": "2025-12-15T00:09:14Z",
    "authors": [
      "David Dang",
      "Stuart Love",
      "Meena Salib",
      "Quynh Dang",
      "Samuel Rothfarb",
      "Mysk Alnatour",
      "Andrew Salij",
      "Hou-Tong Chen",
      "Ho Wai",
      "Lee",
      "Wilton J. M. Kort-Kamp"
    ],
    "categories": [
      "physics.optics",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12887",
    "title": "Revisiting 2D Foundation Models for Scalable 3D Medical Image Classification",
    "abstract": "3D medical image classification is essential for modern clinical workflows. Medical foundation models (FMs) have emerged as a promising approach for scaling to new tasks, yet current research suffers from three critical pitfalls: data-regime bias, suboptimal adaptation, and insufficient task coverage. In this paper, we address these pitfalls and introduce AnyMC3D, a scalable 3D classifier adapted from 2D FMs. Our method scales efficiently to new tasks by adding only lightweight plugins (about 1M parameters per task) on top of a single frozen backbone. This versatile framework also supports multi-view inputs, auxiliary pixel-level supervision, and interpretable heatmap generation. We establish a comprehensive benchmark of 12 tasks covering diverse pathologies, anatomies, and modalities, and systematically analyze state-of-the-art 3D classification techniques. Our analysis reveals key insights: (1) effective adaptation is essential to unlock FM potential, (2) general-purpose FMs can match medical-specific FMs if properly adapted, and (3) 2D-based methods surpass 3D architectures for 3D classification. For the first time, we demonstrate the feasibility of achieving state-of-the-art performance across diverse applications using a single scalable framework (including 1st place in the VLM3D challenge), eliminating the need for separate task-specific models.",
    "published": "2025-12-15T00:01:19Z",
    "authors": [
      "Han Liu",
      "Bogdan Georgescu",
      "Yanbo Zhang",
      "Youngjin Yoo",
      "Michael Baumgartner",
      "Riqiang Gao",
      "Jianing Wang",
      "Gengyan Zhao",
      "Eli Gibson",
      "Dorin Comaniciu",
      "Sasa Grbic"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12885",
    "title": "SignRAG: A Retrieval-Augmented System for Scalable Zero-Shot Road Sign Recognition",
    "abstract": "Automated road sign recognition is a critical task for intelligent transportation systems, but traditional deep learning methods struggle with the sheer number of sign classes and the impracticality of creating exhaustive labeled datasets. This paper introduces a novel zero-shot recognition framework that adapts the Retrieval-Augmented Generation (RAG) paradigm to address this challenge. Our method first uses a Vision Language Model (VLM) to generate a textual description of a sign from an input image. This description is used to retrieve a small set of the most relevant sign candidates from a vector database of reference designs. Subsequently, a Large Language Model (LLM) reasons over the retrieved candidates to make a final, fine-grained recognition. We validate this approach on a comprehensive set of 303 regulatory signs from the Ohio MUTCD. Experimental results demonstrate the framework's effectiveness, achieving 95.58% accuracy on ideal reference images and 82.45% on challenging real-world road data. This work demonstrates the viability of RAG-based architectures for creating scalable and accurate systems for road sign recognition without task-specific training.",
    "published": "2025-12-14T23:56:34Z",
    "authors": [
      "Minghao Zhu",
      "Zhihao Zhang",
      "Anmol Sidhu",
      "Keith Redmill"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.RO"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12884",
    "title": "Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection",
    "abstract": "In automotive sensor fusion systems, smart sensors and Vehicle-to-Everything (V2X) modules are commonly utilized. Sensor data from these systems are typically available only as processed object lists rather than raw sensor data from traditional sensors. Instead of processing other raw data separately and then fusing them at the object level, we propose an end-to-end cross-level fusion concept with Transformer, which integrates highly abstract object list information with raw camera images for 3D object detection. Object lists are fed into a Transformer as denoising queries and propagated together with learnable queries through the latter feature aggregation process. Additionally, a deformable Gaussian mask, derived from the positional and size dimensional priors from the object lists, is explicitly integrated into the Transformer decoder. This directs attention toward the target area of interest and accelerates model training convergence. Furthermore, as there is no public dataset containing object lists as a standalone modality, we propose an approach to generate pseudo object lists from ground-truth bounding boxes by simulating state noise and false positives and negatives. As the first work to conduct cross-level fusion, our approach shows substantial performance improvements over the vision-based baseline on the nuScenes dataset. It demonstrates its generalization capability over diverse noise levels of simulated object lists and real detectors.",
    "published": "2025-12-14T23:56:16Z",
    "authors": [
      "Xiangzhong Liu",
      "Jiajie Zhang",
      "Hao Shen"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12881",
    "title": "Unsupervised learning of multiscale switching dynamical system models from multimodal neural data",
    "abstract": "Neural population activity often exhibits regime-dependent non-stationarity in the form of switching dynamics. Learning accurate switching dynamical system models can reveal how behavior is encoded in neural activity. Existing switching approaches have primarily focused on learning models from a single neural modality, either continuous Gaussian signals or discrete Poisson signals. However, multiple neural modalities are often recorded simultaneously to measure different spatiotemporal scales of brain activity, and all these modalities can encode behavior. Moreover, regime labels are typically unavailable in training data, posing a significant challenge for learning models of regime-dependent switching dynamics. To address these challenges, we develop a novel unsupervised learning algorithm that learns the parameters of switching multiscale dynamical system models using only multiscale neural observations. We demonstrate our method using both simulations and two distinct experimental datasets with multimodal spike-LFP observations during different motor tasks. We find that our switching multiscale dynamical system models more accurately decode behavior than switching single-scale dynamical models, showing the success of multiscale neural fusion. Further, our models outperform stationary multiscale models, illustrating the importance of tracking regime-dependent non-stationarity in multimodal neural data. The developed unsupervised learning framework enables more accurate modeling of complex multiscale neural dynamics by leveraging information in multimodal recordings while incorporating regime switches. This approach holds promise for improving the performance and robustness of brain-computer interfaces over time and for advancing our understanding of the neural basis of behavior.",
    "published": "2025-12-14T23:49:12Z",
    "authors": [
      "DongKyu Kim",
      "Han-Lin Hsieh",
      "Maryam M. Shanechi"
    ],
    "categories": [
      "cs.LG",
      "q-bio.NC",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12880",
    "title": "Improving Recursive Transformers with Mixture of LoRAs",
    "abstract": "Parameter sharing in recursive transformers reduces model size but collapses layer-wise expressivity. We propose Mixture of LoRAs (MoL), a lightweight conditional-computation mechanism that inserts Low-Rank Adaptation (LoRA) experts inside a shared feed-forward network (FFN). MoL enables token-conditional weight-space modulation of the shared FFN without untying backbone parameters, unlike prior approaches that add fixed or externally attached adapters. We pretrain a modernised recursive architecture, ModernALBERT, integrating rotary embeddings, GeGLU, FlashAttention, and a distillation-based initialisation. Across GLUE, SQuAD-v2, and BEIR, ModernALBERT (50M--120M) achieves state-of-the-art performance among compact models and surpasses larger fully parameterised baselines. We also propose an expert-merging procedure that compresses MoL into a single adapter at inference while preserving accuracy, enabling efficient deployment. Our results show that conditional weight-space modulation effectively restores the expressivity lost under aggressive parameter sharing in recursive transformers.",
    "published": "2025-12-14T23:39:30Z",
    "authors": [
      "Mohammadmahdi Nouriborji",
      "Morteza Rohanian",
      "Omid Rohanian"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12875",
    "title": "Schrodinger Audio-Visual Editor: Object-Level Audiovisual Removal",
    "abstract": "Joint editing of audio and visual content is crucial for precise and controllable content creation. This new task poses challenges due to the limitations of paired audio-visual data before and after targeted edits, and the heterogeneity across modalities. To address the data and modeling challenges in joint audio-visual editing, we introduce SAVEBench, a paired audiovisual dataset with text and mask conditions to enable object-grounded source-to-target learning. With SAVEBench, we train the Schrodinger Audio-Visual Editor (SAVE), an end-to-end flow-matching model that edits audio and video in parallel while keeping them aligned throughout processing. SAVE incorporates a Schrodinger Bridge that learns a direct transport from source to target audiovisual mixtures. Our evaluation demonstrates that the proposed SAVE model is able to remove the target objects in audio and visual content while preserving the remaining content, with stronger temporal synchronization and audiovisual semantic correspondence compared with pairwise combinations of an audio editor and a video editor.",
    "published": "2025-12-14T23:19:15Z",
    "authors": [
      "Weihan Xu",
      "Kan Jen Cheng",
      "Koichi Saito",
      "Muhammad Jehanzeb Mirza",
      "Tingle Li",
      "Yisi Liu",
      "Alexander H. Liu",
      "Liming Wang",
      "Masato Ishii",
      "Takashi Shibuya",
      "Yuki Mitsufuji",
      "Gopala Anumanchipalli",
      "Paul Pu Liang"
    ],
    "categories": [
      "cs.CV",
      "cs.MM",
      "cs.SD"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12870",
    "title": "Optimal Labeler Assignment and Sampling for Active Learning in the Presence of Imperfect Labels",
    "abstract": "Active Learning (AL) has garnered significant interest across various application domains where labeling training data is costly. AL provides a framework that helps practitioners query informative samples for annotation by oracles (labelers). However, these labels often contain noise due to varying levels of labeler accuracy. Additionally, uncertain samples are more prone to receiving incorrect labels because of their complexity. Learning from imperfectly labeled data leads to an inaccurate classifier. We propose a novel AL framework to construct a robust classification model by minimizing noise levels. Our approach includes an assignment model that optimally assigns query points to labelers, aiming to minimize the maximum possible noise within each cycle. Additionally, we introduce a new sampling method to identify the best query points, reducing the impact of label noise on classifier performance. Our experiments demonstrate that our approach significantly improves classification performance compared to several benchmark methods.",
    "published": "2025-12-14T23:06:37Z",
    "authors": [
      "Pouya Ahadi",
      "Blair Winograd",
      "Camille Zaug",
      "Karunesh Arora",
      "Lijun Wang",
      "Kamran Paynabar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12869",
    "title": "ERA-IT: Aligning Semantic Models with Revealed Economic Preference for Real-Time and Explainable Patent Valuation",
    "abstract": "Valuing intangible assets under uncertainty remains a critical challenge in the strategic management of technological innovation due to the information asymmetry inherent in high-dimensional technical specifications. Traditional bibliometric indicators, such as citation counts, fail to address this friction in a timely manner due to the systemic latency inherent in data accumulation. To bridge this gap, this study proposes the Economic Reasoning Alignment via Instruction Tuning (ERA-IT) framework. We theoretically conceptualize patent renewal history as a revealed economic preference and leverage it as an objective supervisory signal to align the generative reasoning of Large Language Models (LLMs) with market realities, a process we term Eco-Semantic Alignment. Using a randomly sampled dataset of 10,000 European Patent Office patents across diverse technological domains, we trained the model not only to predict value tiers but also to reverse-engineer the Economic Chain-of-Thought from unstructured text. Empirical results demonstrate that ERA-IT significantly outperforms both conventional econometric models and zero-shot LLMs in predictive accuracy. More importantly, by generating explicit, logically grounded rationales for valuation, the framework serves as a transparent cognitive scaffold for decision-makers, reducing the opacity of black-box AI in high-stakes intellectual property management.",
    "published": "2025-12-14T23:04:07Z",
    "authors": [
      "Yoo Yongmin",
      "Kim Seungwoo",
      "Liu Jingjiang"
    ],
    "categories": [
      "cs.CE",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12868",
    "title": "Counting Clues: A Lightweight Probabilistic Baseline Can Match an LLM",
    "abstract": "Large language models (LLMs) excel on multiple-choice clinical diagnosis benchmarks, yet it is unclear how much of this performance reflects underlying probabilistic reasoning. We study this through questions from MedQA, where the task is to select the most likely diagnosis. We introduce the Frequency-Based Probabilistic Ranker (FBPR), a lightweight method that scores options with a smoothed Naive Bayes over concept-diagnosis co-occurrence statistics from a large corpus. When co-occurrence statistics were sourced from the pretraining corpora for OLMo and Llama, FBPR achieves comparable performance to the corresponding LLMs pretrained on that same corpus. Direct LLM inference and FBPR largely get different questions correct, with an overlap only slightly above random chance, indicating complementary strengths of each method. These findings highlight the continued value of explicit probabilistic baselines: they provide a meaningful performance reference point and a complementary signal for potential hybridization. While the performance of LLMs seems to be driven by a mechanism other than simple frequency aggregation, we show that an approach similar to the historically grounded, low-complexity expert systems still accounts for a substantial portion of benchmark performance.",
    "published": "2025-12-14T23:00:10Z",
    "authors": [
      "Furong Jia",
      "Yuan Pu",
      "Finn Guo",
      "Monica Agrawal"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12858",
    "title": "Information-Consistent Language Model Recommendations through Group Relative Policy Optimization",
    "abstract": "Large Language Models (LLMs) are increasingly deployed in business-critical domains such as finance, education, healthcare, and customer support, where users expect consistent and reliable recommendations. Yet LLMs often exhibit variability when prompts are phrased with minor differences, even when semantically equivalent. Such inconsistency undermines trust, complicates compliance, and disrupts user experience. While personalization is desirable in certain contexts, many enterprise scenarios-such as HR onboarding, customer support, or policy disclosure-require invariant information delivery regardless of phrasing or prior conversational history. Existing approaches, including retrieval-augmented generation (RAG) and temperature tuning, improve factuality or reduce stochasticity but cannot guarantee stability across equivalent prompts. In this paper, we propose a reinforcement learning framework based on Group Relative Policy Optimization (GRPO) to directly optimize for consistency. Unlike prior applications of GRPO, which have been limited to reasoning and code generation, we adapt GRPO to enforce stability of information content across groups of semantically equivalent prompts. We introduce entropy-based helpfulness and stability rewards, treating prompt variants as groups and resetting conversational context to isolate phrasing effects. Experiments on investment and job recommendation tasks show that our GRPO-trained model reduces variability more effectively than fine-tuning or decoding-based baselines. To our knowledge, this is a novel application of GRPO for aligning LLMs toward information consistency, reframing variability not as an acceptable feature of generative diversity but as a correctable flaw in enterprise deployments.",
    "published": "2025-12-14T21:52:31Z",
    "authors": [
      "Sonal Prabhune",
      "Balaji Padmanabhan",
      "Kaushik Dutta"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12856",
    "title": "Forgetful but Faithful: A Cognitive Memory Architecture and Benchmark for Privacy-Aware Generative Agents",
    "abstract": "As generative agents become increasingly sophisticated and deployed in long-term interactive scenarios, their memory management capabilities emerge as a critical bottleneck for both performance and privacy. Current approaches either maintain unlimited memory stores, leading to computational intractability and privacy concerns, or employ simplistic forgetting mechanisms that compromise agent coherence and functionality. This paper introduces the Memory-Aware Retention Schema (MaRS), a novel framework for human-centered memory management in generative agents, coupled with six theoretically-grounded forgetting policies that balance performance, privacy, and computational efficiency. We present the Forgetful but Faithful Agent (FiFA) benchmark, a comprehensive evaluation framework that assesses agent performance across narrative coherence, goal completion, social recall accuracy, privacy preservation, and cost efficiency. Through extensive experimentation involving 300 evaluation runs across multiple memory budgets and agent configurations, we demonstrate that our hybrid forgetting policy achieves superior performance (composite score: 0.911) while maintaining computational tractability and privacy guarantees. Our work establishes new benchmarks for memory-budgeted agent evaluation and provides practical guidelines for deploying generative agents in resource-constrained, privacy-sensitive environments. The theoretical foundations, implementation framework, and empirical results contribute to the emerging field of human-centered AI by addressing fundamental challenges in agent memory management that directly impact user trust, system scalability, and regulatory compliance.",
    "published": "2025-12-14T21:40:07Z",
    "authors": [
      "Saad Alqithami"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12850",
    "title": "KANELÉ: Kolmogorov-Arnold Networks for Efficient LUT-based Evaluation",
    "abstract": "Low-latency, resource-efficient neural network inference on FPGAs is essential for applications demanding real-time capability and low power. Lookup table (LUT)-based neural networks are a common solution, combining strong representational power with efficient FPGA implementation. In this work, we introduce KANELÉ, a framework that exploits the unique properties of Kolmogorov-Arnold Networks (KANs) for FPGA deployment. Unlike traditional multilayer perceptrons (MLPs), KANs employ learnable one-dimensional splines with fixed domains as edge activations, a structure naturally suited to discretization and efficient LUT mapping. We present the first systematic design flow for implementing KANs on FPGAs, co-optimizing training with quantization and pruning to enable compact, high-throughput, and low-latency KAN architectures. Our results demonstrate up to a 2700x speedup and orders of magnitude resource savings compared to prior KAN-on-FPGA approaches. Moreover, KANELÉ matches or surpasses other LUT-based architectures on widely used benchmarks, particularly for tasks involving symbolic or physical formulas, while balancing resource usage across FPGA hardware. Finally, we showcase the versatility of the framework by extending it to real-time, power-efficient control systems.",
    "published": "2025-12-14T21:29:10Z",
    "authors": [
      "Duc Hoang",
      "Aarush Gupta",
      "Philip Harris"
    ],
    "categories": [
      "cs.AR",
      "cs.LG",
      "eess.SY",
      "hep-ex"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12847",
    "title": "HaShiFlex: A High-Throughput Hardened Shifter DNN Accelerator with Fine-Tuning Flexibility",
    "abstract": "We introduce a high-throughput neural network accelerator that embeds most network layers directly in hardware, minimizing data transfer and memory usage while preserving a degree of flexibility via a small neural processing unit for the final classification layer. By leveraging power-of-two (Po2) quantization for weights, we replace multiplications with simple rewiring, effectively reducing each convolution to a series of additions. This streamlined approach offers high-throughput, energy-efficient processing, making it highly suitable for applications where model parameters remain stable, such as continuous sensing tasks at the edge or large-scale data center deployments. Furthermore, by including a strategically chosen reprogrammable final layer, our design achieves high throughput without sacrificing fine-tuning capabilities. We implement this accelerator in a 7nm ASIC flow using MobileNetV2 as a baseline and report throughput, area, accuracy, and sensitivity to quantization and pruning - demonstrating both the advantages and potential trade-offs of the proposed architecture. We find that for MobileNetV2, we can improve inference throughput by 20x over fully programmable GPUs, processing 1.21 million images per second through a full forward pass while retaining fine-tuning flexibility. If absolutely no post-deployment fine tuning is required, this advantage increases to 67x at 4 million images per second.",
    "published": "2025-12-14T21:22:33Z",
    "authors": [
      "Jonathan Herbst",
      "Michael Pellauer",
      "Sherief Reda"
    ],
    "categories": [
      "cs.AR",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12844",
    "title": "Selective Conformal Risk Control",
    "abstract": "Reliable uncertainty quantification is essential for deploying machine learning systems in high-stakes domains. Conformal prediction provides distribution-free coverage guarantees but often produces overly large prediction sets, limiting its practical utility. To address this issue, we propose \\textit{Selective Conformal Risk Control} (SCRC), a unified framework that integrates conformal prediction with selective classification. The framework formulates uncertainty control as a two-stage problem: the first stage selects confident samples for prediction, and the second stage applies conformal risk control on the selected subset to construct calibrated prediction sets. We develop two algorithms under this framework. The first, SCRC-T, preserves exchangeability by computing thresholds jointly over calibration and test samples, offering exact finite-sample guarantees. The second, SCRC-I, is a calibration-only variant that provides PAC-style probabilistic guarantees while being more computational efficient. Experiments on two public datasets show that both methods achieve the target coverage and risk levels, with nearly identical performance, while SCRC-I exhibits slightly more conservative risk control but superior computational practicality. Our results demonstrate that selective conformal risk control offers an effective and efficient path toward compact, reliable uncertainty quantification.",
    "published": "2025-12-14T21:18:28Z",
    "authors": [
      "Yunpeng Xu",
      "Wenge Guo",
      "Zhi Wei"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12842",
    "title": "SAGA: Open-World Mobile Manipulation via Structured Affordance Grounding",
    "abstract": "We present SAGA, a versatile and adaptive framework for visuomotor control that can generalize across various environments, task objectives, and user specifications. To efficiently learn such capability, our key idea is to disentangle high-level semantic intent from low-level visuomotor control by explicitly grounding task objectives in the observed environment. Using an affordance-based task representation, we express diverse and complex behaviors in a unified, structured form. By leveraging multimodal foundation models, SAGA grounds the proposed task representation to the robot's visual observation as 3D affordance heatmaps, highlighting task-relevant entities while abstracting away spurious appearance variations that would hinder generalization. These grounded affordances enable us to effectively train a conditional policy on multi-task demonstration data for whole-body control. In a unified framework, SAGA can solve tasks specified in different forms, including language instructions, selected points, and example demonstrations, enabling both zero-shot execution and few-shot adaptation. We instantiate SAGA on a quadrupedal manipulator and conduct extensive experiments across eleven real-world tasks. SAGA consistently outperforms end-to-end and modular baselines by substantial margins. Together, these results demonstrate that structured affordance grounding offers a scalable and effective pathway toward generalist mobile manipulation.",
    "published": "2025-12-14T21:13:56Z",
    "authors": [
      "Kuan Fang",
      "Yuxin Chen",
      "Xinghao Zhu",
      "Farzad Niroui",
      "Lingfeng Sun",
      "Jiuguang Wang"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12840",
    "title": "PRIVEE: Privacy-Preserving Vertical Federated Learning Against Feature Inference Attacks",
    "abstract": "Vertical Federated Learning (VFL) enables collaborative model training across organizations that share common user samples but hold disjoint feature spaces. Despite its potential, VFL is susceptible to feature inference attacks, in which adversarial parties exploit shared confidence scores (i.e., prediction probabilities) during inference to reconstruct private input features of other participants. To counter this threat, we propose PRIVEE (PRIvacy-preserving Vertical fEderated lEarning), a novel defense mechanism named after the French word privée, meaning \"private.\" PRIVEE obfuscates confidence scores while preserving critical properties such as relative ranking and inter-score distances. Rather than exposing raw scores, PRIVEE shares only the transformed representations, mitigating the risk of reconstruction attacks without degrading model prediction accuracy. Extensive experiments show that PRIVEE achieves a threefold improvement in privacy protection compared to state-of-the-art defenses, while preserving full predictive performance against advanced feature inference attacks.",
    "published": "2025-12-14T21:05:19Z",
    "authors": [
      "Sindhuja Madabushi",
      "Ahmad Faraz Khan",
      "Haider Ali",
      "Ananthram Swami",
      "Rui Ning",
      "Hongyi Wu",
      "Jin-Hee Cho"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12839",
    "title": "What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation",
    "abstract": "In this work, we conduct systematic research in a challenging area: the automatic evaluation of book-length stories (>100K tokens). Our study focuses on two key questions: (1) understanding which evaluation aspects matter most to readers, and (2) exploring effective methods for evaluating lengthy stories. We introduce the first large-scale benchmark, LongStoryEval, comprising 600 newly published books with an average length of 121K tokens (maximum 397K). Each book includes its average rating and multiple reader reviews, presented as critiques organized by evaluation aspects. By analyzing all user-mentioned aspects, we propose an evaluation criteria structure and conduct experiments to identify the most significant aspects among the 8 top-level criteria. For evaluation methods, we compare the effectiveness of three types: aggregation-based, incremental-updated, and summary-based evaluations. Our findings reveal that aggregation- and summary-based evaluations perform better, with the former excelling in detail assessment and the latter offering greater efficiency. Building on these insights, we further propose NovelCritique, an 8B model that leverages the efficient summary-based framework to review and score stories across specified aspects. NovelCritique outperforms commercial models like GPT-4o in aligning with human evaluations. Our datasets and codes are available at https://github.com/DingyiYang/LongStoryEval.",
    "published": "2025-12-14T20:53:29Z",
    "authors": [
      "Dingyi Yang",
      "Qin Jin"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12837",
    "title": "Algorithmic Criminal Liability in Greenwashing: Comparing India, United States, and European Union",
    "abstract": "AI-powered greenwashing has emerged as an insidious challenge within corporate sustainability governance, exacerbating the opacity of environmental disclosures and subverting regulatory oversight. This study conducts a comparative legal analysis of criminal liability for AI-mediated greenwashing across India, the US, and the EU, exposing doctrinal lacunae in attributing culpability when deceptive claims originate from algorithmic systems. Existing statutes exhibit anthropocentric biases by predicating liability on demonstrable human intent, rendering them ill-equipped to address algorithmic deception. The research identifies a critical gap in jurisprudential adaptation, as prevailing fraud statutes remain antiquated vis-à-vis AI-generated misrepresentation. Utilising a doctrinal legal methodology, this study systematically dissects judicial precedents and statutory instruments, yielding results regarding the potential expansion of corporate criminal liability. Findings underscore the viability of strict liability models, recalibrated governance frameworks for AI accountability, and algorithmic due diligence mandates under ESG regimes. Comparative insights reveal jurisdictional disparities, with the EU Corporate Sustainability Due Diligence Directive (CSDDD) offering a potential transnational model. This study contributes to AI ethics and environmental jurisprudence by advocating for a hybrid liability framework integrating algorithmic risk assessment with legal personhood constructs, ensuring algorithmic opacity does not preclude liability enforcement.",
    "published": "2025-12-14T20:49:41Z",
    "authors": [
      "Sahibpreet Singh",
      "Manjit Singh"
    ],
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12832",
    "title": "Network Level Evaluation of Hangup Susceptibility of HRGCs using Deep Learning and Sensing Techniques: A Goal Towards Safer Future",
    "abstract": "Steep profiled Highway Railway Grade Crossings (HRGCs) pose safety hazards to vehicles with low ground clearance, which may become stranded on the tracks, creating risks of train vehicle collisions. This research develops a framework for network level evaluation of hangup susceptibility of HRGCs. Profile data from different crossings in Oklahoma were collected using both a walking profiler and the Pave3D8K Laser Imaging System. A hybrid deep learning model, combining Long Short Term Memory (LSTM) and Transformer architectures, was developed to reconstruct accurate HRGC profiles from Pave3D8K Laser Imaging System data. Vehicle dimension data from around 350 specialty vehicles were collected at various locations across Oklahoma to enable up to date statistical design dimensions. Hangup susceptibility was analyzed using three vehicle dimension scenarios (a) median dimension (median wheelbase and ground clearance), (b) 75 25 percentile dimension (75 percentile wheelbase, 25 percentile ground clearance), and (c) worst case dimension (maximum wheelbase and minimum ground clearance). Results indicate 36, 62, and 67 crossings at the highest hangup risk levels under these scenarios, respectively. An ArcGIS database and a software interface were developed to support transportation agencies in mitigating crossing hazards. This framework advances safety evaluation by integrating next generation sensing, deep learning, and infrastructure datasets into practical decision support tools.",
    "published": "2025-12-14T20:25:42Z",
    "authors": [
      "Kaustav Chatterjee",
      "Joshua Li",
      "Kundan Parajulee",
      "Jared Schwennesen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12829",
    "title": "Towards a Systematic Taxonomy of Attacks against Space Infrastructures",
    "abstract": "Space infrastructures represent an emerging domain that is critical to the global economy and society. However, this domain is vulnerable to attacks. To enhance the resilience of this domain, we must understand the attacks that can be waged against it. The status quo is that there is no systematic understanding of attacks against space infrastructures, despite their importance in guiding systematic analysis of space cybersecurity and future research. In this paper, we fill the void by proposing the first systematic taxonomy of attacks against space infrastructures. We hope this paper will inspire a community effort at refining the taxonomy towards a widely used taxonomy.",
    "published": "2025-12-14T20:20:36Z",
    "authors": [
      "Jose Luis Castanon Remy",
      "Shouhuai Xu"
    ],
    "categories": [
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12827",
    "title": "GradID: Adversarial Detection via Intrinsic Dimensionality of Gradients",
    "abstract": "Despite their remarkable performance, deep neural networks exhibit a critical vulnerability: small, often imperceptible, adversarial perturbations can lead to drastically altered model predictions. Given the stringent reliability demands of applications such as medical diagnosis and autonomous driving, robust detection of such adversarial attacks is paramount. In this paper, we investigate the geometric properties of a model's input loss landscape. We analyze the Intrinsic Dimensionality (ID) of the model's gradient parameters, which quantifies the minimal number of coordinates required to describe the data points on their underlying manifold. We reveal a distinct and consistent difference in the ID for natural and adversarial data, which forms the basis of our proposed detection method. We validate our approach across two distinct operational scenarios. First, in a batch-wise context for identifying malicious data groups, our method demonstrates high efficacy on datasets like MNIST and SVHN. Second, in the critical individual-sample setting, we establish new state-of-the-art results on challenging benchmarks such as CIFAR-10 and MS COCO. Our detector significantly surpasses existing methods against a wide array of attacks, including CW and AutoAttack, achieving detection rates consistently above 92\\% on CIFAR-10. The results underscore the robustness of our geometric approach, highlighting that intrinsic dimensionality is a powerful fingerprint for adversarial detection across diverse datasets and attack strategies.",
    "published": "2025-12-14T20:16:03Z",
    "authors": [
      "Mohammad Mahdi Razmjoo",
      "Mohammad Mahdi Sharifian",
      "Saeed Bagheri Shouraki"
    ],
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12824",
    "title": "Adapting Multimodal Foundation Models for Few-Shot Learning: A Comprehensive Study on Contrastive Captioners",
    "abstract": "Large-scale multimodal foundation models, particularly Contrastive Captioners (CoCa), have achieved state-of-the-art results by unifying contrastive alignment with generative captioning. While zero-shot transfer capabilities are well-documented, the adaptation of these generative-contrastive hybrids to downstream tasks with extreme data scarcity (few-shot learning) remains under-explored. Existing literature predominantly focuses on dual-encoder architectures like CLIP, leaving a gap in understanding how CoCa's distinct latent space responds to parameter-efficient fine-tuning (PEFT). This paper presents a comprehensive empirical study on adapting the CoCa visual backbone for few-shot image classification. We systematically evaluate a hierarchy of strategies, ranging from training-free hybrid prototyping to deep parameter adaptation via Low-Rank Adaptation (LoRA). First, we identify an \"augmentation divergence\": while strong data augmentation degrades the performance of linear probing in low-shot settings, it is essential for stabilizing LoRA fine-tuning. We also demonstrate that hybrid objectives incorporating Supervised Contrastive (SupCon) loss yield consistent performance improvements over standard Cross-Entropy across varying shot counts. Crucially, we characterize the sensitivity of training configurations to data scarcity, providing empirical reference settings for scaling regularization, rank, and sampling strategies to facilitate the efficient adaptation of generative-contrastive foundation models.",
    "published": "2025-12-14T20:13:21Z",
    "authors": [
      "N. K. B. M. P. K. B. Narasinghe",
      "Uthayasanker Thayasivam"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12822",
    "title": "Lemon: A Unified and Scalable 3D Multimodal Model for Universal Spatial Understanding",
    "abstract": "Scaling large multimodal models (LMMs) to 3D understanding poses unique challenges: point cloud data is sparse and irregular, existing models rely on fragmented architectures with modality-specific encoders, and training pipelines often suffer from instability and poor scalability. We introduce Lemon, a unified transformer architecture that addresses these challenges by jointly processing 3D point cloud patches and language tokens as a single sequence. Unlike prior work that relies on modality-specific encoders and cross-modal alignment modules, this design enables early spatial-linguistic fusion, eliminates redundant encoders, improves parameter efficiency, and supports more effective model scaling. To handle the complexity of 3D data, we develop a structured patchification and tokenization scheme that preserves spatial context, and a three-stage training curriculum that progressively builds capabilities from object-level recognition to scene-level spatial reasoning. Lemon establishes new state-of-the-art performance across comprehensive 3D understanding and reasoning tasks, from object recognition and captioning to spatial reasoning in 3D scenes, while demonstrating robust scaling properties as model size and training data increase. Our work provides a unified foundation for advancing 3D spatial intelligence in real-world applications.",
    "published": "2025-12-14T20:02:43Z",
    "authors": [
      "Yongyuan Liang",
      "Xiyao Wang",
      "Yuanchen Ju",
      "Jianwei Yang",
      "Furong Huang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12821",
    "title": "On the continuity of flows",
    "abstract": "Flow matching has emerged as a powerful framework for generative modeling through continuous normalizing flows. We investigate a potential topological constraint: when the prior distribution and target distribution have mismatched topology (e.g., unimodal to multimodal), the optimal velocity field under standard flow matching objectives may exhibit spatial discontinuities. We suggest that this discontinuity arises from the requirement that continuous flows must bifurcate to map a single mode to multiple modes, forcing particles to make discrete routing decisions at intermediate times. Through theoretical analysis on bimodal Gaussian mixtures, we demonstrate that the optimal velocity field exhibits jump discontinuities along decision boundaries, with magnitude approaching infinity as time approaches the target distribution. Our analysis suggests that this phenomenon is not specific to $L^2$ loss, but rather may be a consequence of topological mismatch between distributions. We validate our theory empirically and discuss potential implications for flow matching on manifolds, connecting our findings to recent work on Riemannian flow matching and the challenge of learning discontinuous representations in neural networks.",
    "published": "2025-12-14T20:00:39Z",
    "authors": [
      "Congzhou M Sha"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12818",
    "title": "Hindsight is 20/20: Building Agent Memory that Retains, Recalls, and Reflects",
    "abstract": "Agent memory has been touted as a dimension of growth for LLM-based applications, enabling agents that can accumulate experience, adapt across sessions, and move beyond single-shot question answering. The current generation of agent memory systems treats memory as an external layer that extracts salient snippets from conversations, stores them in vector or graph-based stores, and retrieves top-k items into the prompt of an otherwise stateless model. While these systems improve personalization and context carry-over, they still blur the line between evidence and inference, struggle to organize information over long horizons, and offer limited support for agents that must explain their reasoning. We present Hindsight, a memory architecture that treats agent memory as a structured, first-class substrate for reasoning by organizing it into four logical networks that distinguish world facts, agent experiences, synthesized entity summaries, and evolving beliefs. This framework supports three core operations -- retain, recall, and reflect -- that govern how information is added, accessed, and updated. Under this abstraction, a temporal, entity aware memory layer incrementally turns conversational streams into a structured, queryable memory bank, while a reflection layer reasons over this bank to produce answers and to update information in a traceable way. On key long-horizon conversational memory benchmarks like LongMemEval and LoCoMo, Hindsight with an open-source 20B model lifts overall accuracy from 39% to 83.6% over a full-context baseline with the same backbone and outperforms full context GPT-4o. Scaling the backbone further pushes Hindsight to 91.4% on LongMemEval and up to 89.61% on LoCoMo (vs. 75.78% for the strongest prior open system), consistently outperforming existing memory architectures on multi-session and open-domain questions.",
    "published": "2025-12-14T19:47:23Z",
    "authors": [
      "Chris Latimer",
      "Nicoló Boschi",
      "Andrew Neeser",
      "Chris Bartholomew",
      "Gaurav Srivastava",
      "Xuan Wang",
      "Naren Ramakrishnan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12817",
    "title": "Decoding Human and AI Persuasion in National College Debate: Analyzing Prepared Arguments Through Aristotle's Rhetorical Principles",
    "abstract": "Debate has been widely adopted as a strategy to enhance critical thinking skills in English Language Arts (ELA). One important skill in debate is forming effective argumentation, which requires debaters to select supportive evidence from literature and construct compelling claims. However, the training of this skill largely depends on human coaching, which is labor-intensive and difficult to scale. To better support students in preparing for debates, this study explores the potential of leveraging artificial intelligence to generate effective arguments. Specifically, we prompted GPT-4 to create an evidence card and compared it to those produced by human debaters. The evidence cards outline the arguments students will present and how those arguments will be delivered, including components such as literature-based evidence quotations, summaries of core ideas, verbatim reading scripts, and tags (i.e., titles of the arguments). We compared the quality of the arguments in the evidence cards created by GPT and student debaters using Aristotle's rhetorical principles: ethos (credibility), pathos (emotional appeal), and logos (logical reasoning). Through a systematic qualitative and quantitative analysis, grounded in the rhetorical principles, we identify the strengths and limitations of human and GPT in debate reasoning, outlining areas where AI's focus and justifications align with or diverge from human reasoning. Our findings contribute to the evolving role of AI-assisted learning interventions, offering insights into how student debaters can develop strategies that enhance their argumentation and reasoning skills.",
    "published": "2025-12-14T19:46:16Z",
    "authors": [
      "Mengqian Wu",
      "Jiayi Zhang",
      "Raymond Z. Zhang"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12816",
    "title": "Optimal Resource Allocation for ML Model Training and Deployment under Concept Drift",
    "abstract": "We study how to allocate resources for training and deployment of machine learning (ML) models under concept drift and limited budgets. We consider a setting in which a model provider distributes trained models to multiple clients whose devices support local inference but lack the ability to retrain those models, placing the burden of performance maintenance on the provider. We introduce a model-agnostic framework that captures the interaction between resource allocation, concept drift dynamics, and deployment timing. We show that optimal training policies depend critically on the aging properties of concept durations. Under sudden concept changes, we derive optimal training policies subject to budget constraints when concept durations follow distributions with Decreasing Mean Residual Life (DMRL), and show that intuitive heuristics are provably suboptimal under Increasing Mean Residual Life (IMRL). We further study model deployment under communication constraints, prove that the associated optimization problem is quasi-convex under mild conditions, and propose a randomized scheduling strategy that achieves near-optimal client-side performance. These results offer theoretical and algorithmic foundations for cost-efficient ML model management under concept drift, with implications for continual learning, distributed inference, and adaptive ML systems.",
    "published": "2025-12-14T19:42:04Z",
    "authors": [
      "Hasan Burhan Beytur",
      "Gustavo de Veciana",
      "Haris Vikalo",
      "Kevin S Chan"
    ],
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12812",
    "title": "Does Tone Change the Answer? Evaluating Prompt Politeness Effects on Modern LLMs: GPT, Gemini, LLaMA",
    "abstract": "Prompt engineering has emerged as a critical factor influencing large language model (LLM) performance, yet the impact of pragmatic elements such as linguistic tone and politeness remains underexplored, particularly across different model families. In this work, we propose a systematic evaluation framework to examine how interaction tone affects model accuracy and apply it to three recently released and widely available LLMs: GPT-4o mini (OpenAI), Gemini 2.0 Flash (Google DeepMind), and Llama 4 Scout (Meta). Using the MMMLU benchmark, we evaluate model performance under Very Friendly, Neutral, and Very Rude prompt variants across six tasks spanning STEM and Humanities domains, and analyze pairwise accuracy differences with statistical significance testing.   Our results show that tone sensitivity is both model-dependent and domain-specific. Neutral or Very Friendly prompts generally yield higher accuracy than Very Rude prompts, but statistically significant effects appear only in a subset of Humanities tasks, where rude tone reduces accuracy for GPT and Llama, while Gemini remains comparatively tone-insensitive. When performance is aggregated across tasks within each domain, tone effects diminish and largely lose statistical significance. Compared with earlier researches, these findings suggest that dataset scale and coverage materially influence the detection of tone effects. Overall, our study indicates that while interaction tone can matter in specific interpretive settings, modern LLMs are broadly robust to tonal variation in typical mixed-domain use, providing practical guidance for prompt design and model selection in real-world deployments.",
    "published": "2025-12-14T19:25:20Z",
    "authors": [
      "Hanyu Cai",
      "Binqi Shen",
      "Lier Jin",
      "Lan Hu",
      "Xiaojing Fan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12809",
    "title": "OPAL: Operator-Programmed Algorithms for Landscape-Aware Black-Box Optimization",
    "abstract": "Black-box optimization often relies on evolutionary and swarm algorithms whose performance is highly problem dependent. We view an optimizer as a short program over a small vocabulary of search operators and learn this operator program separately for each problem instance. We instantiate this idea in Operator-Programmed Algorithms (OPAL), a landscape-aware framework for continuous black-box optimization that uses a small design budget with a standard differential evolution baseline to probe the landscape, builds a $k$-nearest neighbor graph over sampled points, and encodes this trajectory with a graph neural network. A meta-learner then maps the resulting representation to a phase-wise schedule of exploration, restart, and local search operators. On the CEC~2017 test suite, a single meta-trained OPAL policy is statistically competitive with state-of-the-art adaptive differential evolution variants and achieves significant improvements over simpler baselines under nonparametric tests. Ablation studies on CEC~2017 justify the choices for the design phase, the trajectory graph, and the operator-program representation, while the meta-components add only modest wall-clock overhead. Overall, the results indicate that operator-programmed, landscape-aware per-instance design is a practical way forward beyond ad hoc metaphor-based algorithms in black-box optimization.",
    "published": "2025-12-14T19:16:49Z",
    "authors": [
      "Junbo Jacob Lian",
      "Mingyang Yu",
      "Kaichen Ouyang",
      "Shengwei Fu",
      "Rui Zhong",
      "Yujun Zhang",
      "Jun Zhang",
      "Huiling Chen"
    ],
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12806",
    "title": "Fault-Tolerant Sandboxing for AI Coding Agents: A Transactional Approach to Safe Autonomous Execution",
    "abstract": "The transition of Large Language Models (LLMs) from passive code generators to autonomous agents introduces significant safety risks, specifically regarding destructive commands and inconsistent system states. Existing commercial solutions often prioritize interactive user safety, enforcing authentication barriers that break the headless loops required for true autonomy. This paper presents a Fault-Tolerant Sandboxing framework designed to mitigate these risks through a policy-based interception layer and a transactional filesystem snapshot mechanism. We hypothesize that wrapping agent actions in atomic transactions can guarantee safety with acceptable latency, outperforming the heavy initialization overhead of containers or the interactive friction of commercial CLIs. We validated this approach by deploying the Minimind-MoE LLM served via nano-vllm on a custom Proxmox-based testbed utilizing EVPN/VXLAN isolation. Experimental results demonstrate a 100\\% interception rate for high-risk commands and a 100\\% success rate in rolling back failed states. Crucially, our prototype incurs only a 14.5\\% performance overhead (approx. 1.8s) per transaction. In contrast, benchmarking against the Gemini CLI sandbox revealed that it requires interactive authentication (\"Sign in\"), rendering it unusable for headless, autonomous agent workflows.",
    "published": "2025-12-14T19:03:59Z",
    "authors": [
      "Boyang Yan"
    ],
    "categories": [
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12805",
    "title": "From Small to Large: Generalization Bounds for Transformers on Variable-Size Inputs",
    "abstract": "Transformers exhibit a notable property of \\emph{size generalization}, demonstrating an ability to extrapolate from smaller token sets to significantly longer ones. This behavior has been documented across diverse applications, including point clouds, graphs, and natural language. Despite its empirical success, this capability still lacks some rigorous theoretical characterizations. In this paper, we develop a theoretical framework to analyze this phenomenon for geometric data, which we represent as discrete samples from a continuous source (e.g., point clouds from manifolds, graphs from graphons). Our core contribution is a bound on the error between the Transformer's output for a discrete sample and its continuous-domain equivalent. We prove that for Transformers with stable positional encodings, this bound is determined by the sampling density and the intrinsic dimensionality of the data manifold. Experiments on graphs and point clouds of various sizes confirm the tightness of our theoretical bound.",
    "published": "2025-12-14T19:02:16Z",
    "authors": [
      "Anastasiia Alokhina",
      "Pan Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12804",
    "title": "Causal Counterfactuals Reconsidered",
    "abstract": "I develop a novel semantics for probabilities of counterfactuals that generalizes the standard Pearlian semantics: it applies to probabilistic causal models that cannot be extended into realistic structural causal models and are therefore beyond the scope of Pearl's semantics. This generalization is needed because, as I show, such probabilistic causal models arise even in simple settings. My semantics offer a natural compromize in the long-standing debate between Pearl and Dawid over counterfactuals: I agree with Dawid that universal causal determinism and unrealistic variables should be rejected, but I agree with Pearl that a general semantics of counterfactuals is nonetheless possible. I restrict attention to causal models that satisfy the Markov condition, only contain realistic variables, and are causally complete. Although I formulate my proposal using structural causal models, as does Pearl, I refrain from using so-called response variables. Moreover, I prove that my semantics is equivalent to two other recent proposals that do not involve structural causal models, and that it is in line with various comments on stochastic counterfactuals that have appeared in the literature more broadly. Throughout I also reflect on the universality of the Markov condition and explore a novel generalization of causal abstractions",
    "published": "2025-12-14T18:59:01Z",
    "authors": [
      "Sander Beckers"
    ],
    "categories": [
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12802",
    "title": "A Disproof of Large Language Model Consciousness: The Necessity of Continual Learning for Consciousness",
    "abstract": "The requirements for a falsifiable and non-trivial theory of consciousness significantly constrain such theories. Specifically, recent research on the Unfolding Argument and the Substitution Argument has given us formal tools to analyze requirements for a theory of consciousness. I show via a new Proximity Argument that these requirements especially constrain the potential consciousness of contemporary Large Language Models (LLMs) because of their proximity to systems that are equivalent to LLMs in terms of input/output function; yet, for these functionally equivalent systems, there cannot be any non-trivial theory of consciousness that judges them conscious. This forms the basis of a disproof of contemporary LLM consciousness. I then show a positive result, which is that theories of consciousness based on (or requiring) continual learning do satisfy the stringent formal constraints for a theory of consciousness in humans. Intriguingly, this work supports a hypothesis: If continual learning is linked to consciousness in humans, the current limitations of LLMs (which do not continually learn) are intimately tied to their lack of consciousness.",
    "published": "2025-12-14T18:51:15Z",
    "authors": [
      "Erik Hoel"
    ],
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 3
  },
  {
    "arxiv_id": "2512.12801",
    "title": "Fine-Grained Energy Prediction For Parallellized LLM Inference With PIE-P",
    "abstract": "With the widespread adoption of Large Language Models (LLMs), energy costs of running LLMs is quickly becoming a critical concern. However, precisely measuring the energy consumption of LLMs is often infeasible because hardware-based power monitors are not always accessible and software-based energy measurement tools are not accurate. While various prediction techniques have been developed to estimate LLM energy consumption, these approaches are limited to single-GPU environments and thus are not applicable to modern LLM inference which is typically parallelized across multiple GPUs. In this work, we remedy this gap and introduce PIE-P, a fine-grained energy prediction framework for multi-GPU inference, including tensor, pipeline, and data parallelism. Predicting the energy under parallelized inference is complicated by the non-determinism in inter-GPU communication, additional communication overheads, and difficulties in isolating energy during the communication/synchronization phase. We develop a scalable prediction framework that addresses these issues via precise sampling, fine-grained modeling of inter-GPU communication, and careful accounting of parallelization overhead. Our evaluation results show that PIE-P yields accurate and fine-grained energy predictions across parallelism strategies, significantly outperforming baselines.",
    "published": "2025-12-14T18:50:51Z",
    "authors": [
      "Anurag Dutt",
      "Young Won Choi",
      "Avirup Sil",
      "Anshul Gandhi",
      "Aruna Balasubramanian",
      "Niranjan Balasubramanian"
    ],
    "categories": [
      "cs.DC",
      "cs.PF"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12800",
    "title": "Learning Common and Salient Generative Factors Between Two Image Datasets",
    "abstract": "Recent advancements in image synthesis have enabled high-quality image generation and manipulation. Most works focus on: 1) conditional manipulation, where an image is modified conditioned on a given attribute, or 2) disentangled representation learning, where each latent direction should represent a distinct semantic attribute. In this paper, we focus on a different and less studied research problem, called Contrastive Analysis (CA). Given two image datasets, we want to separate the common generative factors, shared across the two datasets, from the salient ones, specific to only one dataset. Compared to existing methods, which use attributes as supervised signals for editing (e.g., glasses, gender), the proposed method is weaker, since it only uses the dataset signal. We propose a novel framework for CA, that can be adapted to both GAN and Diffusion models, to learn both common and salient factors. By defining new and well-adapted learning strategies and losses, we ensure a relevant separation between common and salient factors, preserving a high-quality generation. We evaluate our approach on diverse datasets, covering human faces, animal images and medical scans. Our framework demonstrates superior separation ability and image quality synthesis compared to prior methods.",
    "published": "2025-12-14T18:47:41Z",
    "authors": [
      "Yunlong He",
      "Gwilherm Lesné",
      "Ziqian Liu",
      "Michaël Soumm",
      "Pietro Gori"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12799",
    "title": "DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning",
    "abstract": "Although multi-modal large language models (MLLMs) have shown strong capabilities across diverse domains, their application in generating fine-grained 3D perception and prediction outputs in autonomous driving remains underexplored. In this paper, we propose DrivePI, a novel spatial-aware 4D MLLM that serves as a unified Vision-Language-Action (VLA) framework that is also compatible with vision-action (VA) models. Our method jointly performs spatial understanding, 3D perception (i.e., 3D occupancy), prediction (i.e., occupancy flow), and planning (i.e., action outputs) in parallel through end-to-end optimization. To obtain both precise geometric information and rich visual appearance, our approach integrates point clouds, multi-view images, and language instructions within a unified MLLM architecture. We further develop a data engine to generate text-occupancy and text-flow QA pairs for 4D spatial understanding. Remarkably, with only a 0.5B Qwen2.5 model as MLLM backbone, DrivePI as a single unified model matches or exceeds both existing VLA models and specialized VA models. Specifically, compared to VLA models, DrivePI outperforms OpenDriveVLA-7B by 2.5% mean accuracy on nuScenes-QA and reduces collision rate by 70% over ORION (from 0.37% to 0.11%) on nuScenes. Against specialized VA models, DrivePI surpasses FB-OCC by 10.3 RayIoU for 3D occupancy on OpenOcc, reduces the mAVE from 0.591 to 0.509 for occupancy flow on OpenOcc, and achieves 32% lower L2 error than VAD (from 0.72m to 0.49m) for planning on nuScenes. Code will be available at https://github.com/happinesslz/DrivePI",
    "published": "2025-12-14T18:45:54Z",
    "authors": [
      "Zhe Liu",
      "Runhui Huang",
      "Rui Yang",
      "Siming Yan",
      "Zining Wang",
      "Lu Hou",
      "Di Lin",
      "Xiang Bai",
      "Hengshuang Zhao"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12795",
    "title": "TRACER: Transfer Learning based Real-time Adaptation for Clinical Evolving Risk",
    "abstract": "Clinical decision support tools built on electronic health records often experience performance drift due to temporal population shifts, particularly when changes in the clinical environment initially affect only a subset of patients, resulting in a transition to mixed populations. Such case-mix changes commonly arise following system-level operational updates or the emergence of new diseases, such as COVID-19. We propose TRACER (Transfer Learning-based Real-time Adaptation for Clinical Evolving Risk), a framework that identifies encounter-level transition membership and adapts predictive models using transfer learning without full retraining. In simulation studies, TRACER outperformed static models trained on historical or contemporary data. In a real-world application predicting hospital admission following emergency department visits across the COVID-19 transition, TRACER improved both discrimination and calibration. TRACER provides a scalable approach for maintaining robust predictive performance under evolving and heterogeneous clinical conditions.",
    "published": "2025-12-14T18:23:22Z",
    "authors": [
      "Mengying Yan",
      "Ziye Tian",
      "Siqi Li",
      "Nan Liu",
      "Benjamin A. Goldstein",
      "Molei Liu",
      "Chuan Hong"
    ],
    "categories": [
      "cs.LG",
      "stat.ME"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12792",
    "title": "Liquid Reasoning Transformers: A Sudoku-Based Prototype for Chess-Scale Algorithmic Tasks",
    "abstract": "The Liquid Reasoning Transformer (LRT) is a transformer architecture designed for inference with adaptive depths using iterative changes, discard-based correction, and a learned stopping mechanism. Instead of relying on a single feedforward pass, the model updates a recurrent reasoning token across multiple internal steps, allowing it to correct early errors and allocate computation based on input difficulty. We evaluate the LRT on Sudoku as a controlled testbed for structured reasoning and show that it achieves strong performance, reaching 98.68% digit accuracy and 36.30% full-puzzle accuracy without using symbolic rules or search. Analyzing internal patterns shows that the discard and stop gates play different, important roles in stabilizing inferences and adjusting computational depth. We discuss how these mechanisms extend naturally to chess-scale reasoning tasks and outline extensions for multi-token reasoning and larger domains.",
    "published": "2025-12-14T18:20:05Z",
    "authors": [
      "Shivansh Sahni",
      "Wenzhi Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12791",
    "title": "Beyond Task Completion: An Assessment Framework for Evaluating Agentic AI Systems",
    "abstract": "Recent advances in agentic AI have shifted the focus from standalone Large Language Models (LLMs) to integrated systems that combine LLMs with tools, memory, and other agents to perform complex tasks. These multi-agent architectures enable coordinated reasoning, planning, and execution across diverse domains, allowing agents to collaboratively automate complex workflows. Despite these advances, evaluation and assessment of LLM agents and the multi-agent systems they constitute remain a fundamental challenge. Although various approaches have been proposed in the software engineering literature for evaluating conventional software components, existing methods for AI-based systems often overlook the non-deterministic nature of models. This non-determinism introduces behavioral uncertainty during execution, yet existing evaluations rely on binary task completion metrics that fail to capture it. Evaluating agentic systems therefore requires examining additional dimensions, including the agent ability to invoke tools, ingest and retrieve memory, collaborate with other agents, and interact effectively with its environment. We propose an end-to-end Agent Assessment Framework with four evaluation pillars encompassing LLMs, Memory, Tools, and Environment. We validate the framework on a representative Autonomous CloudOps use case, where experiments reveal behavioral deviations overlooked by conventional metrics, demonstrating its effectiveness in capturing runtime uncertainties.",
    "published": "2025-12-14T18:17:40Z",
    "authors": [
      "Sreemaee Akshathala",
      "Bassam Adnan",
      "Mahisha Ramesh",
      "Karthik Vaidhyanathan",
      "Basil Muhammed",
      "Kannan Parthasarathy"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12790",
    "title": "L-STEC: Learned Video Compression with Long-term Spatio-Temporal Enhanced Context",
    "abstract": "Neural Video Compression has emerged in recent years, with condition-based frameworks outperforming traditional codecs. However, most existing methods rely solely on the previous frame's features to predict temporal context, leading to two critical issues. First, the short reference window misses long-term dependencies and fine texture details. Second, propagating only feature-level information accumulates errors over frames, causing prediction inaccuracies and loss of subtle textures. To address these, we propose the Long-term Spatio-Temporal Enhanced Context (L-STEC) method. We first extend the reference chain with LSTM to capture long-term dependencies. We then incorporate warped spatial context from the pixel domain, fusing spatio-temporal information through a multi-receptive field network to better preserve reference details. Experimental results show that L-STEC significantly improves compression by enriching contextual information, achieving 37.01% bitrate savings in PSNR and 31.65% in MS-SSIM compared to DCVC-TCM, outperforming both VTM-17.0 and DCVC-FM and establishing new state-of-the-art performance.",
    "published": "2025-12-14T18:11:16Z",
    "authors": [
      "Tiange Zhang",
      "Zhimeng Huang",
      "Xiandong Meng",
      "Kai Zhang",
      "Zhipin Deng",
      "Siwei Ma"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12788",
    "title": "Temporal HAL-API Dependencies as a Gateway to Formal Embedded Software Development",
    "abstract": "Temporal HAL-API Dependencies (THADs) can be useful to capture an interesting class of correctness properties in embedded software development. They demand a moderate effort for specification (which can be done via program annotations) and verification (which can be done automatically via software model checking). In this sense, they have the potential to form an interesting sweet spot between generic properties (that demand virtually no specification effort, and that are typically addressed by static analysis) and application-specific properties as addressed by full-fledged formal methods. Thus, they may form a gateway to wider and more economic use of formal methods in industrial embedded software development.",
    "published": "2025-12-14T18:08:09Z",
    "authors": [
      "Manuel Bentele",
      "Andreas Podelski",
      "Axel Sikora",
      "Bernd Westphal"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12787",
    "title": "Unveiling Statistical Significance of Online Regression over Multiple Datasets",
    "abstract": "Despite extensive focus on techniques for evaluating the performance of two learning algorithms on a single dataset, the critical challenge of developing statistical tests to compare multiple algorithms across various datasets has been largely overlooked in most machine learning research. Additionally, in the realm of Online Learning, ensuring statistical significance is essential to validate continuous learning processes, particularly for achieving rapid convergence and effectively managing concept drifts in a timely manner. Robust statistical methods are needed to assess the significance of performance differences as data evolves over time. This article examines the state-of-the-art online regression models and empirically evaluates several suitable tests. To compare multiple online regression models across various datasets, we employed the Friedman test along with corresponding post-hoc tests. For thorough evaluations, utilizing both real and synthetic datasets with 5-fold cross-validation and seed averaging ensures comprehensive assessment across various data subsets. Our tests generally confirmed the performance of competitive baselines as consistent with their individual reports. However, some statistical test results also indicate that there is still room for improvement in certain aspects of state-of-the-art methods.",
    "published": "2025-12-14T18:04:11Z",
    "authors": [
      "Mohammad Abu-Shaira",
      "Weishi Shi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12785",
    "title": "OLC-WA: Drift Aware Tuning-Free Online Classification with Weighted Average",
    "abstract": "Real-world data sets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. This paper introduces Online Classification with Weighted Average (OLC-WA), an adaptive, hyperparameter-free online classification model equipped with an automated optimization mechanism. OLC-WA operates by blending incoming data streams with an existing base model. This blending is facilitated by an exponentially weighted moving average. Furthermore, an integrated optimization mechanism dynamically detects concept drift, quantifies its magnitude, and adjusts the model based on the observed data stream characteristics. This approach empowers the model to effectively adapt to evolving data distributions within streaming environments. Rigorous empirical evaluation across diverse benchmark datasets shows that OLC-WA achieves performance comparable to batch models in stationary environments, maintaining accuracy within 1-3%, and surpasses leading online baselines by 10-25% under drift, demonstrating its effectiveness in adapting to dynamic data streams.",
    "published": "2025-12-14T17:52:39Z",
    "authors": [
      "Mohammad Abu Shaira",
      "Yunhe Feng",
      "Heng Fan",
      "Weishi Shi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12783",
    "title": "Credit Risk Estimation with Non-Financial Features: Evidence from a Synthetic Istanbul Dataset",
    "abstract": "Financial exclusion constrains entrepreneurship, increases income volatility, and widens wealth gaps. Underbanked consumers in Istanbul often have no bureau file because their earnings and payments flow through informal channels. To study how such borrowers can be evaluated we create a synthetic dataset of one hundred thousand Istanbul residents that reproduces first quarter 2025 TÜİK census marginals and telecom usage patterns. Retrieval augmented generation feeds these public statistics into the OpenAI o3 model, which synthesises realistic yet private records. Each profile contains seven socio demographic variables and nine alternative attributes that describe phone specifications, online shopping rhythm, subscription spend, car ownership, monthly rent, and a credit card flag. To test the impact of the alternative financial data CatBoost, LightGBM, and XGBoost are each trained in two versions. Demo models use only the socio demographic variables; Full models include both socio demographic and alternative attributes. Across five fold stratified validation the alternative block raises area under the curve by about one point three percentage and lifts balanced \\(F_{1}\\) from roughly 0.84 to 0.95, a fourteen percent gain. We contribute an open Istanbul 2025 Q1 synthetic dataset, a fully reproducible modeling pipeline, and empirical evidence that a concise set of behavioural attributes can approach bureau level discrimination power while serving borrowers who lack formal credit records. These findings give lenders and regulators a transparent blueprint for extending fair and safe credit access to the underbanked.",
    "published": "2025-12-14T17:48:13Z",
    "authors": [
      "Atalay Denknalbant",
      "Emre Sezdi",
      "Zeki Furkan Kutlu",
      "Polat Goktas"
    ],
    "categories": [
      "cs.LG",
      "q-fin.ST",
      "stat.AP"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12779",
    "title": "OLR-WAA: Adaptive and Drift-Resilient Online Regression with Dynamic Weighted Averaging",
    "abstract": "Real-world datasets frequently exhibit evolving data distributions, reflecting temporal variations and underlying shifts. Overlooking this phenomenon, known as concept drift, can substantially degrade the predictive performance of the model. Furthermore, the presence of hyperparameters in online models exacerbates this issue, as these parameters are typically fixed and lack the flexibility to dynamically adjust to evolving data. This paper introduces \"OLR-WAA: An Adaptive and Drift-Resilient Online Regression with Dynamic Weighted Average\", a hyperparameter-free model designed to tackle the challenges of non-stationary data streams and enable effective, continuous adaptation. The objective is to strike a balance between model stability and adaptability. OLR-WAA incrementally updates its base model by integrating incoming data streams, utilizing an exponentially weighted moving average. It further introduces a unique optimization mechanism that dynamically detects concept drift, quantifies its magnitude, and adjusts the model based on real-time data characteristics. Rigorous evaluations show that it matches batch regression performance in static settings and consistently outperforms or rivals state-of-the-art online models, confirming its effectiveness. Concept drift datasets reveal a performance gap that OLR-WAA effectively bridges, setting it apart from other online models. In addition, the model effectively handles confidence-based scenarios through a conservative update strategy that prioritizes stable, high-confidence data points. Notably, OLR-WAA converges rapidly, consistently yielding higher R2 values compared to other online models.",
    "published": "2025-12-14T17:39:51Z",
    "authors": [
      "Mohammad Abu-Shaira",
      "Weishi Shi"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12777",
    "title": "State over Tokens: Characterizing the Role of Reasoning Tokens",
    "abstract": "Large Language Models (LLMs) can generate reasoning tokens before their final answer to boost performance on complex tasks. While these sequences seem like human thought processes, empirical evidence reveals that they are not a faithful explanation of the model's actual reasoning process. To address this gap between appearance and function, we introduce the State over Tokens (SoT) conceptual framework. SoT reframes reasoning tokens not as a linguistic narrative, but as an externalized computational state -- the sole persistent information carrier across the model's stateless generation cycles. This explains how the tokens can drive correct reasoning without being a faithful explanation when read as text and surfaces previously overlooked research questions on these tokens. We argue that to truly understand the process that LLMs do, research must move beyond reading the reasoning tokens as text and focus on decoding them as state.",
    "published": "2025-12-14T17:30:34Z",
    "authors": [
      "Mosh Levy",
      "Zohar Elyoseph",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12775",
    "title": "Persistent Personas? Role-Playing, Instruction Following, and Safety in Extended Interactions",
    "abstract": "Persona-assigned large language models (LLMs) are used in domains such as education, healthcare, and sociodemographic simulation. Yet, they are typically evaluated only in short, single-round settings that do not reflect real-world usage. We introduce an evaluation protocol that combines long persona dialogues (over 100 rounds) and evaluation datasets to create dialogue-conditioned benchmarks that can robustly measure long-context effects. We then investigate the effects of dialogue length on persona fidelity, instruction-following, and safety of seven state-of-the-art open- and closed-weight LLMs. We find that persona fidelity degrades over the course of dialogues, especially in goal-oriented conversations, where models must sustain both persona fidelity and instruction following. We identify a trade-off between fidelity and instruction following, with non-persona baselines initially outperforming persona-assigned models; as dialogues progress and fidelity fades, persona responses become increasingly similar to baseline responses. Our findings highlight the fragility of persona applications in extended interactions and our work provides a protocol to systematically measure such failures.",
    "published": "2025-12-14T17:27:02Z",
    "authors": [
      "Pedro Henrique Luz de Araujo",
      "Michael A. Hedderich",
      "Ali Modarressi",
      "Hinrich Schuetze",
      "Benjamin Roth"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12774",
    "title": "Fast 2DGS: Efficient Image Representation with Deep Gaussian Prior",
    "abstract": "As generative models become increasingly capable of producing high-fidelity visual content, the demand for efficient, interpretable, and editable image representations has grown substantially. Recent advances in 2D Gaussian Splatting (2DGS) have emerged as a promising solution, offering explicit control, high interpretability, and real-time rendering capabilities (>1000 FPS). However, high-quality 2DGS typically requires post-optimization. Existing methods adopt random or heuristics (e.g., gradient maps), which are often insensitive to image complexity and lead to slow convergence (>10s). More recent approaches introduce learnable networks to predict initial Gaussian configurations, but at the cost of increased computational and architectural complexity. To bridge this gap, we present Fast-2DGS, a lightweight framework for efficient Gaussian image representation. Specifically, we introduce Deep Gaussian Prior, implemented as a conditional network to capture the spatial distribution of Gaussian primitives under different complexities. In addition, we propose an attribute regression network to predict dense Gaussian properties. Experiments demonstrate that this disentangled architecture achieves high-quality reconstruction in a single forward pass, followed by minimal fine-tuning. More importantly, our approach significantly reduces computational cost without compromising visual quality, bringing 2DGS closer to industry-ready deployment.",
    "published": "2025-12-14T17:23:28Z",
    "authors": [
      "Hao Wang",
      "Ashish Bastola",
      "Chaoyi Zhou",
      "Wenhui Zhu",
      "Xiwen Chen",
      "Xuanzhao Dong",
      "Siyu Huang",
      "Abolfazl Razi"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12773",
    "title": "Designing The Drive: Enhancing User Experience through Adaptive Interfaces in Autonomous Vehicles",
    "abstract": "With the recent development and integration of autonomous vehicles (AVs) in transportation systems of the modern world, the emphasis on customizing user interfaces to optimize the overall user experience has been growing expediently. Therefore, understanding user needs and preferences is essential to the acceptance and trust of these technologies as they continue to grow in prevalence. This paper addresses the implementation of HCI principles in the personalization of interfaces to improve safety, security, and usability for the users. This paper explores the way that personalized interfaces can be devised to increase user engagement and satisfaction through various HCI strategies such as adaptive design, multi-modal interaction, and user feedback mechanisms. Moreover, this paper puts emphasis on factors of transparency and user control in the design of an interface; hence, allowing users to design or modify their experience could foster an increase in trust in autonomous systems. In so doing, this research touches on the quite influential role HCI will play in this future scenario of autonomous vehicles while designing to ensure relevance to the diverse needs of users while maintaining high standards of safety and security. Discussing various HCI strategies such as adaptive design, multi-modal interaction, and feedback mechanisms to the user, this paper demonstrates how personalized interfaces can enhance significantly both user engagement and satisfaction. Transparency and user control also in designing an interface are further discussed, pointing out the need for a prerequisite condition of enabling the user to take control of their experience as a state of trust in autonomous systems. In summary, this paper points out the role of HCI in the development of autonomous vehicles and addresses numerous needs with respect to those enforced safety and security standards.",
    "published": "2025-12-14T17:23:28Z",
    "authors": [
      "Reeteesha Roy"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12772",
    "title": "JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation",
    "abstract": "Understanding videos inherently requires reasoning over both visual and auditory information. To properly evaluate Omni-Large Language Models (Omni-LLMs), which are capable of processing multi-modal information including vision and audio, an effective benchmark must comprehensively cover three key aspects: (1) multi-modal dependency (i.e., questions that cannot be answered using vision or audio alone), (2) diverse audio information types (e.g., speech, sound events), and (3) varying scene spans. However, existing datasets fall short in one or more of these dimensions, limiting strict and comprehensive evaluation. To address this gap, we introduce JointAVBench, a novel benchmark with strict audio-video correlation, spanning five cognitive dimensions, four audio information types (speech, sound events, music, vocal traits), and three scene spans (single-, cross-, and full-scene). Given the high cost of manual annotation, we propose an automated pipeline that leverages state-of-the-art vision-LLMs, audio-LLMs, and general-purpose LLMs to synthesize questions and answers that strictly require joint audio-visual understanding. We evaluate leading vision-only, audio-only, and Omni-LLMs on our dataset. Results show that even the best-performing Omni-LLM achieves an average accuracy of only 62.6\\%, outperforming uni-modal baselines but revealing substantial room for improvement, especially in cross-scene reasoning.",
    "published": "2025-12-14T17:23:21Z",
    "authors": [
      "Jianghan Chao",
      "Jianzhang Gao",
      "Wenhui Tan",
      "Yuchong Sun",
      "Ruihua Song",
      "Liyun Ru"
    ],
    "categories": [
      "cs.MM",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12770",
    "title": "Curió-Edu 7B: Examining Data Selection Impacts in LLM Continued Pretraining",
    "abstract": "Continued pretraining extends a language model's capabilities by further exposing it to additional data, often tailored to a specific linguistic or domain context. This strategy has emerged as an efficient alternative to full retraining when adapting general-purpose models to new settings. In this work, we investigate this paradigm through Curió 7B, a 7-billion-parameter model derived from LLaMA-2 and trained on 100 billion Portuguese tokens from the ClassiCC-PT corpus - the most extensive Portuguese-specific continued-pretraining effort above the three-billion-parameter scale to date. Beyond scale, we investigate whether quantity alone suffices or whether data quality plays a decisive role in linguistic adaptation. To this end, we introduce Curió-Edu 7B, a variant trained exclusively on the educational and STEM-filtered subset of the same corpus, totaling just 10 billion tokens. Despite using only 10% of the data and 20% of the computation, Curió-Edu 7B surpasses the full-corpus model in our evaluations, demonstrating that data selection can be fundamental even when adapting models with limited prior exposure to the target language. The developed models are available at https://huggingface.co/collections/ClassiCC-Corpus/curio-edu",
    "published": "2025-12-14T17:19:32Z",
    "authors": [
      "Thales Sales Almeida",
      "Rodrigo Nogueira",
      "Hélio Pedrini"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12769",
    "title": "Adaptive Edge-Cloud Inference for Speech-to-Action Systems Using ASR and Large Language Models (ASTA)",
    "abstract": "Voice-based interaction has emerged as a natural and intuitive modality for controlling IoT devices. However, speech-driven edge devices face a fundamental trade-off between cloud-based solutions, which offer stronger language understanding capabilities at the cost of latency, connectivity dependence, and privacy concerns, and edge-based solutions, which provide low latency and improved privacy but are limited by computational constraints. This paper presents ASTA, an adaptive speech-to-action solution that dynamically routes voice commands between edge and cloud inference to balance performance and system resource utilization. ASTA integrates on-device automatic speech recognition and lightweight offline language-model inference with cloud-based LLM processing, guided by real-time system metrics such as CPU workload, device temperature, and network latency. A metric-aware routing mechanism selects the inference path at runtime, while a rule-based command validation and repair component ensures successful end-to-end command execution. We implemented our solution on an NVIDIA Jetson-based edge platform and evaluated it using a diverse dataset of 80 spoken commands. Experimental results show that ASTA successfully routes all input commands for execution, achieving a balanced distribution between online and offline inference. The system attains an ASR accuracy of 62.5% and generates executable commands without repair for only 47.5% of inputs, highlighting the importance of the repair mechanism in improving robustness. These results suggest that adaptive edge-cloud orchestration is a viable approach for resilient and resource-aware voice-controlled IoT systems.",
    "published": "2025-12-14T17:07:23Z",
    "authors": [
      "Mohammad Jalili Torkamani",
      "Israt Zarin"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12768",
    "title": "CoRe3D: Collaborative Reasoning as a Foundation for 3D Intelligence",
    "abstract": "Recent advances in large multimodal models suggest that explicit reasoning mechanisms play a critical role in improving model reliability, interpretability, and cross-modal alignment. While such reasoning-centric approaches have been proven effective in language and vision tasks, their extension to 3D remains underdeveloped. CoRe3D introduces a unified 3D understanding and generation reasoning framework that jointly operates over semantic and spatial abstractions, enabling high-level intent inferred from language to directly guide low-level 3D content formation. Central to this design is a spatially grounded reasoning representation that decomposes 3D latent space into localized regions, allowing the model to reason over geometry in a compositional and procedural manner. By tightly coupling semantic chain-of-thought inference with structured spatial reasoning, CoRe3D produces 3D outputs that exhibit strong local consistency and faithful alignment with linguistic descriptions.",
    "published": "2025-12-14T17:05:11Z",
    "authors": [
      "Tianjiao Yu",
      "Xinzhuo Li",
      "Yifan Shen",
      "Yuanzhe Liu",
      "Ismini Lourentzou"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12762",
    "title": "Federated Learning with Feedback Alignment",
    "abstract": "Federated Learning (FL) enables collaborative training across multiple clients while preserving data privacy, yet it struggles with data heterogeneity, where clients' data are not distributed independently and identically (non-IID). This causes local drift, hindering global model convergence. To address this, we introduce Federated Learning with Feedback Alignment (FLFA), a novel framework that integrates feedback alignment into FL. FLFA uses the global model's weights as a shared feedback matrix during local training's backward pass, aligning local updates with the global model efficiently. This approach mitigates local drift with minimal additional computational cost and no extra communication overhead.   Our theoretical analysis supports FLFA's design by showing how it alleviates local drift and demonstrates robust convergence for both local and global models. Empirical evaluations, including accuracy comparisons and measurements of local drift, further illustrate that FLFA can enhance other FL methods demonstrating its effectiveness.",
    "published": "2025-12-14T16:59:55Z",
    "authors": [
      "Incheol Baek",
      "Hyungbin Kim",
      "Minseo Kim",
      "Yon Dohn Chung"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12760",
    "title": "Intelligent Scientific Literature Explorer using Machine Learning (ISLE)",
    "abstract": "The rapid acceleration of scientific publishing has created substantial challenges for researchers attempting to discover, contextualize, and interpret relevant literature. Traditional keyword-based search systems provide limited semantic understanding, while existing AI-driven tools typically focus on isolated tasks such as retrieval, clustering, or bibliometric visualization. This paper presents an integrated system for scientific literature exploration that combines large-scale data acquisition, hybrid retrieval, semantic topic modeling, and heterogeneous knowledge graph construction. The system builds a comprehensive corpus by merging full-text data from arXiv with structured metadata from OpenAlex. A hybrid retrieval architecture fuses BM25 lexical search with embedding-based semantic search using Reciprocal Rank Fusion. Topic modeling is performed on retrieved results using BERTopic or non-negative matrix factorization depending on computational resources. A knowledge graph unifies papers, authors, institutions, countries, and extracted topics into an interpretable structure. The system provides a multi-layered exploration environment that reveals not only relevant publications but also the conceptual and relational landscape surrounding a query. Evaluation across multiple queries demonstrates improvements in retrieval relevance, topic coherence, and interpretability. The proposed framework contributes an extensible foundation for AI-assisted scientific discovery.",
    "published": "2025-12-14T16:54:24Z",
    "authors": [
      "Sina Jani",
      "Arman Heidari",
      "Amirmohammad Anvari",
      "Zahra Rahimi"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12756",
    "title": "FysicsWorld: A Unified Full-Modality Benchmark for Any-to-Any Understanding, Generation, and Reasoning",
    "abstract": "Despite rapid progress in multimodal large language models (MLLMs) and emerging omni-modal architectures, current benchmarks remain limited in scope and integration, suffering from incomplete modality coverage, restricted interaction to text-centric outputs, and weak interdependence and complementarity among modalities. To bridge these gaps, we introduce FysicsWorld, the first unified full-modality benchmark that supports bidirectional input-output across image, video, audio, and text, enabling comprehensive any-to-any evaluation across understanding, generation, and reasoning. FysicsWorld encompasses 16 primary tasks and 3,268 curated samples, aggregated from over 40 high-quality sources and covering a rich set of open-domain categories with diverse question types. We also propose the Cross-Modal Complementarity Screening (CMCS) strategy integrated in a systematic data construction framework that produces omni-modal data for spoken interaction and fusion-dependent cross-modal reasoning. Through a comprehensive evaluation of over 30 state-of-the-art baselines, spanning MLLMs, modality-specific models, unified understanding-generation models, and omni-modal language models, FysicsWorld exposes the performance disparities and limitations across models in understanding, generation, and reasoning. Our benchmark establishes a unified foundation and strong baselines for evaluating and advancing next-generation full-modality architectures.",
    "published": "2025-12-14T16:41:29Z",
    "authors": [
      "Yue Jiang",
      "Dingkang Yang",
      "Minghao Han",
      "Jinghang Han",
      "Zizhi Chen",
      "Yizhou Liu",
      "Mingcheng Li",
      "Peng Zhai",
      "Lihua Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12755",
    "title": "An End-to-End Approach for Microgrid Probabilistic Forecasting and Robust Operation via Decision-focused Learning",
    "abstract": "High penetration of renewable energy sources (RES) introduces significant uncertainty and intermittency into microgrid operations, posing challenges to economic and reliable scheduling. To address this, this paper proposes an end-to-end decision-focused framework that jointly optimizes probabilistic forecasting and robust operation for microgrids. A multilayer encoder-decoder (MED) probabilistic forecasting model is integrated with a two-stage robust optimization (TSRO) model involving direct load control (DLC) through a differentiable decision pathway, enabling gradient-based feedback from operational outcomes to improve forecasting performance. Unlike conventional sequential approaches, the proposed method aligns forecasting accuracy with operational objectives by directly minimizing decision regret via a surrogate smart predict-then-optimize (SPO) loss function. This integration ensures that probabilistic forecasts are optimized for downstream decisions, enhancing both economic efficiency and robustness. Case studies on modified IEEE 33-bus and 69-bus systems demonstrate that the proposed framework achieves superior forecasting accuracy and operational performance, reducing total and net operation costs by up to 18% compared with conventional forecasting and optimization combinations. The results verify the effectiveness and scalability of the end-to-end decision-focused approach for resilient and cost-efficient microgrid management under uncertainty.",
    "published": "2025-12-14T16:36:04Z",
    "authors": [
      "Tingwei Cao",
      "Yan Xu"
    ],
    "categories": [
      "eess.SY",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12751",
    "title": "GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation",
    "abstract": "Physics-aware driving world model is essential for drive planning, out-of-distribution data synthesis, and closed-loop evaluation. However, existing methods often rely on a single diffusion model to directly map driving actions to videos, which makes learning difficult and leads to physically inconsistent outputs. To overcome these challenges, we propose GenieDrive, a novel framework designed for physics-aware driving video generation. Our approach starts by generating 4D occupancy, which serves as a physics-informed foundation for subsequent video generation. 4D occupancy contains rich physical information, including high-resolution 3D structures and dynamics. To facilitate effective compression of such high-resolution occupancy, we propose a VAE that encodes occupancy into a latent tri-plane representation, reducing the latent size to only 58% of that used in previous methods. We further introduce Mutual Control Attention (MCA) to accurately model the influence of control on occupancy evolution, and we jointly train the VAE and the subsequent prediction module in an end-to-end manner to maximize forecasting accuracy. Together, these designs yield a 7.2% improvement in forecasting mIoU at an inference speed of 41 FPS, while using only 3.47 M parameters. Additionally, a Normalized Multi-View Attention is introduced in the video generation model to generate multi-view driving videos with guidance from our 4D occupancy, significantly improving video quality with a 20.7% reduction in FVD. Experiments demonstrate that GenieDrive enables highly controllable, multi-view consistent, and physics-aware driving video generation.",
    "published": "2025-12-14T16:23:51Z",
    "authors": [
      "Zhenya Yang",
      "Zhe Liu",
      "Yuxiang Lu",
      "Liping Hou",
      "Chenxuan Miao",
      "Siyi Peng",
      "Bailan Feng",
      "Xiang Bai",
      "Hengshuang Zhao"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12749",
    "title": "Flow-matching Operators for Residual-Augmented Probabilistic Learning of Partial Differential Equations",
    "abstract": "Learning probabilistic surrogates for PDEs remains challenging in data-scarce regimes: neural operators require large amounts of high-fidelity data, while generative approaches typically sacrifice resolution invariance. We formulate flow matching in an infinite-dimensional function space to learn a probabilistic transport that maps low-fidelity approximations to the manifold of high-fidelity PDE solutions via learned residual corrections. We develop a conditional neural operator architecture based on feature-wise linear modulation for flow-matching vector fields directly in function space, enabling inference at arbitrary spatial resolutions without retraining. To improve stability and representational control of the induced neural ODE, we parameterize the flow vector field as a sum of a linear operator and a nonlinear operator, combining lightweight linear components with a conditioned Fourier neural operator for expressive, input-dependent dynamics. We then formulate a residual-augmented learning strategy where the flow model learns probabilistic corrections from inexpensive low-fidelity surrogates to high-fidelity solutions, rather than learning the full solution mapping from scratch. Finally, we derive tractable training objectives that extend conditional flow matching to the operator setting with input-function-dependent couplings. To demonstrate the effectiveness of our approach, we present numerical experiments on a range of PDEs, including the 1D advection and Burgers' equation, and a 2D Darcy flow problem for flow through a porous medium.   We show that the proposed method can accurately learn solution operators across different resolutions and fidelities and produces uncertainty estimates that appropriately reflect model confidence, even when trained on limited high-fidelity data.",
    "published": "2025-12-14T16:06:10Z",
    "authors": [
      "Sahil Bhola",
      "Karthik Duraisamy"
    ],
    "categories": [
      "stat.CO",
      "cs.LG",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12744",
    "title": "Resting Neurons, Active Insights: Improving Input Sparsification for Large Language Models",
    "abstract": "Large Language Models (LLMs) achieve state-of-the-art performance across a wide range of applications, but their massive scale poses significant challenges for both efficiency and interpretability. Structural pruning, which reduces model size by removing redundant computational units such as neurons, has been widely explored as a solution, and this study devotes to input sparsification, an increasingly popular technique that improves efficiency by selectively activating only a subset of entry values for each input. However, existing approaches focus primarily on computational savings, often overlooking the representational consequences of sparsification and leaving a noticeable performance gap compared to full models. In this work, we first reinterpret input sparsification as a form of dynamic structural pruning. Motivated by the spontaneous baseline firing rates observed in biological neurons, we introduce a small set of trainable spontaneous neurons that act as compensatory units to stabilize activations in sparsified LLMs. Experiments demonstrate that these auxiliary neurons substantially reduce the sparsification-induced performance gap while generalizing effectively across tasks.",
    "published": "2025-12-14T15:47:40Z",
    "authors": [
      "Haotian Xu",
      "Tian Gao",
      "Tsui-Wei Weng",
      "Tengfei Ma"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12742",
    "title": "Transport Reversible Jump Markov Chain Monte Carlo with proposals generated by Variational Inference with Normalizing Flows",
    "abstract": "We present a framework using variational inference with normalizing flows (VI-NFs) to generate proposals of reversible jump Markov chain Monte Carlo (RJMCMC) for efficient trans-dimensional Bayesian inference. Unlike transport reversible jump methods relying on forward KL minimization with pilot MCMC samples, our approach minimizes the reverse KL divergence which requires only samples from a base distribution, eliminating costly target sampling. The method employs RealNVP-based flows to learn model-specific transport maps, enabling construction of both between-model and within-model proposals. Our framework provides accurate marginal likelihood estimates from the variational approximation. This facilitates efficient model comparison and proposal adaptation in RJMCMC. Experiments on illustrative example, factor analysis and variable selection tasks in linear regression show that TRJ designed by VI-NFs achieves faster mixing and more efficient model space exploration compared to existing baselines. The proposed algorithm can be extended to conditional flows for amortized vairiational inference across models. Code is available at https://github.com/YinPingping111/TRJ_VINFs.",
    "published": "2025-12-14T15:38:47Z",
    "authors": [
      "Pingping Yin",
      "Xiyun Jiao"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12737",
    "title": "SPARK: Igniting Communication-Efficient Decentralized Learning via Stage-wise Projected NTK and Accelerated Regularization",
    "abstract": "Decentralized federated learning (DFL) faces critical challenges from statistical heterogeneity and communication overhead. While NTK-based methods achieve faster convergence, transmitting full Jacobian matrices is impractical for bandwidth-constrained edge networks. We propose SPARK, synergistically integrating random projection-based Jacobian compression, stage-wise annealed distillation, and Nesterov momentum acceleration. Random projections compress Jacobians while preserving spectral properties essential for convergence. Stage-wise annealed distillation transitions from pure NTK evolution to neighbor-regularized learning, counteracting compression noise. Nesterov momentum accelerates convergence through stable accumulation enabled by distillation smoothing. SPARK achieves 98.7% communication reduction compared to NTK-DFL while maintaining convergence speed and superior accuracy. With momentum, SPARK reaches target performance 3 times faster, establishing state-of-the-art results for communication-efficient decentralized learning and enabling practical deployment in bandwidth-limited edge environments.",
    "published": "2025-12-14T15:21:31Z",
    "authors": [
      "Li Xia"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12736",
    "title": "Personalized QoE Prediction: A Demographic-Augmented Machine Learning Framework for 5G Video Streaming Networks",
    "abstract": "Quality of Experience (QoE) prediction is a critical component of modern multimedia systems, particularly for adaptive video streaming in 5G networks. Accurate QoE estimation enables intelligent resource management and supports user centric service delivery. Existing QoE prediction approaches primarily rely on limited datasets and assume uniform user perception, which restricts their applicability in heterogeneous real world environments.   This paper proposes a demographic aware machine learning framework for personalized QoE prediction. We introduce a behaviorally realistic demographic based data augmentation strategy that expands a small QoE dataset six fold by modeling varying user sensitivities to streaming impairments such as rebuffering, bitrate variation, and quality degradation. Using the augmented dataset, we evaluate a comprehensive set of classical machine learning models alongside advanced deep learning architectures, including an attention-based MLP and TabNet.   Experimental results demonstrate significant improvements in prediction accuracy across RMSE, MAE, and R metrics compared to baseline models. Among all evaluated approaches, TabNet achieves the strongest performance, benefiting from its inherent feature selection and attention mechanisms. The results confirm that demographic-aware augmentation substantially enhances QoE prediction robustness and provides a scalable direction for personalized QoE-aware intelligence in 5G video streaming networks.",
    "published": "2025-12-14T15:19:16Z",
    "authors": [
      "Syeda Zunaira Ahmed",
      "Hejab Tahira Beg",
      "Maryam Khalid"
    ],
    "categories": [
      "cs.AI",
      "cs.MM",
      "eess.IV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12735",
    "title": "Limits To (Machine) Learning",
    "abstract": "Machine learning (ML) methods are highly flexible, but their ability to approximate the true data-generating process is fundamentally constrained by finite samples. We characterize a universal lower bound, the Limits-to-Learning Gap (LLG), quantifying the unavoidable discrepancy between a model's empirical fit and the population benchmark. Recovering the true population $R^2$, therefore, requires correcting observed predictive performance by this bound. Using a broad set of variables, including excess returns, yields, credit spreads, and valuation ratios, we find that the implied LLGs are large. This indicates that standard ML approaches can substantially understate true predictability in financial data. We also derive LLG-based refinements to the classic Hansen and Jagannathan (1991) bounds, analyze implications for parameter learning in general-equilibrium settings, and show that the LLG provides a natural mechanism for generating excess volatility.",
    "published": "2025-12-14T15:18:45Z",
    "authors": [
      "Zhimin Chen",
      "Bryan Kelly",
      "Semyon Malamud"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12732",
    "title": "Ethical Risk Analysis of L2 Rollups",
    "abstract": "Layer 2 rollups improve throughput and fees, but can reintroduce risk through operator discretion and information asymmetry. We ask which operator and governance designs produce ethically problematic user risk. We adapt Ethical Risk Analysis to rollup architectures, build a role-based taxonomy of decision authority and exposure, and pair the framework with two empirical signals, a cross sectional snapshot of 129 projects from L2BEAT and a hand curated incident set covering 2022 to 2025. We analyze mechanisms that affect risks to users funds, including upgrade timing and exit windows, proposer liveness and whitelisting, forced inclusion usability, and data availability choices. We find that ethical hazards rooted in L2 components control arrangements are widespread: instant upgrades without exit windows appear in about 86 percent of projects, and proposer controls that can freeze withdrawals in about 50 percent. Reported incidents concentrate in sequencer liveness and inclusion, consistent with these dependencies. We translate these findings into ethically grounded suggestions on mitigation strategies including technical components and governance mechanisms.",
    "published": "2025-12-14T15:17:23Z",
    "authors": [
      "Georgy Ishmaev",
      "Emmanuelle Anceaume",
      "Davide Frey",
      "François Taïani"
    ],
    "categories": [
      "cs.DC",
      "cs.CY"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12731",
    "title": "Solving a Machine Learning Regression Problem Based on the Theory of Random Functions",
    "abstract": "This paper studies a machine learning regression problem as a multivariate approximation problem using the framework of the theory of random functions. An ab initio derivation of a regression method is proposed, starting from postulates of indifference. It is shown that if a probability measure on an infinite-dimensional function space possesses natural symmetries (invariance under translation, rotation, scaling, and Gaussianity), then the entire solution scheme, including the kernel form, the type of regularization, and the noise parameterization, follows analytically from these postulates. The resulting kernel coincides with a generalized polyharmonic spline; however, unlike existing approaches, it is not chosen empirically but arises as a consequence of the indifference principle. This result provides a theoretical foundation for a broad class of smoothing and interpolation methods, demonstrating their optimality in the absence of a priori information.",
    "published": "2025-12-14T15:12:18Z",
    "authors": [
      "Yuriy N. Bakhvalov"
    ],
    "categories": [
      "cs.LG",
      "math.NA"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12730",
    "title": "NL2Repo-Bench: Towards Long-Horizon Repository Generation Evaluation of Coding Agents",
    "abstract": "Recent advances in coding agents suggest rapid progress toward autonomous software development, yet existing benchmarks fail to rigorously evaluate the long-horizon capabilities required to build complete software systems. Most prior evaluations focus on localized code generation, scaffolded completion, or short-term repair tasks, leaving open the question of whether agents can sustain coherent reasoning, planning, and execution over the extended horizons demanded by real-world repository construction. To address this gap, we present NL2Repo Bench, a benchmark explicitly designed to evaluate the long-horizon repository generation ability of coding agents. Given only a single natural-language requirements document and an empty workspace, agents must autonomously design the architecture, manage dependencies, implement multi-module logic, and produce a fully installable Python library. Our experiments across state-of-the-art open- and closed-source models reveal that long-horizon repository generation remains largely unsolved: even the strongest agents achieve below 40% average test pass rates and rarely complete an entire repository correctly. Detailed analysis uncovers fundamental long-horizon failure modes, including premature termination, loss of global coherence, fragile cross-file dependencies, and inadequate planning over hundreds of interaction steps. NL2Repo Bench establishes a rigorous, verifiable testbed for measuring sustained agentic competence and highlights long-horizon reasoning as a central bottleneck for the next generation of autonomous coding agents.",
    "published": "2025-12-14T15:12:13Z",
    "authors": [
      "Jingzhe Ding",
      "Shengda Long",
      "Changxin Pu",
      "Huan Zhou",
      "Hongwan Gao",
      "Xiang Gao",
      "Chao He",
      "Yue Hou",
      "Fei Hu",
      "Zhaojian Li",
      "Weiran Shi",
      "Zaiyuan Wang",
      "Daoguang Zan",
      "Chenchen Zhang",
      "Xiaoxu Zhang",
      "Qizhi Chen",
      "Xianfu Cheng",
      "Bo Deng",
      "Qingshui Gu",
      "Kai Hua",
      "Juntao Lin",
      "Pai Liu",
      "Mingchen Li",
      "Xuanguang Pan",
      "Zifan Peng",
      "Yujia Qin",
      "Yong Shan",
      "Zhewen Tan",
      "Weihao Xie",
      "Zihan Wang",
      "Yishuo Yuan",
      "Jiayu Zhang",
      "Enduo Zhao",
      "Yunfei Zhao",
      "He Zhu",
      "Chenyang Zou",
      "Ming Ding",
      "Jianpeng Jiao",
      "Jiaheng Liu",
      "Minghao Liu",
      "Qian Liu",
      "Chongyao Tao",
      "Jian Yang",
      "Tong Yang",
      "Zhaoxiang Zhang",
      "Xinjie Chen",
      "Wenhao Huang",
      "Ge Zhang"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12729",
    "title": "RunPBA -- Runtime attestation for microcontrollers with PACBTI",
    "abstract": "The widespread adoption of embedded systems has led to their deployment in critical real-world applications, making them attractive targets for malicious actors. These devices face unique challenges in mitigating vulnerabilities due to intrinsic constraints, such as low energy consumption requirements and limited computational resources. This paper presents RunPBA, a hardware-based runtime attestation system designed to defend against control flow attacks while maintaining minimal performance overhead and adhering to strict power consumption constraints. RunPBA leverages PACBTI, a new processor extension tailored for the Arm Cortex M processor family, allowing robust protection without requiring hardware modifications, a limitation present in similar solutions. We implemented a proof-of-concept and evaluated it using two benchmark suites. Experimental results indicate that RunPBA imposes a geometric mean performance overhead of only 1% and 4.7% across the benchmarks, underscoring its efficiency and suitability for real-world deployment.",
    "published": "2025-12-14T15:09:48Z",
    "authors": [
      "André Cirne",
      "Patrícia R. Sousa",
      "João S. Resende",
      "Luís Antunes"
    ],
    "categories": [
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12719",
    "title": "Towards AI Agents Supported Research Problem Formulation",
    "abstract": "Poorly formulated research problems can compromise the practical relevance of Software Engineering studies by not reflecting the complexities of industrial practice. This vision paper explores the use of artificial intelligence agents to support SE researchers during the early stage of a research project, the formulation of the research problem. Based on the Lean Research Inception framework and using a published study on code maintainability in machine learning as a reference, we developed a descriptive evaluation of a scenario illustrating how AI agents, integrated into LRI, can support SE researchers by pre filling problem attributes, aligning stakeholder perspectives, refining research questions, simulating multiperspective assessments, and supporting decision making. The descriptive evaluation of the scenario suggests that AI agent support can enrich collaborative discussions and enhance critical reflection on the value, feasibility, and applicability of the research problem. Although the vision of integrating AI agents into LRI was perceived as promising to support the context aware and practice oriented formulation of research problems, empirical validation is needed to confirm and refine the integration of AI agents into problem formulation.",
    "published": "2025-12-14T14:44:27Z",
    "authors": [
      "Anrafel Fernandes Pereira",
      "Maria Teresa Baldassarre",
      "Daniel Mendez",
      "Marcos Kalinowski"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12718",
    "title": "Spinal Line Detection for Posture Evaluation through Train-ing-free 3D Human Body Reconstruction with 2D Depth Images",
    "abstract": "The spinal angle is an important indicator of body balance. It is important to restore the 3D shape of the human body and estimate the spine center line. Existing mul-ti-image-based body restoration methods require expensive equipment and complex pro-cedures, and single image-based body restoration methods have limitations in that it is difficult to accurately estimate the internal structure such as the spine center line due to occlusion and viewpoint limitation. This study proposes a method to compensate for the shortcomings of the multi-image-based method and to solve the limitations of the sin-gle-image method. We propose a 3D body posture analysis system that integrates depth images from four directions to restore a 3D human model and automatically estimate the spine center line. Through hierarchical matching of global and fine registration, restora-tion to noise and occlusion is performed. Also, the Adaptive Vertex Reduction is applied to maintain the resolution and shape reliability of the mesh, and the accuracy and stabil-ity of spinal angle estimation are simultaneously secured by using the Level of Detail en-semble. The proposed method achieves high-precision 3D spine registration estimation without relying on training data or complex neural network models, and the verification confirms the improvement of matching quality.",
    "published": "2025-12-14T14:43:42Z",
    "authors": [
      "Sehyun Kim",
      "Hye Jun Lee",
      "Jiwoo Lee",
      "Changgyun Kim",
      "Taemin Lee"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12716",
    "title": "CoDA: A Context-Decoupled Hierarchical Agent with Reinforcement Learning",
    "abstract": "Large Language Model (LLM) agents trained with reinforcement learning (RL) show great promise for solving complex, multi-step tasks. However, their performance is often crippled by \"Context Explosion\", where the accumulation of long text outputs overwhelms the model's context window and leads to reasoning failures. To address this, we introduce CoDA, a Context-Decoupled hierarchical Agent, a simple but effective reinforcement learning framework that decouples high-level planning from low-level execution. It employs a single, shared LLM backbone that learns to operate in two distinct, contextually isolated roles: a high-level Planner that decomposes tasks within a concise strategic context, and a low-level Executor that handles tool interactions in an ephemeral, isolated workspace. We train this unified agent end-to-end using PECO (Planner-Executor Co-Optimization), a reinforcement learning methodology that applies a trajectory-level reward to jointly optimize both roles, fostering seamless collaboration through context-dependent policy updates. Extensive experiments demonstrate that CoDA achieves significant performance improvements over state-of-the-art baselines on complex multi-hop question-answering benchmarks, and it exhibits strong robustness in long-context scenarios, maintaining stable performance while all other baselines suffer severe degradation, thus further validating the effectiveness of our hierarchical design in mitigating context overload.",
    "published": "2025-12-14T14:41:29Z",
    "authors": [
      "Xuanzhang Liu",
      "Jianglun Feng",
      "Zhuoran Zhuang",
      "Junzhe Zhao",
      "Maofei Que",
      "Jieting Li",
      "Dianlei Wang",
      "Hao Tong",
      "Ye Chen",
      "Pan Li"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12713",
    "title": "Self-Motivated Growing Neural Network for Adaptive Architecture via Local Structural Plasticity",
    "abstract": "Control policies in deep reinforcement learning are often implemented with fixed-capacity multilayer perceptrons trained by backpropagation, which lack structural plasticity and depend on global error signals. This paper introduces the Self-Motivated Growing Neural Network (SMGrNN), a controller whose topology evolves online through a local Structural Plasticity Module (SPM). The SPM monitors neuron activations and edge-wise weight update statistics over short temporal windows and uses these signals to trigger neuron insertion and pruning, while synaptic weights are updated by a standard gradient-based optimizer. This allows network capacity to be regulated during learning without manual architectural tuning.   SMGrNN is evaluated on control benchmarks via policy distillation. Compared with multilayer perceptron baselines, it achieves similar or higher returns, lower variance, and task-appropriate network sizes. Ablation studies with growth disabled and growth-only variants isolate the role of structural plasticity, showing that adaptive topology improves reward stability. The local and modular design of SPM enables future integration of a Hebbian plasticity module and spike-timing-dependent plasticity, so that SMGrNN can support both artificial and spiking neural implementations driven by local rules.",
    "published": "2025-12-14T14:31:21Z",
    "authors": [
      "Yiyang Jia",
      "Chengxu Zhou"
    ],
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12710",
    "title": "Practical Hybrid Quantum Language Models with Observable Readout on Real Hardware",
    "abstract": "Hybrid quantum-classical models represent a crucial step toward leveraging near-term quantum devices for sequential data processing. We present Quantum Recurrent Neural Networks (QRNNs) and Quantum Convolutional Neural Networks (QCNNs) as hybrid quantum language models, reporting the first empirical demonstration of generative language modeling trained and evaluated end-to-end on real quantum hardware. Our architecture combines hardware-optimized parametric quantum circuits with a lightweight classical projection layer, utilizing a multi-sample SPSA strategy to efficiently train quantum parameters despite hardware noise. To characterize the capabilities of these models, we introduce a synthetic dataset designed to isolate syntactic dependencies in a controlled, low-resource environment. Experiments on IBM Quantum processors reveal the critical trade-offs between circuit depth and trainability, demonstrating that while noise remains a significant factor, observable-based readout enables the successful learning of sequential patterns on NISQ devices. These results establish a rigorous engineering baseline for generative quantum natural language processing, validating the feasibility of training complex sequence models on current quantum hardware.",
    "published": "2025-12-14T14:22:44Z",
    "authors": [
      "Stefan Balauca",
      "Ada-Astrid Balauca",
      "Adrian Iftene"
    ],
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12708",
    "title": "Multi-Trajectory Physics-Informed Neural Networks for HJB Equations with Hard-Zero Terminal Inventory: Optimal Execution on Synthetic & SPY Data",
    "abstract": "We study optimal trade execution with a hard-zero terminal inventory constraint, modeled via Hamilton-Jacobi-Bellman (HJB) equations. Vanilla PINNs often under-enforce this constraint and produce unstable controls. We propose a Multi-Trajectory PINN (MT-PINN) that adds a rollout-based trajectory loss and propagates a terminal penalty on terminal inventory via backpropagation-through-time, directly enforcing zero terminal inventory. A lightweight lambda-curriculum is adopted to stabilize training as the state expands from a risk-neutral reduced HJB to a risk-averse HJB. On the Gatheral-Schied single-asset model, MT-PINN aligns closely with their derived closed-form solutions and concentrates terminal inventory tightly around zero while reducing errors along optimal paths. We apply MT-PINNs on SPY intraday data, matching TWAP when risk-neutral, and achieving lower exposure and competitive costs, especially in falling windows, for higher risk-aversion.",
    "published": "2025-12-14T14:20:58Z",
    "authors": [
      "Anthime Valin"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12706",
    "title": "Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning",
    "abstract": "The widespread adoption of the \"Games as a Service\" model necessitates frequent content updates, placing immense pressure on quality assurance. In response, automated game testing has been viewed as a promising solution to cope with this demanding release cadence. However, existing automated testing approaches typically create a dichotomy: code-centric methods focus on structural coverage without understanding gameplay context, while player-centric agents validate high-level intent but often fail to cover specific underlying code changes. To bridge this gap, we propose SMART (Structural Mapping for Augmented Reinforcement Testing), a novel framework that synergizes structural verification and functional validation for game update testing. SMART leverages large language models (LLMs) to interpret abstract syntax tree (AST) differences and extract functional intent, constructing a context-aware hybrid reward mechanism. This mechanism guides reinforcement learning agents to sequentially fulfill gameplay goals while adaptively exploring modified code branches. We evaluate SMART on two environments, Overcooked and Minecraft. The results demonstrate that SMART significantly outperforms state-of-the-art baselines; it achieves over 94% branch coverage of modified code, nearly double that of traditional reinforcement learning methods, while maintaining a 98% task completion rate, effectively balancing structural comprehensiveness with functional correctness.",
    "published": "2025-12-14T14:18:18Z",
    "authors": [
      "Enhong Mu",
      "Minami Yoda",
      "Yan Zhang",
      "Mingyue Zhang",
      "Yutaka Matsuno",
      "Jialong Li"
    ],
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12703",
    "title": "Robust Motion Generation using Part-level Reliable Data from Videos",
    "abstract": "Extracting human motion from large-scale web videos offers a scalable solution to the data scarcity issue in character animation. However, some human parts in many video frames cannot be seen due to off-screen captures or occlusions. It brings a dilemma: discarding the data missing any part limits scale and diversity, while retaining it compromises data quality and model performance.   To address this problem, we propose leveraging credible part-level data extracted from videos to enhance motion generation via a robust part-aware masked autoregression model. First, we decompose a human body into five parts and detect the parts clearly seen in a video frame as \"credible\". Second, the credible parts are encoded into latent tokens by our proposed part-aware variational autoencoder. Third, we propose a robust part-level masked generation model to predict masked credible parts, while ignoring those noisy parts.   In addition, we contribute K700-M, a challenging new benchmark comprising approximately 200k real-world motion sequences, for evaluation. Experimental results indicate that our method successfully outperforms baselines on both clean and noisy datasets in terms of motion quality, semantic consistency and diversity. Project page: https://boyuaner.github.io/ropar-main/",
    "published": "2025-12-14T14:15:16Z",
    "authors": [
      "Boyuan Li",
      "Sipeng Zheng",
      "Bin Cao",
      "Ruihua Song",
      "Zongqing Lu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12701",
    "title": "Efficient Vision-Language Reasoning via Adaptive Token Pruning",
    "abstract": "Real-world deployment of Vision-Language Models (VLMs) is hindered by high computational demands, as existing architectures inefficiently process all tokens uniformly. We introduce Adaptive Token Pruning (ATP), a dynamic inference mechanism that retains only the most informative tokens based on contextual relevance. ATP operates at the vision-language interface, assigning a hybrid importance score combining ViT CLS attention (intra-modal saliency) and CLIP text-image similarity (inter-modal relevance) to keep top-K tokens for the LLM. Unlike static compression, ATP adapts to each input without modifying the backbone. Proposed as a lightweight gating module, ATP is compatible with popular backbones like BLIP-2, LLaVA, and Flamingo. Preliminary evaluations across VQAv2, GQA, and COCO indicate that ATP reduces inference FLOPs by around 40% and achieves roughly 1.5x speedups in end-to-end latency with negligible accuracy loss (less than 1%). Qualitative analyses suggest ATP preserves visual grounding and enhances interpretability. Beyond efficiency, we investigate robustness under corruptions; observations suggest adaptive pruning suppresses spurious correlations, improving stability. These findings imply that resource-constrained inference and model reliability are not competing objectives. Finally, we discuss ATP's role in efficient multimodal edge computing pipelines.",
    "published": "2025-12-14T14:11:32Z",
    "authors": [
      "Xue Li",
      "Xiaonan Song",
      "Henry Hu"
    ],
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12699",
    "title": "Attributes to Support the Formulation of Practically Relevant Research Problems in Software Engineering",
    "abstract": "[Background] A well-formulated research problem is essential for achieving practical relevance in Software Engineering (SE), yet there is a lack of structured guidance in this early phase. [Aims] Our goal is to introduce and evaluate seven attributes identified in the SE literature as relevant for formulating research problems (practical problem, context, implications/impacts, practitioners, evidence, objective, and research questions) in terms of their perceived importance and completeness, and learn how they can be applied. [Method] We conducted a workshop with 42 senior SE researchers during the ISERN 2024 meeting. The seven attributes were presented using a Problem Vision board filled with a research example. Participants discussed attributes in groups, shared written feedback, and individually completed a survey assessing their importance, completeness, and suggestions for improvement. [Results] The findings confirm the importance of the seven attributes in the formulation of industry-oriented research problems. Qualitative feedback illustrated how they can be applied in practice and revealed suggestions to refine them, such as incorporating financial criteria (e.g., ROI) into implications/impacts and addressing feasibility and constraints under evidence. [Conclusion] The results reaffirm the importance of the seven attributes in supporting a reflective and context-aware problem formulation. Adapting their use to specific research contexts can help to improve the alignment between academic research and industry needs.",
    "published": "2025-12-14T14:06:25Z",
    "authors": [
      "Anrafel Fernandes Pereira",
      "Maria Teresa Baldassarre",
      "Daniel Mendez",
      "Jürgen Börstler",
      "Nauman bin Ali",
      "Rahul Mohanani",
      "Darja Smite",
      "Stefan Biffl",
      "Rogardt Heldal",
      "Davide Falessi",
      "Daniel Graziotin",
      "Marcos Kalinowski"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12694",
    "title": "Hybrid Retrieval-Augmented Generation for Robust Multilingual Document Question Answering",
    "abstract": "Large-scale digitization initiatives have unlocked massive collections of historical newspapers, yet effective computational access remains hindered by OCR corruption, multilingual orthographic variation, and temporal language drift. We develop and evaluate a multilingual Retrieval-Augmented Generation pipeline specifically designed for question answering on noisy historical documents. Our approach integrates: (i) semantic query expansion and multi-query fusion using Reciprocal Rank Fusion to improve retrieval robustness against vocabulary mismatch; (ii) a carefully engineered generation prompt that enforces strict grounding in retrieved evidence and explicit abstention when evidence is insufficient; and (iii) a modular architecture enabling systematic component evaluation. We conduct comprehensive ablation studies on Named Entity Recognition and embedding model selection, demonstrating the importance of syntactic coherence in entity extraction and balanced performance-efficiency trade-offs in dense retrieval. Our end-to-end evaluation framework shows that the pipeline generates faithful answers for well-supported queries while correctly abstaining from unanswerable questions. The hybrid retrieval strategy improves recall stability, particularly benefiting from RRF's ability to smooth performance variance across query formulations. We release our code and configurations at https://anonymous.4open.science/r/RAGs-C5AE/, providing a reproducible foundation for robust historical document question answering.",
    "published": "2025-12-14T13:57:05Z",
    "authors": [
      "Anthony Mudet",
      "Souhail Bakkali"
    ],
    "categories": [
      "cs.DL",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12693",
    "title": "Co-Exploration and Co-Exploitation via Shared Structure in Multi-Task Bandits",
    "abstract": "We propose a novel Bayesian framework for efficient exploration in contextual multi-task multi-armed bandit settings, where the context is only observed partially and dependencies between reward distributions are induced by latent context variables. In order to exploit these structural dependencies, our approach integrates observations across all tasks and learns a global joint distribution, while still allowing personalised inference for new tasks. In this regard, we identify two key sources of epistemic uncertainty, namely structural uncertainty in the latent reward dependencies across arms and tasks, and user-specific uncertainty due to incomplete context and limited interaction history. To put our method into practice, we represent the joint distribution over tasks and rewards using a particle-based approximation of a log-density Gaussian process. This representation enables flexible, data-driven discovery of both inter-arm and inter-task dependencies without prior assumptions on the latent variables. Empirically, we demonstrate that our method outperforms baselines such as hierarchical model bandits, especially in settings with model misspecification or complex latent heterogeneity.",
    "published": "2025-12-14T13:56:58Z",
    "authors": [
      "Sumantrak Mukherjee",
      "Serafima Lebedeva",
      "Valentin Margraf",
      "Jonas Hanselle",
      "Kanta Yamaoka",
      "Viktor Bengs",
      "Stefan Konigorski",
      "Eyke Hüllermeier",
      "Sebastian Josef Vollmer"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12692",
    "title": "WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment",
    "abstract": "LLM-based agents often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-where a single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. Tree-search methods provide a principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actions-limitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, a tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates a best-first search strategy that ranks actions by both reward estimates and safety considerations, along with a robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates a high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves a state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution.",
    "published": "2025-12-14T13:56:54Z",
    "authors": [
      "Mahir Labib Dihan",
      "Tanzima Hashem",
      "Mohammed Eunus Ali",
      "Md Rizwan Parvez"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12690",
    "title": "Reassessing the Role of Supervised Fine-Tuning: An Empirical Study in VLM Reasoning",
    "abstract": "Recent advances in vision-language models (VLMs) reasoning have been largely attributed to the rise of reinforcement Learning (RL), which has shifted the community's focus away from the supervised fine-tuning (SFT) paradigm. Many studies suggest that introducing the SFT stage not only fails to improve reasoning ability but may also negatively impact model training. In this study, we revisit this RL-centric belief through a systematic and controlled comparison of SFT and RL on VLM Reasoning. Using identical data sources, we find that the relative effectiveness of SFT and RL is conditional and strongly influenced by model capacity, data scale, and data distribution. Contrary to common assumptions, our findings show that SFT plays a crucial role across several scenarios: (1) Effectiveness for weaker models. SFT more reliably elicits reasoning capabilities in smaller or weaker VLMs. (2) Data efficiency. SFT with only 2K achieves comparable or better reasoning performance to RL with 20K. (3) Cross-modal transferability. SFT demonstrates stronger generalization across modalities. Moreover, we identify a pervasive issue of deceptive rewards, where higher rewards fail to correlate with better reasoning accuracy in RL. These results challenge the prevailing \"RL over SFT\" narrative. They highlight that the role of SFT may have been underestimated and support a more balanced post-training pipeline in which SFT and RL function as complementary components.",
    "published": "2025-12-14T13:46:42Z",
    "authors": [
      "Yongcan Yu",
      "Lingxiao He",
      "Shuo Lu",
      "Lijun Sheng",
      "Yinuo Xu",
      "Yanbo Wang",
      "Kuangpu Guo",
      "Jianjie Cheng",
      "Meng Wang",
      "Qianlong Xie",
      "Xingxing Wang",
      "Dapeng Hu",
      "Jian Liang"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12688",
    "title": "Theoretical Foundations of Prompt Engineering: From Heuristics to Expressivity",
    "abstract": "Prompts can switch a model's behavior even when the weights are fixed, yet this phenomenon is rarely treated as a clean theoretical object rather than a heuristic. We study the family of functions obtainable by holding a Transformer backbone fixed as an executor and varying only the prompt. Our core idea is to view the prompt as an externally injected program and to construct a simplified Transformer that interprets it to implement different computations. The construction exposes a mechanism-level decomposition: attention performs selective routing from prompt memory, the FFN performs local arithmetic conditioned on retrieved fragments, and depth-wise stacking composes these local updates into a multi-step computation. Under this viewpoint, we prove a constructive existential result showing that a single fixed backbone can approximate a broad class of target behaviors via prompts alone. The framework provides a unified starting point for formalizing trade-offs under prompt length/precision constraints and for studying structural limits of prompt-based switching, while remaining distinct from empirical claims about pretrained LLMs.",
    "published": "2025-12-14T13:42:20Z",
    "authors": [
      "Dongseok Kim",
      "Hyoungsun Choi",
      "Mohamed Jismy Aashik Rasool",
      "Gisung Oh"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12686",
    "title": "Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI",
    "abstract": "Agentic memory is emerging as a key enabler for large language models (LLM) to maintain continuity, personalization, and long-term context in extended user interactions, critical capabilities for deploying LLMs as truly interactive and adaptive agents. Agentic memory refers to the memory that provides an LLM with agent-like persistence: the ability to retain and act upon information across conversations, similar to how a human would. We present Memoria, a modular memory framework that augments LLM-based conversational systems with persistent, interpretable, and context-rich memory. Memoria integrates two complementary components: dynamic session-level summarization and a weighted knowledge graph (KG)-based user modelling engine that incrementally captures user traits, preferences, and behavioral patterns as structured entities and relationships. This hybrid architecture enables both short-term dialogue coherence and long-term personalization while operating within the token constraints of modern LLMs. We demonstrate how Memoria enables scalable, personalized conversational artificial intelligence (AI) by bridging the gap between stateless LLM interfaces and agentic memory systems, offering a practical solution for industry applications requiring adaptive and evolving user experiences.",
    "published": "2025-12-14T13:38:06Z",
    "authors": [
      "Samarth Sarin",
      "Lovepreet Singh",
      "Bhaskarjit Sarmah",
      "Dhagash Mehta"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12683",
    "title": "Quantum Implicit Neural Representations for 3D Scene Reconstruction and Novel View Synthesis",
    "abstract": "Implicit neural representations (INRs) have become a powerful paradigm for continuous signal modeling and 3D scene reconstruction, yet classical networks suffer from a well-known spectral bias that limits their ability to capture high-frequency details. Quantum Implicit Representation Networks (QIREN) mitigate this limitation by employing parameterized quantum circuits with inherent Fourier structures, enabling compact and expressive frequency modeling beyond classical MLPs. In this paper, we present Quantum Neural Radiance Fields (Q-NeRF), the first hybrid quantum-classical framework for neural radiance field rendering. Q-NeRF integrates QIREN modules into the Nerfacto backbone, preserving its efficient sampling, pose refinement, and volumetric rendering strategies while replacing selected density and radiance prediction components with quantum-enhanced counterparts. We systematically evaluate three hybrid configurations on standard multi-view indoor datasets, comparing them to classical baselines using PSNR, SSIM, and LPIPS metrics. Results show that hybrid quantum-classical models achieve competitive reconstruction quality under limited computational resources, with quantum modules particularly effective in representing fine-scale, view-dependent appearance. Although current implementations rely on quantum circuit simulators constrained to few-qubit regimes, the results highlight the potential of quantum encodings to alleviate spectral bias in implicit representations. Q-NeRF provides a foundational step toward scalable quantum-enabled 3D scene reconstruction and a baseline for future quantum neural rendering research.",
    "published": "2025-12-14T13:24:11Z",
    "authors": [
      "Yeray Cordero",
      "Paula García-Molina",
      "Fernando Vilariño"
    ],
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12678",
    "title": "$β$-CLIP: Text-Conditioned Contrastive Learning for Multi-Granular Vision-Language Alignment",
    "abstract": "CLIP achieves strong zero-shot image-text retrieval by aligning global vision and text representations, yet it falls behind on fine-grained tasks even when fine-tuned on long, detailed captions. In this work, we propose $β$-CLIP, a multi-granular text-conditioned contrastive learning framework designed to achieve hierarchical alignment between multiple textual granularities-from full captions to sentences and phrases-and their corresponding visual regions. For each level of granularity, $β$-CLIP utilizes cross-attention to dynamically pool image patches, producing contextualized visual embeddings. To address the semantic overlap inherent in this hierarchy, we introduce the $β$-Contextualized Contrastive Alignment Loss ($β$-CAL). This objective parameterizes the trade-off between strict query-specific matching and relaxed intra-image contextualization, supporting both soft Cross-Entropy and hard Binary Cross-Entropy formulations. Through extensive experiments, we demonstrate that $β$-CLIP significantly improves dense alignment: achieving 91.8% T2I 92.3% I2T at R@1 on Urban1K and 30.9% on FG-OVD (Hard), setting state-of-the-art among methods trained without hard negatives. $β$-CLIP establishes a robust, adaptive baseline for dense vision-language correspondence. The code and models are released at https://github.com/fzohra/B-CLIP.",
    "published": "2025-12-14T13:03:20Z",
    "authors": [
      "Fatimah Zohra",
      "Chen Zhao",
      "Hani Itani",
      "Bernard Ghanem"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12677",
    "title": "Fine-Tuning Causal LLMs for Text Classification: Embedding-Based vs. Instruction-Based Approaches",
    "abstract": "We explore efficient strategies to fine-tune decoder-only Large Language Models (LLMs) for downstream text classification under resource constraints. Two approaches are investigated: (1) attaching a classification head to a pre-trained causal LLM and fine-tuning on the task (using the LLM's final token embedding as a sequence representation), and (2) instruction-tuning the LLM in a prompt->response format for classification. To enable single-GPU fine-tuning of models up to 8B parameters, we combine 4-bit model quantization with Low-Rank Adaptation (LoRA) for parameter-efficient training. Experiments on two datasets - a proprietary single-label dataset and the public WIPO-Alpha patent dataset (extreme multi-label classification) - show that the embedding-based method significantly outperforms the instruction-tuned method in F1-score, and is very competitive with - even surpassing - fine-tuned domain-specific models (e.g. BERT) on the same tasks. These results demonstrate that directly leveraging the internal representations of causal LLMs, along with efficient fine-tuning techniques, yields impressive classification performance under limited computational resources. We discuss the advantages of each approach while outlining practical guidelines and future directions for optimizing LLM fine-tuning in classification scenarios.",
    "published": "2025-12-14T13:02:06Z",
    "authors": [
      "Amirhossein Yousefiramandi",
      "Ciaran Cooney"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12676",
    "title": "Robust Variational Bayes by Min-Max Median Aggregation",
    "abstract": "We propose a robust and scalable variational Bayes (VB) framework designed to effectively handle contamination and outliers in dataset. Our approach partitions the data into $m$ disjoint subsets and formulates a joint optimization problem based on robust aggregation principles. A key insight is that the full posterior distribution is equivalent to the minimizer of the mean Kullback-Leibler (KL) divergence from the $m$-powered local posterior distributions. To enhance robustness, we replace the mean KL divergence with a min-max median formulation. The min-max formulation not only ensures consistency between the KL minimizer and the Evidence Lower Bound (ELBO) maximizer but also facilitates the establishment of improved statistical rates for the mean of variational posterior. We observe a notable discrepancy in the $m$-powered marginal log likelihood function contingent on the presence of local latent variables. To address this, we treat these two scenarios separately to guarantee the consistency of the aggregated variational posterior. Specifically, when local latent variables are present, we introduce an aggregate-and-rescale strategy. Theoretically, we provide a non-asymptotic analysis of our proposed posterior, incorporating a refined analysis of Bernstein-von Mises (BvM) theorem to accommodate a diverging number of subsets $m$. Our findings indicate that the two-stage approach yields a smaller approximation error compared to directly aggregating the $m$-powered local posteriors. Furthermore, we establish a nearly optimal statistical rate for the mean of the proposed posterior, advancing existing theories related to min-max median estimators. The efficacy of our method is demonstrated through extensive simulation studies.",
    "published": "2025-12-14T13:02:00Z",
    "authors": [
      "Jiawei Yan",
      "Ju Liu",
      "Weidong Liu",
      "Jiyuan Tu"
    ],
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12675",
    "title": "Scone: Bridging Composition and Distinction in Subject-Driven Image Generation via Unified Understanding-Generation Modeling",
    "abstract": "Subject-driven image generation has advanced from single- to multi-subject composition, while neglecting distinction, the ability to identify and generate the correct subject when inputs contain multiple candidates. This limitation restricts effectiveness in complex, realistic visual settings. We propose Scone, a unified understanding-generation method that integrates composition and distinction. Scone enables the understanding expert to act as a semantic bridge, conveying semantic information and guiding the generation expert to preserve subject identity while minimizing interference. A two-stage training scheme first learns composition, then enhances distinction through semantic alignment and attention-based masking. We also introduce SconeEval, a benchmark for evaluating both composition and distinction across diverse scenarios. Experiments demonstrate that Scone outperforms existing open-source models in composition and distinction tasks on two benchmarks. Our model, benchmark, and training data are available at: https://github.com/Ryann-Ran/Scone.",
    "published": "2025-12-14T12:58:19Z",
    "authors": [
      "Yuran Wang",
      "Bohan Zeng",
      "Chengzhuo Tong",
      "Wenxuan Liu",
      "Yang Shi",
      "Xiaochen Ma",
      "Hao Liang",
      "Yuanxing Zhang",
      "Wentao Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12673",
    "title": "Progressive Conditioned Scale-Shift Recalibration of Self-Attention for Online Test-time Adaptation",
    "abstract": "Online test-time adaptation aims to dynamically adjust a network model in real-time based on sequential input samples during the inference stage. In this work, we find that, when applying a transformer network model to a new target domain, the Query, Key, and Value features of its self-attention module often change significantly from those in the source domain, leading to substantial performance degradation of the transformer model. To address this important issue, we propose to develop a new approach to progressively recalibrate the self-attention at each layer using a local linear transform parameterized by conditioned scale and shift factors. We consider the online model adaptation from the source domain to the target domain as a progressive domain shift separation process. At each transformer network layer, we learn a Domain Separation Network to extract the domain shift feature, which is used to predict the scale and shift parameters for self-attention recalibration using a Factor Generator Network. These two lightweight networks are adapted online during inference. Experimental results on benchmark datasets demonstrate that the proposed progressive conditioned scale-shift recalibration (PCSR) method is able to significantly improve the online test-time domain adaptation performance by a large margin of up to 3.9\\% in classification accuracy on the ImageNet-C dataset.",
    "published": "2025-12-14T12:56:02Z",
    "authors": [
      "Yushun Tang",
      "Ziqiong Liu",
      "Jiyuan Jia",
      "Yi Zhang",
      "Zhihai He"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12671",
    "title": "On Approaches to Building Surrogate ODE Models for Diffusion Bridges",
    "abstract": "Diffusion and Schrödinger Bridge models have established state-of-the-art performance in generative modeling but are often hampered by significant computational costs and complex training procedures. While continuous-time bridges promise faster sampling, overparameterized neural networks describe their optimal dynamics, and the underlying stochastic differential equations can be difficult to integrate efficiently. This work introduces a novel paradigm that uses surrogate models to create simpler, faster, and more flexible approximations of these dynamics. We propose two specific algorithms: SINDy Flow Matching (SINDy-FM), which leverages sparse regression to identify interpretable, symbolic differential equations from data, and a Neural-ODE reformulation of the Schrödinger Bridge (DSBM-NeuralODE) for flexible continuous-time parameterization. Our experiments on Gaussian transport tasks and MNIST latent translation demonstrate that these surrogates achieve competitive performance while offering dramatic improvements in efficiency and interpretability. The symbolic SINDy-FM models, in particular, reduce parameter counts by several orders of magnitude and enable near-instantaneous inference, paving the way for a new class of tractable and high-performing bridge models for practical deployment.",
    "published": "2025-12-14T12:49:38Z",
    "authors": [
      "Maria Khilchuk",
      "Vladimir Latypov",
      "Pavel Kleshchev",
      "Alexander Hvatov"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12669",
    "title": "DynaGen: Unifying Temporal Knowledge Graph Reasoning with Dynamic Subgraphs and Generative Regularization",
    "abstract": "Temporal Knowledge Graph Reasoning (TKGR) aims to complete missing factual elements along the timeline. Depending on the temporal position of the query, the task is categorized into interpolation and extrapolation. Existing interpolation methods typically embed temporal information into individual facts to complete missing historical knowledge, while extrapolation techniques often leverage sequence models over graph snapshots to identify recurring patterns for future event prediction. These methods face two critical challenges: limited contextual modeling in interpolation and cognitive generalization bias in extrapolation. To address these, we propose a unified method for TKGR, dubbed DynaGen. For interpolation, DynaGen dynamically constructs entity-centric subgraphs and processes them with a synergistic dual-branch GNN encoder to capture evolving structural context. For extrapolation, it applies a conditional diffusion process, which forces the model to learn underlying evolutionary principles rather than just superficial patterns, enhancing its ability to predict unseen future events. Extensive experiments on six benchmark datasets show DynaGen achieves state-of-the-art performance. On average, compared to the second-best models, DynaGen improves the Mean Reciprocal Rank (MRR) score by 2.61 points for interpolation and 1.45 points for extrapolation.",
    "published": "2025-12-14T12:46:07Z",
    "authors": [
      "Jiawei Shen",
      "Jia Zhu",
      "Hanghui Guo",
      "Weijie Shi",
      "Guoqing Ma",
      "Yidan Liang",
      "Jingjiang Liu",
      "Hao Chen",
      "Shimin Di"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12667",
    "title": "Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning",
    "abstract": "The proliferation of synthetic facial imagery has intensified the need for robust Open-World DeepFake Attribution (OW-DFA), which aims to attribute both known and unknown forgeries using labeled data for known types and unlabeled data containing a mixture of known and novel types. However, existing OW-DFA methods face two critical limitations: 1) A confidence skew that leads to unreliable pseudo-labels for novel forgeries, resulting in biased training. 2) An unrealistic assumption that the number of unknown forgery types is known *a priori*. To address these challenges, we propose a Confidence-Aware Asymmetric Learning (CAL) framework, which adaptively balances model confidence across known and novel forgery types. CAL mainly consists of two components: Confidence-Aware Consistency Regularization (CCR) and Asymmetric Confidence Reinforcement (ACR). CCR mitigates pseudo-label bias by dynamically scaling sample losses based on normalized confidence, gradually shifting the training focus from high- to low-confidence samples. ACR complements this by separately calibrating confidence for known and novel classes through selective learning on high-confidence samples, guided by their confidence gap. Together, CCR and ACR form a mutually reinforcing loop that significantly improves the model's OW-DFA performance. Moreover, we introduce a Dynamic Prototype Pruning (DPP) strategy that automatically estimates the number of novel forgery types in a coarse-to-fine manner, removing the need for unrealistic prior assumptions and enhancing the scalability of our methods to real-world OW-DFA scenarios. Extensive experiments on the standard OW-DFA benchmark and a newly extended benchmark incorporating advanced manipulations demonstrate that CAL consistently outperforms previous methods, achieving new state-of-the-art performance on both known and novel forgery attribution.",
    "published": "2025-12-14T12:31:28Z",
    "authors": [
      "Haiyang Zheng",
      "Nan Pu",
      "Wenjing Li",
      "Teng Long",
      "Nicu Sebe",
      "Zhun Zhong"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12664",
    "title": "InteracTalker: Prompt-Based Human-Object Interaction with Co-Speech Gesture Generation",
    "abstract": "Generating realistic human motions that naturally respond to both spoken language and physical objects is crucial for interactive digital experiences. Current methods, however, address speech-driven gestures or object interactions independently, limiting real-world applicability due to a lack of integrated, comprehensive datasets. To overcome this, we introduce InteracTalker, a novel framework that seamlessly integrates prompt-based object-aware interactions with co-speech gesture generation. We achieve this by employing a multi-stage training process to learn a unified motion, speech, and prompt embedding space. To support this, we curate a rich human-object interaction dataset, formed by augmenting an existing text-to-motion dataset with detailed object interaction annotations. Our framework utilizes a Generalized Motion Adaptation Module that enables independent training, adapting to the corresponding motion condition, which is then dynamically combined during inference. To address the imbalance between heterogeneous conditioning signals, we propose an adaptive fusion strategy, which dynamically reweights the conditioning signals during diffusion sampling. InteracTalker successfully unifies these previously separate tasks, outperforming prior methods in both co-speech gesture generation and object-interaction synthesis, outperforming gesture-focused diffusion methods, yielding highly realistic, object-aware full-body motions with enhanced realism, flexibility, and control.",
    "published": "2025-12-14T12:29:49Z",
    "authors": [
      "Sreehari Rajan",
      "Kunal Bhosikar",
      "Charu Sharma"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12663",
    "title": "PerNodeDrop: A Method Balancing Specialized Subnets and Regularization in Deep Neural Networks",
    "abstract": "Deep neural networks possess strong representational capacity yet remain vulnerable to overfitting, primarily because neurons tend to co-adapt in ways that, while capturing complex and fine-grained feature interactions, also reinforce spurious and non-generalizable patterns that inflate training performance but reduce reliability on unseen data. Noise-based regularizers such as Dropout and DropConnect address this issue by injecting stochastic perturbations during training, but the noise they apply is typically uniform across a layer or across a batch of samples, which can suppress both harmful and beneficial co-adaptation.   This work introduces PerNodeDrop, a lightweight stochastic regularization method. It applies per-sample, per-node perturbations to break the uniformity of the noise injected by existing techniques, thereby allowing each node to experience input-specific variability. Hence, PerNodeDrop preserves useful co-adaptation while applying regularization. This narrows the gap between training and validation performance and improves reliability on unseen data, as evident from the experiments.   Although superficially similar to DropConnect, PerNodeDrop operates at the sample level. It drops weights at the sample level, not the batch level. An expected-loss analysis formalizes how its perturbations attenuate excessive co-adaptation while retaining predictive interactions. Empirical evaluations on vision, text, and audio benchmarks indicate improved generalization relative to the standard noise-based regularizer.",
    "published": "2025-12-14T12:26:56Z",
    "authors": [
      "Gelesh G Omathil",
      "Sreeja CS"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12662",
    "title": "Anatomy-Guided Representation Learning Using a Transformer-Based Network for Thyroid Nodule Segmentation in Ultrasound Images",
    "abstract": "Accurate thyroid nodule segmentation in ultrasound images is critical for diagnosis and treatment planning. However, ambiguous boundaries between nodules and surrounding tissues, size variations, and the scarcity of annotated ultrasound data pose significant challenges for automated segmentation. Existing deep learning models struggle to incorporate contextual information from the thyroid gland and generalize effectively across diverse cases. To address these challenges, we propose SSMT-Net, a Semi-Supervised Multi-Task Transformer-based Network that leverages unlabeled data to enhance Transformer-centric encoder feature extraction capability in an initial unsupervised phase. In the supervised phase, the model jointly optimizes nodule segmentation, gland segmentation, and nodule size estimation, integrating both local and global contextual features. Extensive evaluations on the TN3K and DDTI datasets demonstrate that SSMT-Net outperforms state-of-the-art methods, with higher accuracy and robustness, indicating its potential for real-world clinical applications.",
    "published": "2025-12-14T12:20:20Z",
    "authors": [
      "Muhammad Umar Farooq",
      "Abd Ur Rehman",
      "Azka Rehman",
      "Muhammad Usman",
      "Dong-Kyu Chae",
      "Junaid Qadir"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12658",
    "title": "CogDoc: Towards Unified thinking in Documents",
    "abstract": "Current document reasoning paradigms are constrained by a fundamental trade-off between scalability (processing long-context documents) and fidelity (capturing fine-grained, multimodal details). To bridge this gap, we propose CogDoc, a unified coarse-to-fine thinking framework that mimics human cognitive processes: a low-resolution \"Fast Reading\" phase for scalable information localization,followed by a high-resolution \"Focused Thinking\" phase for deep reasoning. We conduct a rigorous investigation into post-training strategies for the unified thinking framework, demonstrating that a Direct Reinforcement Learning (RL) approach outperforms RL with Supervised Fine-Tuning (SFT) initialization. Specifically, we find that direct RL avoids the \"policy conflict\" observed in SFT. Empirically, our 7B model achieves state-of-the-art performance within its parameter class, notably surpassing significantly larger proprietary models (e.g., GPT-4o) on challenging, visually rich document benchmarks.",
    "published": "2025-12-14T12:14:17Z",
    "authors": [
      "Qixin Xu",
      "Haozhe Wang",
      "Che Liu",
      "Fangzhen Lin",
      "Wenhu Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12657",
    "title": "Cross-modal Fundus Image Registration under Large FoV Disparity",
    "abstract": "Previous work on cross-modal fundus image registration (CMFIR) assumes small cross-modal Field-of-View (FoV) disparity. By contrast, this paper is targeted at a more challenging scenario with large FoV disparity, to which directly applying current methods fails. We propose Crop and Alignment for cross-modal fundus image Registration(CARe), a very simple yet effective method. Specifically, given an OCTA with smaller FoV as a source image and a wide-field color fundus photograph (wfCFP) as a target image, our Crop operation exploits the physiological structure of the retina to crop from the target image a sub-image with its FoV roughly aligned with that of the source. This operation allows us to re-purpose the previous small-FoV-disparity oriented methods for subsequent image registration. Moreover, we improve spatial transformation by a double-fitting based Alignment module that utilizes the classical RANSAC algorithm and polynomial-based coordinate fitting in a sequential manner. Extensive experiments on a newly developed test set of 60 OCTA-wfCFP pairs verify the viability of CARe for CMFIR.",
    "published": "2025-12-14T12:10:37Z",
    "authors": [
      "Hongyang Li",
      "Junyi Tao",
      "Qijie Wei",
      "Ningzhi Yang",
      "Meng Wang",
      "Weihong Yu",
      "Xirong Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12654",
    "title": "Modeling Authorial Style in Urdu Novels Using Character Interaction Graphs and Graph Neural Networks",
    "abstract": "Authorship analysis has traditionally focused on lexical and stylistic cues within text, while higher-level narrative structure remains underexplored, particularly for low-resource languages such as Urdu. This work proposes a graph-based framework that models Urdu novels as character interaction networks to examine whether authorial style can be inferred from narrative structure alone. Each novel is represented as a graph where nodes correspond to characters and edges denote their co-occurrence within narrative proximity. We systematically compare multiple graph representations, including global structural features, node-level semantic summaries, unsupervised graph embeddings, and supervised graph neural networks. Experiments on a dataset of 52 Urdu novels written by seven authors show that learned graph representations substantially outperform hand-crafted and unsupervised baselines, achieving up to 0.857 accuracy under a strict author-aware evaluation protocol.",
    "published": "2025-12-14T11:59:16Z",
    "authors": [
      "Hassan Mujtaba",
      "Hamza Naveed",
      "Hanzlah Munir"
    ],
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12652",
    "title": "Value-Aware Multiagent Systems",
    "abstract": "This paper introduces the concept of value awareness in AI, which goes beyond the traditional value-alignment problem. Our definition of value awareness presents us with a concise and simplified roadmap for engineering value-aware AI. The roadmap is structured around three core pillars: (1) learning and representing human values using formal semantics, (2) ensuring the value alignment of both individual agents and multiagent systems, and (3) providing value-based explainability on behaviour. The paper presents a selection of our ongoing work on some of these topics, along with applications to real-life domains.",
    "published": "2025-12-14T11:53:36Z",
    "authors": [
      "Nardine Osman"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12650",
    "title": "A Systematic Analysis of Higher Education on Software Engineering in the Netherlands",
    "abstract": "Software engineering educators strive to continuously improve their courses and programs. Understanding the current state of practice of software engineering higher education can empower educators to critically assess their courses, fine-tune them by benchmarking against observed practices, and ultimately enhance their curricula. In this study, we aim to provide an encompassing analysis of higher education on software engineering by considering the higher educational offering of an entire European country, namely the Netherlands. We leverage a crowd-sourced analysis process by considering 10 Dutch universities and 207 university courses. The courses are analysed via knowledge areas adopted from the SWEBOK. The mapping process is refined via homogenisation and internal consistency improvement phases, and is followed by a data analysis phase. Given its fundamental nature, Construction and Programming is the most covered knowledge area at Bachelor level. Other knowledge areas are equally covered at Bachelor and Master level (e.g., software engineering models), while more advanced ones are almost exclusively covered at Master level. We identify three clusters of tightly coupled knowledge areas: (i) requirements, architecture, and design, (ii) testing, verification, and security, and (iii) process-oriented and DevOps topics. Dutch universities generally cover all knowledge areas uniformly, with minor deviations reflecting institutional research strengths. Our results highlight correlations among key knowledge areas and their potential for enhancing integrated learning. We also identify underrepresented areas, such as software engineering economics, which educators may consider including in curricula. We invite researchers to use our research method in their own geographical region, in order to contrast software engineering education programs across the globe.",
    "published": "2025-12-14T11:37:16Z",
    "authors": [
      "Bastiaan Heeren",
      "Fabiano Dalpiaz",
      "Mazyar Seraj",
      "Roberto Verdecchia",
      "Vadim Zaytsev"
    ],
    "categories": [
      "cs.SE"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12643",
    "title": "LexRel: Benchmarking Legal Relation Extraction for Chinese Civil Cases",
    "abstract": "Legal relations form a highly consequential analytical framework of civil law system, serving as a crucial foundation for resolving disputes and realizing values of the rule of law in judicial practice. However, legal relations in Chinese civil cases remain underexplored in the field of legal artificial intelligence (legal AI), largely due to the absence of comprehensive schemas. In this work, we firstly introduce a comprehensive schema, which contains a hierarchical taxonomy and definitions of arguments, for AI systems to capture legal relations in Chinese civil cases. Based on this schema, we then formulate legal relation extraction task and present LexRel, an expert-annotated benchmark for legal relation extraction in Chinese civil law. We use LexRel to evaluate state-of-the-art large language models (LLMs) on legal relation extractions, showing that current LLMs exhibit significant limitations in accurately identifying civil legal relations. Furthermore, we demonstrate that incorporating legal relations information leads to consistent performance gains on other downstream legal AI tasks.",
    "published": "2025-12-14T11:16:39Z",
    "authors": [
      "Yida Cai",
      "Ranjuexiao Hu",
      "Huiyuan Xie",
      "Chenyang Li",
      "Yun Liu",
      "Yuxiao Ye",
      "Zhenghao Liu",
      "Weixing Shen",
      "Zhiyuan Liu"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12642",
    "title": "Torch Geometric Pool: the Pytorch library for pooling in Graph Neural Networks",
    "abstract": "We introduce Torch Geometric Pool (tgp), a library for hierarchical pooling in Graph Neural Networks. Built upon Pytorch Geometric, Torch Geometric Pool (tgp) provides a wide variety of pooling operators, unified under a consistent API and a modular design. The library emphasizes usability and extensibility, and includes features like precomputed pooling, which significantly accelerate training for a class of operators. In this paper, we present tgp's structure and present an extensive benchmark. The latter showcases the library's features and systematically compares the performance of the implemented graph-pooling methods in different downstream tasks. The results, showing that the choice of the optimal pooling operator depends on tasks and data at hand, support the need for a library that enables fast prototyping.",
    "published": "2025-12-14T11:15:09Z",
    "authors": [
      "Filippo Maria Bianchi",
      "Carlo Abate",
      "Ivan Marisca"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12641",
    "title": "Which Pieces Does Unigram Tokenization Really Need?",
    "abstract": "The Unigram tokenization algorithm offers a probabilistic alternative to the greedy heuristics of Byte-Pair Encoding. Despite its theoretical elegance, its implementation in practice is complex, limiting its adoption to the SentencePiece package and adapters thereof. We bridge this gap between theory and practice by providing a clear guide to implementation and parameter choices. We also identify a simpler algorithm that accepts slightly higher training loss in exchange for improved compression.",
    "published": "2025-12-14T11:13:49Z",
    "authors": [
      "Sander Land",
      "Yuval Pinter"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12634",
    "title": "Modular and Multi-Path-Aware Offline Benchmarking for Mobile GUI Agents",
    "abstract": "Mobile GUI Agents, AI agents capable of interacting with mobile applications on behalf of users, have the potential to transform human computer interaction. However, current evaluation practices for GUI agents face two fundamental limitations. First, they either rely on single path offline benchmarks or online live benchmarks. Offline benchmarks using static, single path annotated datasets unfairly penalize valid alternative actions, while online benchmarks suffer from poor scalability and reproducibility due to the dynamic and unpredictable nature of live evaluation. Second, existing benchmarks treat agents as monolithic black boxes, overlooking the contributions of individual components, which often leads to unfair comparisons or obscures key performance bottlenecks. To address these limitations, we present MobiBench, the first modular and multi path aware offline benchmarking framework for mobile GUI agents that enables high fidelity, scalable, and reproducible evaluation entirely in offline settings. Our experiments demonstrate that MobiBench achieves 94.72 percent agreement with human evaluators, on par with carefully engineered online benchmarks, while preserving the scalability and reproducibility of static offline benchmarks. Furthermore, our comprehensive module level analysis uncovers several key insights, including a systematic evaluation of diverse techniques used in mobile GUI agents, optimal module configurations across model scales, the inherent limitations of current LFMs, and actionable guidelines for designing more capable and cost efficient mobile agents.",
    "published": "2025-12-14T10:41:39Z",
    "authors": [
      "Youngmin Im",
      "Byeongung Jo",
      "Jaeyoung Wi",
      "Seungwoo Baek",
      "Tae Hoon Min",
      "Joo Hyung Lee",
      "Sangeun Oh",
      "Insik Shin",
      "Sunjae Lee"
    ],
    "categories": [
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12633",
    "title": "DiG: Differential Grounding for Enhancing Fine-Grained Perception in Multimodal Large Language Model",
    "abstract": "Multimodal Large Language Models have achieved impressive performance on a variety of vision-language tasks, yet their fine-grained visual perception and precise spatial reasoning remain limited. In this work, we introduce DiG (Differential Grounding), a novel proxy task framework where MLLMs learn fine-grained perception by identifying and localizing all differences between similar image pairs without prior knowledge of their number. To support scalable training, we develop an automated 3D rendering-based data generation pipeline that produces high-quality paired images with fully controllable discrepancies. To address the sparsity of difference signals, we further employ curriculum learning that progressively increases complexity from single to multiple differences, enabling stable optimization. Extensive experiments demonstrate that DiG significantly improves model performance across a variety of visual perception benchmarks and that the learned fine-grained perception skills transfer effectively to standard downstream tasks, including RefCOCO, RefCOCO+, RefCOCOg, and general multimodal perception benchmarks. Our results highlight differential grounding as a scalable and robust approach for advancing fine-grained visual reasoning in MLLMs.",
    "published": "2025-12-14T10:40:27Z",
    "authors": [
      "Zhou Tao",
      "Shida Wang",
      "Yongxiang Hua",
      "Haoyu Cao",
      "Linli Xu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12630",
    "title": "ORIBA: Exploring LLM-Driven Role-Play Chatbot as a Creativity Support Tool for Original Character Artists",
    "abstract": "Recent advances in Generative AI (GAI) have led to new opportunities for creativity support. However, this technology has raised ethical concerns in the visual artists community. This paper explores how GAI can assist visual artists in developing original characters (OCs) while respecting their creative agency. We present ORIBA, an AI chatbot leveraging large language models (LLMs) to enable artists to role-play with their OCs, focusing on conceptualization (e.g., backstories) while leaving exposition (visual creation) to creators. Through a study with 14 artists, we found ORIBA motivated artists' imaginative engagement, developing multidimensional attributes and stronger bonds with OCs that inspire their creative process. Our contributions include design insights for AI systems that develop from artists' perspectives, demonstrating how LLMs can support cross-modal creativity while preserving creative agency in OC art. This paper highlights the potential of GAI as a neutral, non-visual support that strengthens existing creative practice, without infringing artistic exposition.",
    "published": "2025-12-14T10:29:35Z",
    "authors": [
      "Yuqian Sun",
      "Xingyu Li",
      "Shunyu Yao",
      "Noura Howell",
      "Tristan Braud",
      "Chang Hee Lee",
      "Ali Asadipour"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12624",
    "title": "CoLSE: A Lightweight and Robust Hybrid Learned Model for Single-Table Cardinality Estimation using Joint CDF",
    "abstract": "Cardinality estimation (CE), the task of predicting the result size of queries is a critical component of query optimization. Accurate estimates are essential for generating efficient query execution plans. Recently, machine learning techniques have been applied to CE, broadly categorized into query-driven and data-driven approaches. Data-driven methods learn the joint distribution of data, while query-driven methods construct regression models that map query features to cardinalities. Ideally, a CE technique should strike a balance among three key factors: accuracy, efficiency, and memory footprint. However, existing state-of-the-art models often fail to achieve this balance.   To address this, we propose CoLSE, a hybrid learned approach for single-table cardinality estimation. CoLSE directly models the joint probability over queried intervals using a novel algorithm based on copula theory and integrates a lightweight neural network to correct residual estimation errors. Experimental results show that CoLSE achieves a favorable trade-off among accuracy, training time, inference latency, and model size, outperforming existing state-of-the-art methods.",
    "published": "2025-12-14T10:08:20Z",
    "authors": [
      "Lankadinee Rathuwadu",
      "Guanli Liu",
      "Christopher Leckie",
      "Renata Borovica-Gajic"
    ],
    "categories": [
      "cs.DB",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12623",
    "title": "Reasoning Within the Mind: Dynamic Multimodal Interleaving in Latent Space",
    "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced cross-modal understanding and reasoning by incorporating Chain-of-Thought (CoT) reasoning in the semantic space. Building upon this, recent studies extend the CoT mechanism to the visual modality, enabling models to integrate visual information during reasoning through external tools or explicit image generation. However, these methods remain dependent on explicit step-by-step reasoning, unstable perception-reasoning interaction and notable computational overhead. Inspired by human cognition, we posit that thinking unfolds not linearly but through the dynamic interleaving of reasoning and perception within the mind. Motivated by this perspective, we propose DMLR, a test-time Dynamic Multimodal Latent Reasoning framework that employs confidence-guided latent policy gradient optimization to refine latent think tokens for in-depth reasoning. Furthermore, a Dynamic Visual Injection Strategy is introduced, which retrieves the most relevant visual features at each latent think token and updates the set of best visual patches. The updated patches are then injected into latent think token to achieve dynamic visual-textual interleaving. Experiments across seven multimodal reasoning benchmarks and various model architectures demonstrate that DMLR significantly improves reasoning and perception performance while maintaining high inference efficiency.",
    "published": "2025-12-14T10:07:45Z",
    "authors": [
      "Chengzhi Liu",
      "Yuzhe Yang",
      "Yue Fan",
      "Qingyue Wei",
      "Sheng Liu",
      "Xin Eric Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12622",
    "title": "D3D-VLP: Dynamic 3D Vision-Language-Planning Model for Embodied Grounding and Navigation",
    "abstract": "Embodied agents face a critical dilemma that end-to-end models lack interpretability and explicit 3D reasoning, while modular systems ignore cross-component interdependencies and synergies. To bridge this gap, we propose the Dynamic 3D Vision-Language-Planning Model (D3D-VLP). Our model introduces two key innovations: 1) A Dynamic 3D Chain-of-Thought (3D CoT) that unifies planning, grounding, navigation, and question answering within a single 3D-VLM and CoT pipeline; 2) A Synergistic Learning from Fragmented Supervision (SLFS) strategy, which uses a masked autoregressive loss to learn from massive and partially-annotated hybrid data. This allows different CoT components to mutually reinforce and implicitly supervise each other. To this end, we construct a large-scale dataset with 10M hybrid samples from 5K real scans and 20K synthetic scenes that are compatible with online learning methods such as RL and DAgger. Our D3D-VLP achieves state-of-the-art results on multiple benchmarks, including Vision-and-Language Navigation (R2R-CE, REVERIE-CE, NavRAG-CE), Object-goal Navigation (HM3D-OVON), and Task-oriented Sequential Grounding and Navigation (SG3D). Real-world mobile manipulation experiments further validate the effectiveness.",
    "published": "2025-12-14T09:53:15Z",
    "authors": [
      "Zihan Wang",
      "Seungjun Lee",
      "Guangzhao Dai",
      "Gim Hee Lee"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12620",
    "title": "Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives",
    "abstract": "We study syllogistic reasoning in LLMs from the logical and natural language perspectives. In process, we explore fundamental reasoning capabilities of the LLMs and the direction this research is moving forward. To aid in our studies, we use 14 large language models and investigate their syllogistic reasoning capabilities in terms of symbolic inferences as well as natural language understanding. Even though this reasoning mechanism is not a uniform emergent property across LLMs, the perfect symbolic performances in certain models make us wonder whether LLMs are becoming more and more formal reasoning mechanisms, rather than making explicit the nuances of human reasoning.",
    "published": "2025-12-14T09:50:10Z",
    "authors": [
      "Aheli Poddar",
      "Saptarshi Sahoo",
      "Sujata Ghosh"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12617",
    "title": "Spectral Sentinel: Scalable Byzantine-Robust Decentralized Federated Learning via Sketched Random Matrix Theory on Blockchain",
    "abstract": "Decentralized federated learning (DFL) enables collaborative model training without centralized trust, but it remains vulnerable to Byzantine clients that poison gradients under heterogeneous (Non-IID) data. Existing defenses face a scalability trilemma: distance-based filtering (e.g., Krum) can reject legitimate Non-IID updates, geometric-median methods incur prohibitive $O(n^2 d)$ cost, and many certified defenses are evaluated only on models below 100M parameters. We propose Spectral Sentinel, a Byzantine detection and aggregation framework that leverages a random-matrix-theoretic signature: honest Non-IID gradients produce covariance eigenspectra whose bulk follows the Marchenko-Pastur law, while Byzantine perturbations induce detectable tail anomalies. Our algorithm combines Frequent Directions sketching with data-dependent MP tracking, enabling detection on models up to 1.5B parameters using $O(k^2)$ memory with $k \\ll d$. Under a $(σ,f)$ threat model with coordinate-wise honest variance bounded by $σ^2$ and $f < 1/2$ adversaries, we prove $(ε,δ)$-Byzantine resilience with convergence rate $O(σf / \\sqrt{T} + f^2 / T)$, and we provide a matching information-theoretic lower bound $Ω(σf / \\sqrt{T})$, establishing minimax optimality. We implement the full system with blockchain integration on Polygon networks and validate it across 144 attack-aggregator configurations, achieving 78.4 percent average accuracy versus 48-63 percent for baseline methods.",
    "published": "2025-12-14T09:43:03Z",
    "authors": [
      "Animesh Mishra"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12613",
    "title": "StruProKGR: A Structural and Probabilistic Framework for Sparse Knowledge Graph Reasoning",
    "abstract": "Sparse Knowledge Graphs (KGs) are commonly encountered in real-world applications, where knowledge is often incomplete or limited. Sparse KG reasoning, the task of inferring missing knowledge over sparse KGs, is inherently challenging due to the scarcity of knowledge and the difficulty of capturing relational patterns in sparse scenarios. Among all sparse KG reasoning methods, path-based ones have attracted plenty of attention due to their interpretability. Existing path-based methods typically rely on computationally intensive random walks to collect paths, producing paths of variable quality. Additionally, these methods fail to leverage the structured nature of graphs by treating paths independently. To address these shortcomings, we propose a Structural and Probabilistic framework named StruProKGR, tailored for efficient and interpretable reasoning on sparse KGs. StruProKGR utilizes a distance-guided path collection mechanism to significantly reduce computational costs while exploring more relevant paths. It further enhances the reasoning process by incorporating structural information through probabilistic path aggregation, which prioritizes paths that reinforce each other. Extensive experiments on five sparse KG reasoning benchmarks reveal that StruProKGR surpasses existing path-based methods in both effectiveness and efficiency, providing an effective, efficient, and interpretable solution for sparse KG reasoning.",
    "published": "2025-12-14T09:36:58Z",
    "authors": [
      "Yucan Guo",
      "Saiping Guan",
      "Miao Su",
      "Zeya Zhao",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "categories": [
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12610",
    "title": "Patch-wise Retrieval: A Bag of Practical Techniques for Instance-level Matching",
    "abstract": "Instance-level image retrieval aims to find images containing the same object as a given query, despite variations in size, position, or appearance. To address this challenging task, we propose Patchify, a simple yet effective patch-wise retrieval framework that offers high performance, scalability, and interpretability without requiring fine-tuning. Patchify divides each database image into a small number of structured patches and performs retrieval by comparing these local features with a global query descriptor, enabling accurate and spatially grounded matching. To assess not just retrieval accuracy but also spatial correctness, we introduce LocScore, a localization-aware metric that quantifies whether the retrieved region aligns with the target object. This makes LocScore a valuable diagnostic tool for understanding and improving retrieval behavior. We conduct extensive experiments across multiple benchmarks, backbones, and region selection strategies, showing that Patchify outperforms global methods and complements state-of-the-art reranking pipelines. Furthermore, we apply Product Quantization for efficient large-scale retrieval and highlight the importance of using informative features during compression, which significantly boosts performance. Project website: https://wons20k.github.io/PatchwiseRetrieval/",
    "published": "2025-12-14T09:24:51Z",
    "authors": [
      "Wonseok Choi",
      "Sohwi Lim",
      "Nam Hyeon-Woo",
      "Moon Ye-Bin",
      "Dong-Ju Jeong",
      "Jinyoung Hwang",
      "Tae-Hyun Oh"
    ],
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12608",
    "title": "Human-Inspired Learning for Large Language Models via Obvious Record and Maximum-Entropy Method Discovery",
    "abstract": "Large Language Models (LLMs) excel at extracting common patterns from large-scale corpora, yet they struggle with rare, low-resource, or previously unseen scenarios-such as niche hardware deployment issues or irregular IoT device behaviors-because such cases are sparsely represented in training data. Moreover, LLMs rely primarily on implicit parametric memory, which limits their ability to explicitly acquire, recall, and refine methods, causing them to behave predominantly as intuition-driven predictors rather than deliberate, method-oriented learners. Inspired by how humans learn from rare experiences, this paper proposes a human-inspired learning framework that integrates two complementary mechanisms. The first, Obvious Record, explicitly stores cause--result (or question--solution) relationships as symbolic memory, enabling persistent learning even from single or infrequent encounters. The second, Maximum-Entropy Method Discovery, prioritizes and preserves methods with high semantic dissimilarity, allowing the system to capture diverse and underrepresented strategies that are typically overlooked by next-token prediction. Verification on a benchmark of 60 semantically diverse question--solution pairs demonstrates that the proposed entropy-guided approach achieves stronger coverage of unseen questions and significantly greater internal diversity than a random baseline, confirming its effectiveness in discovering more generalizable and human-inspired methods.",
    "published": "2025-12-14T09:12:09Z",
    "authors": [
      "Hong Su"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12605",
    "title": "Causal inference and model explainability tools for retail",
    "abstract": "Most major retailers today have multiple divisions focused on various aspects, such as marketing, supply chain, online customer experience, store customer experience, employee productivity, and vendor fulfillment. They also regularly collect data corresponding to all these aspects as dashboards and weekly/monthly/quarterly reports. Although several machine learning and statistical techniques have been in place to analyze and predict key metrics, such models typically lack interpretability. Moreover, such techniques also do not allow the validation or discovery of causal links. In this paper, we aim to provide a recipe for applying model interpretability and causal inference for deriving sales insights. In this paper, we review the existing literature on causal inference and interpretability in the context of problems in e-commerce and retail, and apply them to a real-world dataset. We find that an inherently explainable model has a lower variance of SHAP values, and show that including multiple confounders through a double machine learning approach allows us to get the correct sign of causal effect.",
    "published": "2025-12-14T09:02:44Z",
    "authors": [
      "Pranav Gupta",
      "Nithin Surendran"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12604",
    "title": "No Cache Left Idle: Accelerating diffusion model via Extreme-slimming Caching",
    "abstract": "Diffusion models achieve remarkable generative quality, but computational overhead scales with step count, model depth, and sequence length. Feature caching is effective since adjacent timesteps yield highly similar features. However, an inherent trade-off remains: aggressive timestep reuse offers large speedups but can easily cross the critical line, hurting fidelity, while block- or token-level reuse is safer but yields limited computational savings. We present X-Slim (eXtreme-Slimming Caching), a training-free, cache-based accelerator that, to our knowledge, is the first unified framework to exploit cacheable redundancy across timesteps, structure (blocks), and space (tokens). Rather than simply mixing levels, X-Slim introduces a dual-threshold controller that turns caching into a push-then-polish process: it first pushes reuse at the timestep level up to an early-warning line, then switches to lightweight block- and token-level refresh to polish the remaining redundancy, and triggers full inference once the critical line is crossed to reset accumulated error. At each level, context-aware indicators decide when and where to cache. Across diverse tasks, X-Slim advances the speed-quality frontier. On FLUX.1-dev and HunyuanVideo, it reduces latency by up to 4.97x and 3.52x with minimal perceptual loss. On DiT-XL/2, it reaches 3.13x acceleration and improves FID by 2.42 over prior methods.",
    "published": "2025-12-14T09:02:18Z",
    "authors": [
      "Tingyan Wen",
      "Haoyu Li",
      "Yihuang Chen",
      "Xing Zhou",
      "Lifei Zhu",
      "Xueqian Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12602",
    "title": "Error-Free Linear Attention is a Free Lunch: Exact Solution from Continuous-Time Dynamics",
    "abstract": "Linear-time attention and State Space Models (SSMs) promise to solve the quadratic cost bottleneck in long-context language models employing softmax attention. We introduce Error-Free Linear Attention (EFLA), a numerically stable, fully parallelism and generalized formulation of the delta rule. Specifically, we formulate the online learning update as a continuous-time dynamical system and prove that its exact solution is not only attainable but also computable in linear time with full parallelism. By leveraging the rank-1 structure of the dynamics matrix, we directly derive the exact closed-form solution effectively corresponding to the infinite-order Runge-Kutta method. This attention mechanism is theoretically free from error accumulation, perfectly capturing the continuous dynamics while preserving the linear-time complexity. Through an extensive suite of experiments, we show that EFLA enables robust performance in noisy environments, achieving lower language modeling perplexity and superior downstream benchmark performance than DeltaNet without introducing additional parameters. Our work provides a new theoretical foundation for building high-fidelity, scalable linear-time attention models.",
    "published": "2025-12-14T08:51:02Z",
    "authors": [
      "Jingdi Lei",
      "Di Zhang",
      "Soujanya Poria"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12598",
    "title": "Geometry-Aware Scene-Consistent Image Generation",
    "abstract": "We study geometry-aware scene-consistent image generation: given a reference scene image and a text condition specifying an entity to be generated in the scene and its spatial relation to the scene, the goal is to synthesize an output image that preserves the same physical environment as the reference scene while correctly generating the entity according to the spatial relation described in the text. Existing methods struggle to balance scene preservation with prompt adherence: they either replicate the scene with high fidelity but poor responsiveness to the prompt, or prioritize prompt compliance at the expense of scene consistency. To resolve this trade-off, we introduce two key contributions: (i) a scene-consistent data construction pipeline that generates diverse, geometrically-grounded training pairs, and (ii) a novel geometry-guided attention loss that leverages cross-view cues to regularize the model's spatial reasoning. Experiments on our scene-consistent benchmark show that our approach achieves better scene alignment and text-image consistency than state-of-the-art baselines, according to both automatic metrics and human preference studies. Our method produces geometrically coherent images with diverse compositions that remain faithful to the textual instructions and the underlying scene structure.",
    "published": "2025-12-14T08:35:04Z",
    "authors": [
      "Cong Xie",
      "Che Wang",
      "Yan Zhang",
      "Zheng Pan",
      "Han Zou",
      "Zhenpeng Zhan"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12597",
    "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation",
    "abstract": "LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot. No existing XAI methods address tool-level explanations. We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents. AgentSHAP is model-agnostic: it treats the agent as a black box and works with any LLM (GPT, Claude, Llama, etc.) without needing access to internal weights or gradients. Using Monte Carlo Shapley values, AgentSHAP tests how an agent responds with different tool subsets and computes fair importance scores based on game theory. Our contributions are: (1) the first explainability method for agent tool attribution, grounded in Shapley values from game theory; (2) Monte Carlo sampling that reduces cost from O(2n) to practical levels; and (3) comprehensive experiments on API-Bank showing that AgentSHAP produces consistent scores across runs, correctly identifies which tools matter, and distinguishes relevant from irrelevant tools. AgentSHAP joins TokenSHAP (for tokens) and PixelSHAP (for image regions) to complete a family of Shapley-based XAI tools for modern generative AI. Code: https://github.com/GenAISHAP/TokenSHAP.",
    "published": "2025-12-14T08:31:43Z",
    "authors": [
      "Miriam Horovicz"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12596",
    "title": "Content-Aware Ad Banner Layout Generation with Two-Stage Chain-of-Thought in Vision Language Models",
    "abstract": "In this paper, we propose a method for generating layouts for image-based advertisements by leveraging a Vision-Language Model (VLM). Conventional advertisement layout techniques have predominantly relied on saliency mapping to detect salient regions within a background image, but such approaches often fail to fully account for the image's detailed composition and semantic content. To overcome this limitation, our method harnesses a VLM to recognize the products and other elements depicted in the background and to inform the placement of text and logos. The proposed layout-generation pipeline consists of two steps. In the first step, the VLM analyzes the image to identify object types and their spatial relationships, then produces a text-based \"placement plan\" based on this analysis. In the second step, that plan is rendered into the final layout by generating HTML-format code. We validated the effectiveness of our approach through evaluation experiments, conducting both quantitative and qualitative comparisons against existing methods. The results demonstrate that by explicitly considering the background image's content, our method produces noticeably higher-quality advertisement layouts.",
    "published": "2025-12-14T08:30:15Z",
    "authors": [
      "Kei Yoshitake",
      "Kento Hosono",
      "Ken Kobayashi",
      "Kazuhide Nakata"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12595",
    "title": "Vision-Enhanced Large Language Models for High-Resolution Image Synthesis and Multimodal Data Interpretation",
    "abstract": "This research introduces a transformative framework for integrating Vision-Enhanced Large Language Models (LLMs) with advanced transformer-based architectures to tackle challenges in high-resolution image synthesis and multimodal data interpretation. The proposed model incorporates a rectified flow mechanism that connects noise and data with linear paths, enabling efficient and high-quality generation. A bidirectional tokenization strategy is employed to seamlessly merge inputs from text, image, and video modalities, fostering a unified understanding across diverse data types. By embedding spatial-temporal features and leveraging a hybrid text-image sequence modeling approach, the framework achieves unparalleled fidelity in synthesized images and coherent multimodal representations. The architecture is optimized with a noise-aware learning algorithm, addressing discrepancies in noisy data distributions and improving generative performance under varying input conditions. Rigorous evaluations on benchmark datasets demonstrate a 25% increase in image resolution clarity and a 20% reduction in computational requirements compared to diffusion-based methods. Furthermore, the model exhibits robust scalability and adaptability, showcasing its potential in applications like autonomous systems, creative content generation, and advanced video analysis. This work underscores the role of vision-centric LLMs in redefining capabilities in computer vision and multimodal artificial intelligence.",
    "published": "2025-12-14T08:28:50Z",
    "authors": [
      "Karthikeya KV"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12594",
    "title": "ceLLMate: Sandboxing Browser AI Agents",
    "abstract": "Browser-using agents (BUAs) are an emerging class of autonomous agents that interact with web browsers in human-like ways, including clicking, scrolling, filling forms, and navigating across pages. While these agents help automate repetitive online tasks, they are vulnerable to prompt injection attacks that can trick an agent into performing undesired actions, such as leaking private information or issuing state-changing requests. We propose ceLLMate, a browser-level sandboxing framework that restricts the agent's ambient authority and reduces the blast radius of prompt injections. We address two fundamental challenges: (1) The semantic gap challenge in policy enforcement arises because the agent operates through low-level UI observations and manipulations; however, writing and enforcing policies directly over UI-level events is brittle and error-prone. To address this challenge, we introduce an agent sitemap that maps low-level browser behaviors to high-level semantic actions. (2) Policy prediction in BUAs is the norm rather than the exception. BUAs have no app developer to pre-declare sandboxing policies, and thus, ceLLMate pairs website-authored mandatory policies with an automated policy-prediction layer that adapts and instantiates these policies from the user's natural-language task. We implement ceLLMate as an agent-agnostic browser extension and demonstrate how it enables sandboxing policies that effectively block various types of prompt injection attacks with negligible overhead.",
    "published": "2025-12-14T08:25:31Z",
    "authors": [
      "Luoxi Meng",
      "Henry Feng",
      "Ilia Shumailov",
      "Earlence Fernandes"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12593",
    "title": "SHERLOCK: A Deep Learning Approach To Detect Software Vulnerabilities",
    "abstract": "The increasing reliance on software in various applications has made the problem of software vulnerability detection more critical. Software vulnerabilities can lead to security breaches, data theft, and other negative outcomes. Traditional software vulnerability detection techniques, such as static and dynamic analysis, have been shown to be ineffective at detecting multiple vulnerabilities.   To address this issue, this study employed a deep learning approach, specifically Convolutional Neural Networks (CNN), to solve the software vulnerability detection problem. A 5-split cross-validation approach was used to train and evaluate the CNN model, which takes tokenized source code as input.   The findings indicated that Sherlock successfully detected multiple vulnerabilities at the function level, and its performance was particularly strong for CWE-199, CWE-120, and CWE-Other, with an overall high accuracy rate and significant true positive and true negative values. However, the performance was less reliable for some vulnerabilities due to the lack of a standardized dataset which will be a future research direction. The results suggest that compared to current techniques, the proposed deep learning approach has the potential to substantially enhance the accuracy of software vulnerability detection.",
    "published": "2025-12-14T08:24:06Z",
    "authors": [
      "Saadh Jawwadh",
      "Guhanathan Poravi"
    ],
    "categories": [
      "cs.SE",
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12590",
    "title": "Automatic Wire-Harness Color Sequence Detector",
    "abstract": "Wire harness inspection process remains a labor-intensive process prone to errors in the modern Electronics Manufacturing Services (EMS) industry. This paper introduces a semiautomated machine vision system capable of verifying correct wire positioning, correctness of the connector polarity and correctness of color sequences for both linear and circular wire harness configurations. Five industrial standard CMOS cameras are integrated into a modularized mechanical framework in the physical structure of the solution and a HSV and RGB color domain value comparison based color sequence classifier is used in the operation. For each harness batch, a user can train the system using at least five reference samples; the trained file is stored and reused for similar harness types. The Solution is deployed at GPV Lanka Pvt. Ltd. (Fig. 2) and the system achieved 100% detection accuracy and reduced inspection time by 44% compared to manual methods. Additional features include user management, adjustable lighting, session data storage, and secure login. Results of this product usage in the real world situation demonstrate that this approach delivers reliable and efficient inspection capabilities.",
    "published": "2025-12-14T08:12:03Z",
    "authors": [
      "Indiwara Nanayakkara",
      "Dehan Jayawickrama",
      "Mervyn Parakrama B. Ekanayake"
    ],
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12586",
    "title": "StegaVAR: Privacy-Preserving Video Action Recognition via Steganographic Domain Analysis",
    "abstract": "Despite the rapid progress of deep learning in video action recognition (VAR) in recent years, privacy leakage in videos remains a critical concern. Current state-of-the-art privacy-preserving methods often rely on anonymization. These methods suffer from (1) low concealment, where producing visually distorted videos that attract attackers' attention during transmission, and (2) spatiotemporal disruption, where degrading essential spatiotemporal features for accurate VAR. To address these issues, we propose StegaVAR, a novel framework that embeds action videos into ordinary cover videos and directly performs VAR in the steganographic domain for the first time. Throughout both data transmission and action analysis, the spatiotemporal information of hidden secret video remains complete, while the natural appearance of cover videos ensures the concealment of transmission. Considering the difficulty of steganographic domain analysis, we propose Secret Spatio-Temporal Promotion (STeP) and Cross-Band Difference Attention (CroDA) for analysis within the steganographic domain. STeP uses the secret video to guide spatiotemporal feature extraction in the steganographic domain during training. CroDA suppresses cover interference by capturing cross-band semantic differences. Experiments demonstrate that StegaVAR achieves superior VAR and privacy-preserving performance on widely used datasets. Moreover, our framework is effective for multiple steganographic models.",
    "published": "2025-12-14T07:44:07Z",
    "authors": [
      "Lixin Chen",
      "Chaomeng Chen",
      "Jiale Zhou",
      "Zhijian Wu",
      "Xun Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12583",
    "title": "Detecting Prompt Injection Attacks Against Application Using Classifiers",
    "abstract": "Prompt injection attacks can compromise the security and stability of critical systems, from infrastructure to large web applications. This work curates and augments a prompt injection dataset based on the HackAPrompt Playground Submissions corpus and trains several classifiers, including LSTM, feed forward neural networks, Random Forest, and Naive Bayes, to detect malicious prompts in LLM integrated web applications. The proposed approach improves prompt injection detection and mitigation, helping protect targeted applications and systems.",
    "published": "2025-12-14T07:35:32Z",
    "authors": [
      "Safwan Shaheer",
      "G. M. Refatul Islam",
      "Mohammad Rafid Hamid",
      "Md. Abrar Faiaz Khan",
      "Md. Omar Faruk",
      "Yaseen Nur"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12581",
    "title": "Differentiable Energy-Based Regularization in GANs: A Simulator-Based Exploration of VQE-Inspired Auxiliary Losses",
    "abstract": "This paper presents an exploratory, simulator-based proof of concept investigating whether differentiable energy terms derived from parameterized quantum circuits can serve as auxiliary regularization signals in Generative Adversarial Networks (GANs). We augment the Auxiliary Classifier GAN (ACGAN) generator objective with a Variational Quantum Eigensolver (VQE)-inspired energy term computed from class-specific Ising Hamiltonians using Qiskit's EstimatorQNN and TorchConnector.   Important limitations: All experiments run on a noiseless statevector simulator with only 4 qubits, use a deliberately simple Hamiltonian parameterization, and lack ablation studies comparing against equivalent classical biases. The computational overhead (approximately 200x slower than classical ACGAN) reflects simulator artifacts rather than inherent quantum costs.   On MNIST, we observe that the energy-regularized model (termed QACGAN) achieves high classification accuracy (99 to 100 percent) within 5 epochs compared to 87.8 percent for ACGAN, suggesting the auxiliary term influences class conditioning. However, sample quality metrics (FID) show high variance across runs (coefficient of variation approximately 25 percent at epoch 5), with values ranging from 19.92 to 35.96. Extended runs stabilize around FID 23 to 24, comparable to the ACGAN baseline.   We explicitly do not claim quantum advantage, improved stability in any general sense, or scalability beyond this toy setting. The contribution is methodological: demonstrating that VQE-style energy computations can be integrated into GAN training loops via differentiable pathways. Whether such auxiliary signals provide benefits beyond equivalent classical regularizers remains an open question requiring systematic ablation studies, which we leave for future work.",
    "published": "2025-12-14T07:23:57Z",
    "authors": [
      "David Strnadel"
    ],
    "categories": [
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12580",
    "title": "Cryptographic transformations over polyadic rings",
    "abstract": "This article introduces a novel cryptographic paradigm based on nonderived polyadic algebraic structures. Traditional cryptosystems rely on binary operations within groups, rings, or fields, whose well-understood properties can be exploited in cryptanalysis. To overcome these vulnerabilities, we propose a shift to polyadic rings, which generalize classical rings by allowing operations of higher arity: an $m$-ary addition and an $n$-ary multiplication. The foundation of our approach is the construction of polyadic integers -- congruence classes of ordinary integers endowed with such $m$-ary and $n$-ary operations. A key innovation is the parameter-to-arity mapping $Φ(a,b)=(m,n)$, which links the parameters $(a,b)$ defining a congruence class to the specific arities required for algebraic closure. This mapping is mathematically intricate: it is non-injective, non-surjective, and multivalued. This complex, non-unique relationship forms the core of the proposed cryptosystem's security. We present two concrete encryption procedures that leverage this structure by encoding plaintext within the parameters of polyadic rings and transmitting information via polyadically quantized analog signals. In one method, plaintext is linked to the additive arity $m_{i}$ and secured using the summation of such signals; in the other, it is linked to a ring parameter $a_{i}$ and secured using their multiplication. In both cases, the \"quantized\" nature of polyadic operations generates systems of equations that are straightforward for a legitimate recipient with the correct key but exceptionally difficult for an attacker without it. The resulting framework promises a substantial increase in cryptographic security. This work establishes the theoretical foundation for this new class of encryption schemes and highlights their potential for constructing robust, next-generation cryptographic protocols.",
    "published": "2025-12-14T07:15:55Z",
    "authors": [
      "Steven Duplij",
      "Na Fu",
      "Qiang Guo"
    ],
    "categories": [
      "cs.CR"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12578",
    "title": "Scalable Quantum Error Mitigation with Neighbor-Informed Learning",
    "abstract": "Noise in quantum hardware is the primary obstacle to realizing the transformative potential of quantum computing. Quantum error mitigation (QEM) offers a promising pathway to enhance computational accuracy on near-term devices, yet existing methods face a difficult trade-off between performance, resource overhead, and theoretical guarantees. In this work, we introduce neighbor-informed learning (NIL), a versatile and scalable QEM framework that unifies and strengthens existing methods such as zero-noise extrapolation (ZNE) and probabilistic error cancellation (PEC), while offering improved flexibility, accuracy, efficiency, and robustness.   NIL learns to predict the ideal output of a target quantum circuit from the noisy outputs of its structurally related ``neighbor'' circuits. A key innovation is our 2-design training method, which generates training data for our machine learning model. In contrast to conventional learning-based QEM protocols that create training circuits by replacing non-Clifford gates with uniformly random Clifford gates, our approach achieves higher accuracy and efficiency, as demonstrated by both theoretical analysis and numerical simulation. Furthermore, we prove that the required size of the training set scales only \\emph{logarithmically} with the total number of neighbor circuits, enabling NIL to be applied to problems involving large-scale quantum circuits. Our work establishes a theoretically grounded and practically efficient framework for QEM, paving a viable path toward achieving quantum advantage on noisy hardware.",
    "published": "2025-12-14T07:07:48Z",
    "authors": [
      "Zhenyu Chen",
      "Bin Cheng",
      "Minbo Gao",
      "Xiaodie Lin",
      "Ruiqi Zhang",
      "Zhaohui Wei",
      "Zhengfeng Ji"
    ],
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.LG"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12576",
    "title": "Coupled Variational Reinforcement Learning for Language Model General Reasoning",
    "abstract": "While reinforcement learning have achieved impressive progress in language model reasoning, they are constrained by the requirement for verifiable rewards. Recent verifier-free RL methods address this limitation by utilizing the intrinsic probabilities of LLMs generating reference answers as reward signals. However, these approaches typically sample reasoning traces conditioned only on the question. This design decouples reasoning-trace sampling from answer information, leading to inefficient exploration and incoherence between traces and final answers. In this paper, we propose \\textit{\\b{Co}upled \\b{V}ariational \\b{R}einforcement \\b{L}earning} (CoVRL), which bridges variational inference and reinforcement learning by coupling prior and posterior distributions through a hybrid sampling strategy. By constructing and optimizing a composite distribution that integrates these two distributions, CoVRL enables efficient exploration while preserving strong thought-answer coherence. Extensive experiments on mathematical and general reasoning benchmarks show that CoVRL improves performance by 12.4\\% over the base model and achieves an additional 2.3\\% improvement over strong state-of-the-art verifier-free RL baselines, providing a principled framework for enhancing the general reasoning capabilities of language models.",
    "published": "2025-12-14T07:03:51Z",
    "authors": [
      "Xueru Wen",
      "Jie Lou",
      "Yanjiang Liu",
      "Hongyu Lin",
      "Ben He",
      "Xianpei Han",
      "Le Sun",
      "Yaojie Lu",
      "Debing Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12574",
    "title": "Mind the Jumps: A Scalable Robust Local Gaussian Process for Multidimensional Response Surfaces with Discontinuities",
    "abstract": "Modeling response surfaces with abrupt jumps and discontinuities remains a major challenge across scientific and engineering domains. Although Gaussian process models excel at capturing smooth nonlinear relationships, their stationarity assumptions limit their ability to adapt to sudden input-output variations. Existing nonstationary extensions, particularly those based on domain partitioning, often struggle with boundary inconsistencies, sensitivity to outliers, and scalability issues in higher-dimensional settings, leading to reduced predictive accuracy and unreliable parameter estimation.   To address these challenges, this paper proposes the Robust Local Gaussian Process (RLGP) model, a framework that integrates adaptive nearest-neighbor selection with a sparsity-driven robustification mechanism. Unlike existing methods, RLGP leverages an optimization-based mean-shift adjustment after a multivariate perspective transformation combined with local neighborhood modeling to mitigate the influence of outliers. This approach improves predictive accuracy near discontinuities while enhancing robustness to data heterogeneity.   Comprehensive evaluations on real-world datasets show that RLGP consistently delivers high predictive accuracy and maintains competitive computational efficiency, especially in scenarios with sharp transitions and complex response structures. Scalability tests further confirm RLGP's stability and reliability in higher-dimensional settings, where other methods struggle. These results establish RLGP as an effective and practical solution for modeling nonstationary and discontinuous response surfaces across a wide range of applications.",
    "published": "2025-12-14T06:52:17Z",
    "authors": [
      "Isaac Adjetey",
      "Yiyuan She"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "source": "arXiv",
    "batch": 4
  },
  {
    "arxiv_id": "2512.12572",
    "title": "On the Accuracy of Newton Step and Influence Function Data Attributions",
    "abstract": "Data attribution aims to explain model predictions by estimating how they would change if certain training points were removed, and is used in a wide range of applications, from interpretability and credit assignment to unlearning and privacy.   Even in the relatively simple case of linear regressions, existing mathematical analyses of leading data attribution methods such as Influence Functions (IF) and single Newton Step (NS) remain limited in two key ways. First, they rely on global strong convexity assumptions which are often not satisfied in practice. Second, the resulting bounds scale very poorly with the number of parameters ($d$) and the number of samples removed ($k$). As a result, these analyses are not tight enough to answer fundamental questions such as \"what is the asymptotic scaling of the errors of each method?\" or \"which of these methods is more accurate for a given dataset?\"   In this paper, we introduce a new analysis of the NS and IF data attribution methods for convex learning problems. To the best of our knowledge, this is the first analysis of these questions that does not assume global strong convexity and also the first explanation of [KATL19] and [RH25a]'s observation that NS data attribution is often more accurate than IF. We prove that for sufficiently well-behaved logistic regression, our bounds are asymptotically tight up to poly-logarithmic factors, yielding scaling laws for the errors in the average-case sample removals.   \\[ \\mathbb{E}_{T \\subseteq [n],\\, |T| = k} \\bigl[ \\|\\hatθ_T - \\hatθ_T^{\\mathrm{NS}}\\|_2 \\bigr] = \\widetildeΘ\\!\\left(\\frac{k d}{n^2}\\right), \\qquad \\mathbb{E}_{T \\subseteq [n],\\, |T| = k} \\bigl[ \\|\\hatθ_T^{\\mathrm{NS}} - \\hatθ_T^{\\mathrm{IF}}\\|_2 \\bigr] = \\widetildeΘ\\!\\left( \\frac{(k + d)\\sqrt{k d}}{n^2} \\right). \\]",
    "published": "2025-12-14T06:33:52Z",
    "authors": [
      "Ittai Rubinstein",
      "Samuel B. Hopkins"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "source": "arXiv",
    "batch": 4
  }
]